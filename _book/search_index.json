[
["index.html", "Geología Numérica: Ciencia de Datos para Geociencias Prefacio", " Geología Numérica: Ciencia de Datos para Geociencias Maximiliano Garnier Villarreal 2020-05-06 Prefacio Este libro es producido en Markdown (Xie, Allaire, &amp; Grolemund, 2018), usando bookdown (Xie, 2016). El paquete bookdown puede ser instalado desde CRAN o GitHub: install.packages(&quot;bookdown&quot;) # version en desarrollo # devtools::install_github(&quot;rstudio/bookdown&quot;) Este documento se basa en el material creado para el curso G-4101 Geología Numérica, de la Escuela Centroamericana de Geologia, Universidad de Costa Rica, pero la idea es ir expandiendo los temas más allá del curso. El curso hace uso del software estadístico y de programación R (R Core Team, 2019) para desarrollar la parte practica de los temas cubiertos en la teoría. Existe un repositorio en GitHub para este proyecto (geolonum), donde se pueden acceder los documentos y datos usados en este libro. Adicionalmente, se ha creado un paquete que ofrece funciones adicionales que serán usadas en algunos de los temas que se van a tratar. Para instalar y ver la documentación del paquete se puede ir a GMisc y seguir las instrucciones de la instalación (el paquete no esta en CRAN, esta en GitHub, por lo que no se puede instalar de la forma convencional). El libro se divide en 2 partes principales: Uso de R (Capítulos 1 al 6) Análisis de datos (Capítulos 7-19) En la parte de análisis de datos se cubre lo básico de álgebra lineal, para luego caer en la parte gruesa del curso que es estadística. En esta parte se ve lo que es estadística descriptiva (univariable y bivariable), principios de probabilidad, distribuciones de probabilidad, estadística inferencial (pruebas de hipótesis, estimación), y estadística no paramétrica. La parte final del curso cubre temas relacionados con geociencias (datos direccionales, secuencias, y geoestadística), donde se aplican conceptos anteriormente adquiridos en la sección de estadística. Este obra está bajo una licencia de Creative Commons Reconocimiento-NoComercial-CompartirIgual 4.0 Internacional. This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. Referencias "],
["intro.html", "Capítulo 1 Introducción 1.1 Instalación de R y RStudio 1.2 Paquetes 1.3 Ayuda en R 1.4 RMarkdown 1.5 Recursos", " Capítulo 1 Introducción R es un programa estadístico y de programación, el cual le permite al usuario hacer uso de funciones (en paquetes) ya definidas o la creación de funciones propias para resolver problemas específicos. Muchas de las funciones presentan un gran detalle en los resultados, haciendo fácil la interpretación de los mismos. 1.1 Instalación de R y RStudio R es el motor, donde se realizan las operaciones, RStudio es el chasis, lo que le permite al usuario interactuar con el motor, es una interfaz de desarrollo que facilita las tareas en un proyecto. Primero hay que instalar R: Ir a R Descargar la versión dependiendo del sistema operativo (Figura 1.1) Figura 1.1: Repositorio CRAN para descargar R Después de instalar R hay que instalar RStudio: Ir a RStudio Descargar RStudio Desktop, la versión libre (Free) 1.2 Paquetes La instalación de R básica trae una serie de paquetes (librerías) instaladas, que funcionan para cosas básicas y sencillas. Para instalar paquetes de forma interactiva se va a la sección de paquetes (packages), se hace click en instalar (install), como se muestra en la Figura 1.2, y se escribe el o los nombres de los paquetes a instalar, separados por espacios. Figura 1.2: Como instalar paquetes de forma manual La forma más práctica de instalar (actualizar) paquetes es por medio de código, usando install.packages(&quot;paquete&quot;). Para cargar paquetes y sus funciones durante una sesión de R se usa la función library(paquete). Cabe mencionar que en el orden que se carguen los paquetes así se habilitaran las funciones, y si hay funciones con el mismo nombre en diferentes paquetes, la que se va a habilitar por defecto es la del ultimo paquete cargado. Una forma de solucionar un conflicto de este tipo o llamar una función de un paquete sin cargarlo es por medio de paquete::funcion, donde se usa del paquete deseado la función correspondiente (Ejemplo dplyr::select). install.packages(&quot;devtools&quot;) library(lubridate) library(tidyverse) 1.3 Ayuda en R Para buscar ayuda sobre funciones y cuales argumentos requiere se puede usar ?funcion, o se para sobre la función y se apreta F1. ?mean 1.4 RMarkdown Un documento R Markdown es un tipo de documento que permite mezclar texto con código, manteniendo el análisis y los resultados en un mismo lugar. La interfaz y estructura típica se muestran en la Figura 1.3. Cuando ejecuta el código dentro del documento el resultado aparece por debajo del código. Figura 1.3: Estructura de un documento RMarkdown Todo documento empieza con el encabezado YAML, que se define entre guiones consecutivos (---). Aquí se definen las características generales del documento: titulo (‘title’) autor (‘author’) fecha (‘date’) tipo de documento (‘output’) etc Idealmente todo bloque de código debiera llevar un nombre para poder identificarlo, así como su resultado. Para ejecutar una sección de código se puede hacer click en el botón verde de Run dentro de la sección o colocando el cursor dentro de la sección y ejecutando Ctrl+Shift+Enter (Windows) o Cmd+Shift+Enter (Mac). Así de fácil! Se puede agregar una nueva sección haciendo click en Insert Chunk o ejecutando Ctrl+Alt+I (Windows) o Cmd+Option+I (Mac). 1.4.1 Tipos de resultados Se pueden tener resultados de diferentes tipos, los cuales se muestran a continuación. 1.4.1.1 Consola Podemos crear diferentes objetos dentro de la sección como si fuera la consola de R. Creemos un objeto que contenga los números del 1 al 15. numeros &lt;- seq_len(15) numeros ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 Podemos desplegar tablas (Tabla 1.1). La apariencia va a cambiar dependiendo el formato de salida y va a estar sujeta a la opción df_print en el encabezado YAML, a menos de que se sobre-escriba en el código. Para darle numero y etiqueta a una tabla se debe usar la función kable del paquete knitr (Xie, 2014, 2015). mtcars %&gt;% knitr::kable(caption = &#39;Datos de diferentes carros&#39;) Tabla 1.1: Datos de diferentes carros mpg cyl disp hp drat wt qsec vs am gear carb Mazda RX4 21.0 6 160.0 110 3.90 2.620 16.46 0 1 4 4 Mazda RX4 Wag 21.0 6 160.0 110 3.90 2.875 17.02 0 1 4 4 Datsun 710 22.8 4 108.0 93 3.85 2.320 18.61 1 1 4 1 Hornet 4 Drive 21.4 6 258.0 110 3.08 3.215 19.44 1 0 3 1 Hornet Sportabout 18.7 8 360.0 175 3.15 3.440 17.02 0 0 3 2 Valiant 18.1 6 225.0 105 2.76 3.460 20.22 1 0 3 1 Duster 360 14.3 8 360.0 245 3.21 3.570 15.84 0 0 3 4 Merc 240D 24.4 4 146.7 62 3.69 3.190 20.00 1 0 4 2 Merc 230 22.8 4 140.8 95 3.92 3.150 22.90 1 0 4 2 Merc 280 19.2 6 167.6 123 3.92 3.440 18.30 1 0 4 4 Merc 280C 17.8 6 167.6 123 3.92 3.440 18.90 1 0 4 4 Merc 450SE 16.4 8 275.8 180 3.07 4.070 17.40 0 0 3 3 Merc 450SL 17.3 8 275.8 180 3.07 3.730 17.60 0 0 3 3 Merc 450SLC 15.2 8 275.8 180 3.07 3.780 18.00 0 0 3 3 Cadillac Fleetwood 10.4 8 472.0 205 2.93 5.250 17.98 0 0 3 4 Lincoln Continental 10.4 8 460.0 215 3.00 5.424 17.82 0 0 3 4 Chrysler Imperial 14.7 8 440.0 230 3.23 5.345 17.42 0 0 3 4 Fiat 128 32.4 4 78.7 66 4.08 2.200 19.47 1 1 4 1 Honda Civic 30.4 4 75.7 52 4.93 1.615 18.52 1 1 4 2 Toyota Corolla 33.9 4 71.1 65 4.22 1.835 19.90 1 1 4 1 Toyota Corona 21.5 4 120.1 97 3.70 2.465 20.01 1 0 3 1 Dodge Challenger 15.5 8 318.0 150 2.76 3.520 16.87 0 0 3 2 AMC Javelin 15.2 8 304.0 150 3.15 3.435 17.30 0 0 3 2 Camaro Z28 13.3 8 350.0 245 3.73 3.840 15.41 0 0 3 4 Pontiac Firebird 19.2 8 400.0 175 3.08 3.845 17.05 0 0 3 2 Fiat X1-9 27.3 4 79.0 66 4.08 1.935 18.90 1 1 4 1 Porsche 914-2 26.0 4 120.3 91 4.43 2.140 16.70 0 1 5 2 Lotus Europa 30.4 4 95.1 113 3.77 1.513 16.90 1 1 5 2 Ford Pantera L 15.8 8 351.0 264 4.22 3.170 14.50 0 1 5 4 Ferrari Dino 19.7 6 145.0 175 3.62 2.770 15.50 0 1 5 6 Maserati Bora 15.0 8 301.0 335 3.54 3.570 14.60 0 1 5 8 Volvo 142E 21.4 4 121.0 109 4.11 2.780 18.60 1 1 4 2 1.4.1.2 Gráficos Gráficos de ggplot2 o cualquier otro gráfico estático son resultados que se pueden desplegar. Opciones para el control sobre las figura van a empezar con fig. en el encabezado del código (como se hace en el siguiente ejemplo, Figura ?? donde se ajusta el ancho a 6 pulgadas - fig.width=6). q = ggplot(mtcars, aes(wt,mpg,col=factor(cyl))) + geom_point(size=2,shape=1) + theme_bw() + labs(x=&#39;Peso&#39;,y=&#39;Millaje&#39;,col=&#39;Cilindros&#39;) q Figura 1.4: Grafico estatico 1.4.1.3 Widgets HTML Si el análisis en R involucra componentes interactivos, estos también son compatibles con los resultados en el cuaderno o archivo HTML. La opción eval=knitr::is_html_output() se incluye para que el código sea evaluado únicamente cuando el formato de salida es HTML, ya que estos no pueden desplegarse en PDF o Word. El siguiente código genera un gráfico interactivo (Figura 1.5). dygraph(nhtemp, main = &quot;Temperaturas de New Haven&quot;) %&gt;% dyRangeSelector(dateWindow = c(&quot;1920-01-01&quot;, &quot;1960-01-01&quot;)) ## Registered S3 method overwritten by &#39;xts&#39;: ## method from ## as.zoo.xts zoo Figura 1.5: Ejemplo de grafico interactivo En la Figura 1.6 se muestra la versión interactiva de la Figura ??, anteriormente generada. ggplotly(q) Figura 1.6: Version interactiva del grafico estatico 1.4.2 Formulas Expresiones matemáticas y formulas se pueden desplegar en linea, dentro del cuerpo del texto (\\(A = \\pi*r^{2}\\)) o por separado \\[E = mc^{2}\\] Para escribir estas expresiones se usa la metodología o lenguaje LaTeX. 1.4.3 Importando datos Los documentos R Markdown usan una dirección relativa a la ubicación del archivo. dat &lt;- import(&quot;data/LungCapData2.csv&quot;) 1.4.4 Cálculos en linea Siempre que un valor exista dentro de un objeto guardado, este se puede acceder para ser desplegado en el cuerpo del documento. Esto se realiza escribiendo código entre comillas invertidas, como por ejemplo round(mean(airquality$Temp), 2), lo que resulta en 77.88, que es la temperatura media en grados Fahrenheit. 1.4.5 Importando figuras La mejor manera es usando el paquete knitr. Aquí se ajusta no el ancho de la figura directamente sino que se le dice que se ajuste a un 50% del ancho disponible. Existen otras opciones que empiezan con out.. En la Figura 1.7 se ajusta el ancho de salida con out.width='50%'. knitr::include_graphics(&#39;images/r_rocks.jpg&#39;) Figura 1.7: R Rocks 1.4.6 Salvando y compartiendo Los documentos R Markdown tienen como extensión .Rmd. Cuando se crea y se salva un cuaderno se crea un archivo adjunto con extensión .nb.html. Este archivo contiene una copia renderizada del cuaderno, que puede ser visualizada en cualquier navegador. Cuando se abre el archivo .nb.html en un navegador se va a tener la opción de descargar el código original (.Rmd). Para previsualizar el cuaderno renderizado (.nb.html) haga click en Preview. La previsualización le muestra una copia renderizada del HTML. A diferencia de Knit (para otros documentos R Markdown), Preview no ejecuta ninguna sección de código, por lo que si una sección no se ha ejecutado en el editor el Preview no va a mostrar ningún resultado. La previsualización se actualiza cada vez que se salva el documento .Rmd. 1.4.6.1 Otros formatos El cuaderno es un documento R Markdown. Se puede cambiar el formato de salida cambiando el orden en el encabezado YAML. En ese caso el Preview es reemplazado por Knit y genera un documento HTML corriente. También se puede generar desplegando el menú contextual haciendo click en la flecha junto a Preview. También se pueden crear documentos PDF o Word. 1.5 Recursos Se presentan recursos a consultar para ahondar más en los temas presentados. La guía definitiva de RMarkdown RMarkdown Definitive Guide, para consultas sobre documentos rmakrdown y sus opciones y configuraciones. La guía definitiva de Bookdown Bookdown Guide. Este recurso cubre más sobre rmarkdown y expande sus funciones para la creación de libros. Referencias "],
["basico.html", "Capítulo 2 Funcionamiento básico de R 2.1 Operaciones básicas 2.2 Crear objetos 2.3 Vectores 2.4 Matrices 2.5 DataFrames, listas y tibbles 2.6 Verificando objetos 2.7 Guardando el espacio de trabajo 2.8 Importando/cargando datos 2.9 Exportando datos 2.10 Inspeccionando los datos 2.11 Descripciones generales (globales) 2.12 Recursos", " Capítulo 2 Funcionamiento básico de R En este capitulo se va a dar una introducción al funcionamiento básico de R (R Core Team, 2019), incluyendo el uso de R como una calculadora (consola), creación de objetos, y los tipos principales objetos que se utilizan en R, así como importar y exportar datos, y unas inspecciones generales de los datos. Se van a usar, aunque poco en este capitulo, funciones de los paquetes: library(rio) library(skimr) library(psych) library(DescTools) library(tidyverse) library(summarytools) 2.1 Operaciones básicas R puede funcionar como una calculadora básica, donde es posible realizar operaciones aritméticas sencillas. Los nombres de las funciones están en ingles (ej: sqrt para raíz cuadrada, round para redondeo, etc.). Como cualquier otro programa, si se va a utilizar operaciones con ángulos (ej: cos, tan, etc.), los ángulos tienen que darse en radianes, y el resultado va a estar en radianes. 1+2 ## [1] 3 1-2 ## [1] -1 1*2 ## [1] 2 1/2 ## [1] 0.5 sqrt(125) ## [1] 11.18034 2.2 Crear objetos Objetos se pueden crear usando los operadores &lt;- o =. Al crear un objeto este no se despliega en la consola a menos que uno lo llame directamente o que a la hora de crearlo sea encerrado con paréntesis redondos (). La idea de generar objetos es básica para los lenguajes de programación. Los objetos que se crean pueden ser reutilizados después de ser creados. Si se desean actualizar las operaciones o funciones que dependen de un objeto, solo se cambia el objeto una vez, y el resto se actualiza cuando se vuelve a correr. Aquí se están generando los objetos x, y, y z, donde x se imprime hasta llamarlo, y se imprime al guardarlo por estar encerrado en paréntesis, y z es función de x y y. x &lt;- 1 (y = 2) ## [1] 2 x ## [1] 1 x + y ## [1] 3 z = x + y 2.3 Vectores Los vectores son unidimensionales y deben ser (contener elementos) del mismo tipo. Aquí se muestran los diferentes tipos, y como crearlos. Los más importantes tipos son Numéricos, Texto, y Factores (tipo especial en R). 2.3.1 Numéricos Se pueden crear vectores numéricos a partir de datos puntuales, sin ningún orden, usando la función c(), y separando las entradas (elementos) por medio de comas ,. x &lt;- c(1,2,3,4,5) y &lt;- c(6,7,8,9,10) O se pueden crear vectores en secuencia (seq(from = , to = , by =, o length.out = )) o de valores repetidos (rep()). Crear vectores de valores repetidos no aplica únicamente para datos numéricos. En seq se definen los argumentos from: valor inicial, to: valor final, y by: el intervalo, o length.out: la cantidad de elementos que quiero. En rep se define lo que se quiere repetir, y el numero de veces a repetir. (f = 1:30) ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 ## [26] 26 27 28 29 30 (t1 = seq(from = 0, to = 20, by = .2)) ## [1] 0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 1.6 1.8 2.0 2.2 2.4 2.6 2.8 ## [16] 3.0 3.2 3.4 3.6 3.8 4.0 4.2 4.4 4.6 4.8 5.0 5.2 5.4 5.6 5.8 ## [31] 6.0 6.2 6.4 6.6 6.8 7.0 7.2 7.4 7.6 7.8 8.0 8.2 8.4 8.6 8.8 ## [46] 9.0 9.2 9.4 9.6 9.8 10.0 10.2 10.4 10.6 10.8 11.0 11.2 11.4 11.6 11.8 ## [61] 12.0 12.2 12.4 12.6 12.8 13.0 13.2 13.4 13.6 13.8 14.0 14.2 14.4 14.6 14.8 ## [76] 15.0 15.2 15.4 15.6 15.8 16.0 16.2 16.4 16.6 16.8 17.0 17.2 17.4 17.6 17.8 ## [91] 18.0 18.2 18.4 18.6 18.8 19.0 19.2 19.4 19.6 19.8 20.0 (t2 = seq(from = 0, to = 20, length.out = 11)) ## [1] 0 2 4 6 8 10 12 14 16 18 20 (u = rep(5,20)) ## [1] 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 rep(5:7,3) ## [1] 5 6 7 5 6 7 5 6 7 rep(5:7,each=3) ## [1] 5 5 5 6 6 6 7 7 7 2.3.2 Texto (string, character) Los vectores de texto son usualmente el precursor de vectores categóricos o factores. Se construyen de manera similar usando c(), pero cada entrada (elemento) va en comillas (doble &quot;&quot;, o sencilla ’’). z &lt;- &quot;pura vida&quot; z ## [1] &quot;pura vida&quot; dias &lt;- c(&quot;lunes&quot;,&quot;martes&quot;,&quot;miercoles&quot;,&quot;jueves&quot;,&quot;viernes&quot;) dias ## [1] &quot;lunes&quot; &quot;martes&quot; &quot;miercoles&quot; &quot;jueves&quot; &quot;viernes&quot; 2.3.3 Categóricos (factores) Los vectores para datos categóricos en R son llamados factores, y estos factores van a contener niveles o clases (levels). Este tipo de vector es muy utilizado en diversos análisis. El primer tipo es un factor nominal (sin orden en los niveles/clases). Aquí se esta usando el vector de texto creado anteriormente, y simplemente se convierte a factor. La función as_factor es del paquete forcats, que se carga al cargar el tidyverse. Existe una función básica as.factor; los comportamientos son un poco diferentes, siendo la principal diferencia que as_factor ordena los niveles de acuerdo al orden de aparición, mientras que as.factor ordena los niveles de manera alfabética. dias.f1 = as_factor(dias) dias.f1 ## [1] lunes martes miercoles jueves viernes ## Levels: lunes martes miercoles jueves viernes dias.f2 = as.factor(dias) dias.f2 ## [1] lunes martes miercoles jueves viernes ## Levels: jueves lunes martes miercoles viernes Factores ordinales pueden crearse usando la función básica factor, primero con el vector de datos (usualmente texto), agregando el argumento ordered = TRUE. Ademas, hay que especificar los niveles en el orden deseado con el argumento levels, donde van a ir de menor a mayor. ordenado = factor(c(&#39;Bajo&#39;,&#39;Alto&#39;,&#39;Alto&#39;,&#39;Medio&#39;,&#39;Medio&#39;,&#39;Bajo&#39;,&#39;Alto&#39;), ordered = T, levels = c(&#39;Bajo&#39;,&#39;Medio&#39;,&#39;Alto&#39;)) ordenado ## [1] Bajo Alto Alto Medio Medio Bajo Alto ## Levels: Bajo &lt; Medio &lt; Alto 2.4 Matrices Las matrices son representaciones multidimensionales de datos numéricos. La función para construirlas es matrix, donde se especifican los datos y el numero de filas o columnas. Por defecto inserta los datos por columna, si se quieren meter por fila se debe usar byrow = TRUE. Adicionalmente se le pueden agregar nombres a las filas y columnas con el argumento dimnames. matrix(data = 1:15, nrow = 3) ## [,1] [,2] [,3] [,4] [,5] ## [1,] 1 4 7 10 13 ## [2,] 2 5 8 11 14 ## [3,] 3 6 9 12 15 matrix(data = 1:15, nrow = 3, byrow = T) ## [,1] [,2] [,3] [,4] [,5] ## [1,] 1 2 3 4 5 ## [2,] 6 7 8 9 10 ## [3,] 11 12 13 14 15 matrix(data = 1:15, nrow = 3, byrow = T, dimnames = list(Filas = letters[1:3], Columnas = LETTERS[1:5])) ## Columnas ## Filas A B C D E ## a 1 2 3 4 5 ## b 6 7 8 9 10 ## c 11 12 13 14 15 2.5 DataFrames, listas y tibbles Los vectores son unidimensionales y pueden almacenar datos (elementos) de un solo tipo. DataFrames, listas y tibbles son objetos que pueden almacenar más de 1 vector y los diferentes vectores pueden ser diferentes entre ellos. Esto es similar a una hoja de calculo donde cada columna es un vector. Para DataFrames los contenidos pueden ser únicamente vectores de la misma longitud. Se crea usando la función data.frame, con los argumentos siendo los vectores, que van a pasar a ser las columnas. La función names brinda los nombres de las columnas, y a su vez se puede usar para renombrar a las columnas. DF = data.frame(Visitas = x, Revision = y, Dias = dias) DF ## # A tibble: 5 x 3 ## Visitas Revision Dias ## &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; ## 1 1 6 lunes ## 2 2 7 martes ## 3 3 8 miercoles ## 4 4 9 jueves ## 5 5 10 viernes names(DF) ## [1] &quot;Visitas&quot; &quot;Revision&quot; &quot;Dias&quot; names(DF) = c(&quot;Experimento&quot;, &quot;Valores&quot;, &quot;Tiempo&quot;) DF ## # A tibble: 5 x 3 ## Experimento Valores Tiempo ## &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; ## 1 1 6 lunes ## 2 2 7 martes ## 3 3 8 miercoles ## 4 4 9 jueves ## 5 5 10 viernes Para listas los contenidos pueden ser cualquier objeto y de cualquier dimensión. Muchos de los resultados de funciones en R son listas. Estas se crean con la función list. lst = list(Exp = x, Val = y, Dias = dias, Data = DF) lst ## $Exp ## [1] 1 2 3 4 5 ## ## $Val ## [1] 6 7 8 9 10 ## ## $Dias ## [1] &quot;lunes&quot; &quot;martes&quot; &quot;miercoles&quot; &quot;jueves&quot; &quot;viernes&quot; ## ## $Data ## Experimento Valores Tiempo ## 1 1 6 lunes ## 2 2 7 martes ## 3 3 8 miercoles ## 4 4 9 jueves ## 5 5 10 viernes Tibbles son un tipo especial de DataFrame, donde la principal diferencia es que pueden tener un contenido (columna) que puede ser una lista y esto puede brindar muchas facilidades a la hora de manipular y analizar los datos. Ademas no fuerza a datos de texto a factores y en la consola se despliega de manera más amigable. tb = tibble(Visitas = x, Revision = y, Dias = dias, Extra = map(6:10, ~rnorm(.x))) tb ## # A tibble: 5 x 4 ## Visitas Revision Dias Extra ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;list&gt; ## 1 1 6 lunes &lt;dbl [6]&gt; ## 2 2 7 martes &lt;dbl [7]&gt; ## 3 3 8 miercoles &lt;dbl [8]&gt; ## 4 4 9 jueves &lt;dbl [9]&gt; ## 5 5 10 viernes &lt;dbl [10]&gt; 2.6 Verificando objetos Hay funciones para verificar el tipo de objeto (mode, is, class), comprobar si es de un tipo en especifico (is.*) y cambiar de un tipo a otro (as.*). Con la funcione methods(class = *) se pueden obtener los diferentes métodos o funciones disponibles para ese tipo de objeto (va a depender de los paquetes cargados). mode(x) ## [1] &quot;numeric&quot; is(x) ## [1] &quot;numeric&quot; &quot;vector&quot; &quot;index&quot; &quot;replValue&quot; ## [5] &quot;numLike&quot; &quot;number&quot; &quot;atomicVector&quot; &quot;numericVector&quot; ## [9] &quot;EnumerationValue&quot; &quot;replValueSp&quot; &quot;Mnumeric&quot; class(x) ## [1] &quot;numeric&quot; x &lt;- c(1, 2, 3, 4, 5, 6) methods(class = class(x)) ## [1] [ [&lt;- all.equal Arith as_factor ## [6] as_mapper as.data.frame as.Date as.POSIXct as.POSIXlt ## [11] as.raster as.yearmon as.yearqtr cbind2 coerce ## [16] coerce&lt;- Compare Desc full_seq get_skimmers ## [21] Logic months Ops rbind2 recode ## [26] rescale scale_type ## see &#39;?methods&#39; for accessing help and source code Aquí se agrega un elemento de texto a un vector numérico, R por defecto lo va a cambiar a texto, que se revisa con mode(x), y específicamente si es numérico con is.numeric(x). Para cambiarlo de nuevo a numérico se usa as.numeric(x). x[6]&lt;-&quot;NA&quot; x ## [1] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; &quot;5&quot; &quot;NA&quot; mode(x) ## [1] &quot;character&quot; is.numeric(x) ## [1] FALSE x2 &lt;- as.numeric(x) x2 ## [1] 1 2 3 4 5 NA 2.7 Guardando el espacio de trabajo Una vez se han generado objetos estos pueden ser guardados para compartir con otra gente o cargar en otra sesión para no tener que volver a generarlos. save.image(&quot;introR.rdata&quot;) load(&quot;introR.rdata&quot;) 2.8 Importando/cargando datos La mejor opción para importar datos es usar import del paquete rio (Chan &amp; Leeper, 2018). Uno simplemente ocupa darle la dirección del archivo que se quiere importar y la función inteligentemente escoge la forma para importarlo. Si se quiere importar un documento de Excel que contiene varias hojas, se usa import_list, donde el resultado es una lista con las diferentes hojas. El argumento setclass = 'tibble' se usa para definir que el objeto creado sea un tibble y no un DataFrame. data(&quot;airquality&quot;) head(airquality) ## # A tibble: 6 x 6 ## Ozone Solar.R Wind Temp Month Day ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 41 190 7.4 67 5 1 ## 2 36 118 8 72 5 2 ## 3 12 149 12.6 74 5 3 ## 4 18 313 11.5 62 5 4 ## 5 NA NA 14.3 56 5 5 ## 6 28 NA 14.9 66 5 6 # dat1 &lt;- import(file.choose(), setclass = &#39;tibble&#39;) dat1 &lt;- import(&quot;data/LungCapData2.csv&quot;, setclass = &#39;tibble&#39;) titanic &lt;- import(&quot;data/titanic.csv&quot;, setclass = &#39;tibble&#39;) lista_datos = import_list(&#39;data/datasets.xlsx&#39;, setclass = &#39;tibble&#39;) 2.9 Exportando datos Usar export del paquete rio. Se pueden exportar diferentes formatos. Si se exporta una lista con nombres a un Excel, cada entrada de la lista aparece en una hoja diferente. export(airquality, &quot;data/airquality.csv&quot;) export(list(airquality = airquality, mpg = mpg, gss = gss_cat), &quot;data/datasets.xlsx&quot;) 2.10 Inspeccionando los datos Aquí se muestran funciones básicas para explorar los datos y como acceder a ciertos datos en especifico. Dentro de las funciones más usadas están: head: Muestra las primeras 6 filas o elementos de un DataFrame o vector (no es necesario usar esto con un Tibble ya que el Tibble muestra las primeras 10 filas por defecto) tail: Muestra las ultimas 6 filas o elementos dim: Muestra la dimensión del objeto summary: Dependiendo del objeto esta función muestra diferentes cosas, en general siendo un resumen de los contenidos del objeto str: Muestra la estructura de los datos, indicando numero de variables y observaciones, así como el tipo de variables (de nuevo esto lo muestra un Tibble por defecto) names: Muestra los nombres de los objetos; en el caso de DataFrames y tibbles los nombres de las columnas, en el caso de una lista los nombres de los objetos dentro de la lista head(dat1) ## # A tibble: 6 x 5 ## Age LungCap Height Gender Smoke ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 9 3.12 57 female no ## 2 8 3.17 67.5 female no ## 3 7 3.16 54.5 female no ## 4 9 2.67 53 male no ## 5 9 3.68 57 male no ## 6 8 5.01 61 female no tail(dat1) ## # A tibble: 6 x 5 ## Age LungCap Height Gender Smoke ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 16 12.6 72 male yes ## 2 16 10.8 67 male yes ## 3 15 9.18 68 male yes ## 4 18 6.56 60 female no ## 5 16 6.38 63 female yes ## 6 15 7.63 66.5 female no dim(dat1) ## [1] 654 5 summary(dat1) ## Age LungCap Height Gender ## Min. : 3.000 Min. : 0.373 Min. :46.00 Length:654 ## 1st Qu.: 8.000 1st Qu.: 3.943 1st Qu.:57.00 Class :character ## Median :10.000 Median : 5.643 Median :61.50 Mode :character ## Mean : 9.931 Mean : 5.910 Mean :61.14 ## 3rd Qu.:12.000 3rd Qu.: 7.356 3rd Qu.:65.50 ## Max. :19.000 Max. :15.379 Max. :74.00 ## Smoke ## Length:654 ## Class :character ## Mode :character ## ## ## str(dat1) ## tibble [654 × 5] (S3: tbl_df/tbl/data.frame) ## $ Age : int [1:654] 9 8 7 9 9 8 6 6 8 9 ... ## $ LungCap: num [1:654] 3.12 3.17 3.16 2.67 3.69 ... ## $ Height : num [1:654] 57 67.5 54.5 53 57 61 58 56 58.5 60 ... ## $ Gender : chr [1:654] &quot;female&quot; &quot;female&quot; &quot;female&quot; &quot;male&quot; ... ## $ Smoke : chr [1:654] &quot;no&quot; &quot;no&quot; &quot;no&quot; &quot;no&quot; ... names(dat1) ## [1] &quot;Age&quot; &quot;LungCap&quot; &quot;Height&quot; &quot;Gender&quot; &quot;Smoke&quot; Para acceder a elementos de un vector (de cualquier tipo) se usan los corchetes cuadrados [], con el numero de la posición del elemento dentro de estos. La posición se puede especificar por medio de un valor único, un rango (inicio:fin), o por medio de un vector de posiciones usando c(). t1[3:5] ## [1] 0.4 0.6 0.8 dias[2] ## [1] &quot;martes&quot; ordenado[c(2,5,7)] ## [1] Alto Medio Alto ## Levels: Bajo &lt; Medio &lt; Alto Para acceder a elementos de una lista se usa el corchete sencillo para extraer el elemento como tal, o doble corchete para extraer los contenido del elemento. lst[1] ## $Exp ## [1] 1 2 3 4 5 lst[[1]] ## [1] 1 2 3 4 5 lst[[1]][3] ## [1] 3 Para acceder a los datos de una matriz o tabla (DataFrame o tibble) se usan los corchetes cuadrados [,], donde el espacio antes de la coma se usa para seleccionar filas y el espacio después para seleccionar columnas (de acuerdo al numero, o al nombre para tablas). En tablas, para acceder a una columna como vector se pueden usar los dobles corchetes [[]] o el operados $. dat1[,1] # primer columna ## # A tibble: 654 x 1 ## Age ## &lt;int&gt; ## 1 9 ## 2 8 ## 3 7 ## 4 9 ## 5 9 ## 6 8 ## 7 6 ## 8 6 ## 9 8 ## 10 9 ## # … with 644 more rows dat1[1,] # primer fila ## # A tibble: 1 x 5 ## Age LungCap Height Gender Smoke ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 9 3.12 57 female no dat1[1,1] # elemento en primer fila y columna ## # A tibble: 1 x 1 ## Age ## &lt;int&gt; ## 1 9 dat1[,1:3] # columnas de la 1 a la 3 ## # A tibble: 654 x 3 ## Age LungCap Height ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 9 3.12 57 ## 2 8 3.17 67.5 ## 3 7 3.16 54.5 ## 4 9 2.67 53 ## 5 9 3.68 57 ## 6 8 5.01 61 ## 7 6 3.76 58 ## 8 6 2.24 56 ## 9 8 3.96 58.5 ## 10 9 3.83 60 ## # … with 644 more rows dat1[,c(1,3,5)] # columnas 1, 3, y 5 ## # A tibble: 654 x 3 ## Age Height Smoke ## &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 9 57 no ## 2 8 67.5 no ## 3 7 54.5 no ## 4 9 53 no ## 5 9 57 no ## 6 8 61 no ## 7 6 58 no ## 8 6 56 no ## 9 8 58.5 no ## 10 9 60 no ## # … with 644 more rows dat1[,c(&quot;Age&quot;,&quot;Height&quot;)] # columnas por nombre ## # A tibble: 654 x 2 ## Age Height ## &lt;int&gt; &lt;dbl&gt; ## 1 9 57 ## 2 8 67.5 ## 3 7 54.5 ## 4 9 53 ## 5 9 57 ## 6 8 61 ## 7 6 58 ## 8 6 56 ## 9 8 58.5 ## 10 9 60 ## # … with 644 more rows head(dat1[[&quot;Age&quot;]]) # columna como vector ## [1] 9 8 7 9 9 8 head(dat1$Age) # columna como vector ## [1] 9 8 7 9 9 8 dat1[&quot;Age&quot;] # columna por nombre ## # A tibble: 654 x 1 ## Age ## &lt;int&gt; ## 1 9 ## 2 8 ## 3 7 ## 4 9 ## 5 9 ## 6 8 ## 7 6 ## 8 6 ## 9 8 ## 10 9 ## # … with 644 more rows Para columnas de tipo factor se pueden revisar los niveles con la función levels. Si una columna es de tipo texto y se quiere cambiar a factor se reescribe la columna (tabla$columna) por medio de la función factor. Ademas, si se requieren ordenar los niveles, estos se puede hacer especificando el orden deseado con el argumento levels, usando el nombre de los elementos en el vector. levels(dat1$Smoke) ## NULL dat1$Smoke = factor(dat1$Smoke,levels = c(&quot;yes&quot;,&quot;no&quot;)) # reordenar niveles levels(dat1$Smoke) ## [1] &quot;yes&quot; &quot;no&quot; summary(dat1) ## Age LungCap Height Gender Smoke ## Min. : 3.000 Min. : 0.373 Min. :46.00 Length:654 yes: 65 ## 1st Qu.: 8.000 1st Qu.: 3.943 1st Qu.:57.00 Class :character no :589 ## Median :10.000 Median : 5.643 Median :61.50 Mode :character ## Mean : 9.931 Mean : 5.910 Mean :61.14 ## 3rd Qu.:12.000 3rd Qu.: 7.356 3rd Qu.:65.50 ## Max. :19.000 Max. :15.379 Max. :74.00 2.11 Descripciones generales (globales) Se muestran varias funciones que generan un resumen general de un vector, o tabla dependiendo del tipo de variable presente. Estas funciones se encuentran en los paquetes skimr (Waring et al., 2019), psych (Revelle, 2020), DescTools (Signorell, 2020), y summarytools (Comtois, 2019). set.seed(101) myvector = rnorm(n = 60,mean = 30,sd = 8) skim(myvector) Tabla 2.1: Data summary Name myvector Number of rows 60 Number of columns 1 _______________________ Column type frequency: numeric 1 ________________________ Group variables None Variable type: numeric skim_variable n_missing complete_rate mean sd p0 p25 p50 p75 p100 hist data 0 1 29.11 7.42 11.45 24.06 29.78 34.57 41.42 ▂▅▇▇▆ describe(myvector) ## # A tibble: 1 x 13 ## vars n mean sd median trimmed mad min max range skew kurtosis ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 60 29.1 7.42 29.8 29.5 7.87 11.4 41.4 30.0 -0.499 -0.671 ## # … with 1 more variable: se &lt;dbl&gt; Desc(myvector) ## ------------------------------------------------------------------------------ ## myvector (numeric) ## ## length n NAs unique 0s mean meanCI ## 60 60 0 = n 0 29.10622 27.18840 ## 100.0% 0.0% 0.0% 31.02404 ## ## .05 .10 .25 median .75 .90 .95 ## 16.47568 18.28631 24.06407 29.78292 34.56941 37.43271 39.38988 ## ## range sd vcoef mad IQR skew kurt ## 29.97666 7.42400 0.25507 7.86821 10.50535 -0.49887 -0.67149 ## ## lowest : 11.44538, 13.41515, 13.59754, 16.62716, 18.12898 ## highest: 39.03847, 39.38978, 39.39173, 39.51883, 41.42204 dfSummary(myvector) %&gt;% view(method = &#39;render&#39;) Data Frame Summary myvector Dimensions: 60 x 1 Duplicates: 0 No Variable Stats / Values Freqs (% of Valid) Valid Missing 1 myvector [numeric] Mean (sd) : 29.1 (7.4) min 60 distinct values 60 (100%) 0 (0%) Generated by summarytools 0.9.4 (R version 3.6.0)2020-05-06 skim(airquality) Tabla 2.2: Data summary Name airquality Number of rows 153 Number of columns 6 _______________________ Column type frequency: numeric 6 ________________________ Group variables None Variable type: numeric skim_variable n_missing complete_rate mean sd p0 p25 p50 p75 p100 hist Ozone 37 0.76 42.13 32.99 1.0 18.00 31.5 63.25 168.0 ▇▃▂▁▁ Solar.R 7 0.95 185.93 90.06 7.0 115.75 205.0 258.75 334.0 ▅▃▅▇▅ Wind 0 1.00 9.96 3.52 1.7 7.40 9.7 11.50 20.7 ▂▇▇▃▁ Temp 0 1.00 77.88 9.47 56.0 72.00 79.0 85.00 97.0 ▂▃▇▇▃ Month 0 1.00 6.99 1.42 5.0 6.00 7.0 8.00 9.0 ▇▇▇▇▇ Day 0 1.00 15.80 8.86 1.0 8.00 16.0 23.00 31.0 ▇▇▇▇▆ describe(airquality) ## # A tibble: 6 x 13 ## vars n mean sd median trimmed mad min max range skew ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 116 42.1 33.0 31.5 37.8 25.9 1 168 167 1.21 ## 2 2 146 186. 90.1 205 190. 98.6 7 334 327 -0.419 ## 3 3 153 9.96 3.52 9.7 9.87 3.41 1.7 20.7 19 0.341 ## 4 4 153 77.9 9.47 79 78.3 8.90 56 97 41 -0.371 ## 5 5 153 6.99 1.42 7 6.99 1.48 5 9 4 -0.00234 ## 6 6 153 15.8 8.86 16 15.8 11.9 1 31 30 0.00260 ## # … with 2 more variables: kurtosis &lt;dbl&gt;, se &lt;dbl&gt; Desc(airquality) ## ------------------------------------------------------------------------------ ## Describe airquality (data.frame): ## ## data frame: 153 obs. of 6 variables ## 111 complete cases (72.5%) ## ## Nr ColName Class NAs Levels ## 1 Ozone integer 37 (24.2%) ## 2 Solar.R integer 7 (4.6%) ## 3 Wind numeric . ## 4 Temp integer . ## 5 Month integer . ## 6 Day integer . ## ## ## ------------------------------------------------------------------------------ ## 1 - Ozone (integer) ## ## length n NAs unique 0s mean meanCI ## 153 116 37 67 0 42.13 36.06 ## 75.8% 24.2% 0.0% 48.20 ## ## .05 .10 .25 median .75 .90 .95 ## 7.75 11.00 18.00 31.50 63.25 87.00 108.50 ## ## range sd vcoef mad IQR skew kurt ## 167.00 32.99 0.78 25.95 45.25 1.21 1.11 ## ## lowest : 1, 4, 6, 7 (3), 8 ## highest: 115, 118, 122, 135, 168 ## ------------------------------------------------------------------------------ ## 2 - Solar.R (integer) ## ## length n NAs unique 0s mean meanCI ## 153 146 7 117 0 185.93 171.20 ## 95.4% 4.6% 0.0% 200.66 ## ## .05 .10 .25 median .75 .90 .95 ## 24.25 47.50 115.75 205.00 258.75 288.50 311.50 ## ## range sd vcoef mad IQR skew kurt ## 327.00 90.06 0.48 98.59 143.00 -0.42 -1.00 ## ## lowest : 7, 8, 13, 14, 19 ## highest: 320, 322 (2), 323, 332, 334 ## ------------------------------------------------------------------------------ ## 3 - Wind (numeric) ## ## length n NAs unique 0s mean meanCI ## 153 153 0 31 0 9.96 9.39 ## 100.0% 0.0% 0.0% 10.52 ## ## .05 .10 .25 median .75 .90 .95 ## 4.60 5.82 7.40 9.70 11.50 14.90 15.50 ## ## range sd vcoef mad IQR skew kurt ## 19.00 3.52 0.35 3.41 4.10 0.34 0.03 ## ## lowest : 1.7, 2.3, 2.8, 3.4, 4.0 ## highest: 16.1, 16.6 (3), 18.4, 20.1, 20.7 ## ## heap(?): remarkable frequency (9.8%) for the mode(s) (= 11.5) ## ------------------------------------------------------------------------------ ## 4 - Temp (integer) ## ## length n NAs unique 0s mean meanCI ## 153 153 0 40 0 77.88 76.37 ## 100.0% 0.0% 0.0% 79.39 ## ## .05 .10 .25 median .75 .90 .95 ## 60.20 64.20 72.00 79.00 85.00 90.00 92.00 ## ## range sd vcoef mad IQR skew kurt ## 41.00 9.47 0.12 8.90 13.00 -0.37 -0.46 ## ## lowest : 56, 57 (3), 58 (2), 59 (2), 61 (3) ## highest: 92 (5), 93 (3), 94 (2), 96, 97 ## ------------------------------------------------------------------------------ ## 5 - Month (integer) ## ## length n NAs unique 0s mean meanCI ## 153 153 0 5 0 6.99 6.77 ## 100.0% 0.0% 0.0% 7.22 ## ## .05 .10 .25 median .75 .90 .95 ## 5.00 5.00 6.00 7.00 8.00 9.00 9.00 ## ## range sd vcoef mad IQR skew kurt ## 4.00 1.42 0.20 1.48 2.00 -0.00 -1.32 ## ## ## level freq perc cumfreq cumperc ## 1 5 31 20.3% 31 20.3% ## 2 6 30 19.6% 61 39.9% ## 3 7 31 20.3% 92 60.1% ## 4 8 31 20.3% 123 80.4% ## 5 9 30 19.6% 153 100.0% ## ## heap(?): remarkable frequency (20.3%) for the mode(s) (= 5, 7, 8) ## ------------------------------------------------------------------------------ ## 6 - Day (integer) ## ## length n NAs unique 0s mean meanCI ## 153 153 0 31 0 15.80 14.39 ## 100.0% 0.0% 0.0% 17.22 ## ## .05 .10 .25 median .75 .90 .95 ## 2.00 4.00 8.00 16.00 23.00 28.00 29.40 ## ## range sd vcoef mad IQR skew kurt ## 30.00 8.86 0.56 11.86 15.00 0.00 -1.22 ## ## lowest : 1 (5), 2 (5), 3 (5), 4 (5), 5 (5) ## highest: 27 (5), 28 (5), 29 (5), 30 (5), 31 (3) dfSummary(airquality) %&gt;% view(method = &#39;render&#39;) Data Frame Summary airquality Dimensions: 153 x 6 Duplicates: 0 No Variable Stats / Values Freqs (% of Valid) Valid Missing 1 Ozone [integer] Mean (sd) : 42.1 (33) min 67 distinct values 116 (75.82%) 37 (24.18%) 2 Solar.R [integer] Mean (sd) : 185.9 (90.1) min 117 distinct values 146 (95.42%) 7 (4.58%) 3 Wind [numeric] Mean (sd) : 10 (3.5) min 31 distinct values 153 (100%) 0 (0%) 4 Temp [integer] Mean (sd) : 77.9 (9.5) min 40 distinct values 153 (100%) 0 (0%) 5 Month [integer] Mean (sd) : 7 (1.4) min 5:31(20.3%)6:30(19.6%)7:31(20.3%)8:31(20.3%)9:30(19.6%) 153 (100%) 0 (0%) 6 Day [integer] Mean (sd) : 15.8 (8.9) min 31 distinct values 153 (100%) 0 (0%) Generated by summarytools 0.9.4 (R version 3.6.0)2020-05-06 2.12 Recursos Se presentan recursos a consultar para ahondar más en los temas presentados. Introducción a estadística con R Foundations of Statistics with R Referencias "],
["avanzado.html", "Capítulo 3 Funcionamiento avanzado de R 3.1 Operadores lógicos 3.2 Operador de secuencia (Pipe operator) 3.3 Resumen de variables 3.4 Selección y renombre de variables 3.5 Filtrado de observaciones 3.6 Orden de acuerdo a variables 3.7 Creación de variables 3.8 Conteo de variables cualitativas 3.9 Tabla interactiva 3.10 Datos relacionales 3.11 Datos ordenados (Tidy data) 3.12 Datos anidados (Nesting) 3.13 Recursos", " Capítulo 3 Funcionamiento avanzado de R En el capitulo anterior se mostraron de manera muy rápida las funciones básicas de R, esto porque de ahora en adelante se va a enfocar en el uso de funciones del tidyverse (Wickham et al., 2019). Este meta-paquete es uno que engloba a un montón de paquetes que se rigen bajo el paradigma de datos ordenados (tidy data). Datos ordenados quiere decir una observación por fila y cada variable en su columna. Lo que se cubre en este capitulo y más se puede encontrar en “R for Data Science” (Grolemund &amp; Wickham, 2016). En este capitulo se van a utilizar los siguientes paquetes: library(babynames) library(nycflights13) library(gapminder) library(DT) library(rio) library(tidyverse) Los tres primeros corresponden con conjuntos de datos. Así mismo se vuelven a importar los datos con que se venia trabajando: data(&quot;airquality&quot;) dat1 &lt;- import(&quot;data/LungCapData2.csv&quot;, setclass = &#39;tibble&#39;) titanic &lt;- import(&quot;data/titanic.csv&quot;, setclass = &#39;tibble&#39;) Los paquetes más usados e importantes del tidyverse son: dplyr: Manipulación de datos mediante selección, filtrado, creación, agrupamiento, arreglo y resumen de tablas tidyr: Convierte datos a ordenados y viceversa ggplot2: Paquete para crear gráficos de alta calidad y personalizables purrr: Brinda funciones para la racionero sobre vectores, listas y tablas forcats: Manipulación de datos categóricos (factores) stringr: Manipulación de datos de texto lubridate: Manipulación de fechas Un punto importante a destacar, es que en todas (sino la mayoría) de las funciones del tidyverse la tabla de datos es el primer argumento. 3.1 Operadores lógicos Operadores lógicos permiten hacer comparaciones o pruebas, donde usualmente el resultado es TRUE o FALSE. En términos numéricos TRUE equivale a 1 y FALSE a 0. Los operadores lógicos más usados son: &lt;, menor que &lt;=, menor o igual que ==, igual que !=, no igual que &gt;, mayor que &gt;=, mayor o igual que %in%, pertenencia Aquí se asigna 4 a x y se aplican varios de los operadores lógicos para cuestionar el contenido de el objeto x. x &lt;- 4 x == 4 ## [1] TRUE x != 4 ## [1] FALSE x &lt; 4 ## [1] FALSE x &lt;= 5 ## [1] TRUE Estos operadores se pueden usar igualmente en vectores. Recordando que el resultado de una operación lógica es TRUE o FALSE, el vector resultante es del tipo lógico. Si se desea acceder a los elementos que cumplen la condición hay que aplicar el vector lógico sobre el vector, donde va a extraer los elementos que coinciden con TRUE. Aquí se crea un vector numérico, y se tratan de extraer los valores menores a 70. Se muestra la forma básica de R (vector[condicion]) y una forma más directa e intuitiva que ofrece purrr. y &lt;- c(95, 90, 58, 87, 62, 75) y &lt; 70 ## [1] FALSE FALSE TRUE FALSE TRUE FALSE y[y &lt; 70] ## [1] 58 62 keep(y, ~.x &lt; 70) # purrr ## [1] 58 62 3.2 Operador de secuencia (Pipe operator) Uno de los operadores básicos en el tidyverse es el pipe operator (%&gt;%). Este permite que el resultado antes del operador sea la (primer) entrada de lo que se va a hacer después del operador (x %&gt;% f(y) es lo mismo que f(x,y)). El shortcut para escribirlo es: Mac: Cmd + Shift + M Windows: Ctrl + Shift + M La ventaja es que permite encadenar operaciones sin necesidad de salvar objetos intermedios y es más fácil de leer que encerrar operaciones una dentro de la otra. Se ejemplifica con un caso sencillo, donde se tiene un vector de errores y se quiere calcular el error cuadrático medio (RMSE por sus siglas en ingles). set.seed(26) e = runif(50,-10,10) round(sqrt(mean(e^2)),3) # forma clasica ## [1] 5.595 e %&gt;% .^2 %&gt;% mean() %&gt;% sqrt() %&gt;% round(3) # usando el operador ## [1] 5.595 Lo anterior se lee: agarre el vector e, eleve sus valores al cuadrado, después calcule la media, después sáquele la raíz y por ultimo redondeélo a 3 cifras. 3.3 Resumen de variables Para resumir datos la función principal es summarise, que colapsa una o varias columnas a un dato resumen. Muchas veces se tiene una variable agrupadora (factor) en los datos y se requiere calcular estadísticas por grupo, para esto se usa group_by junto con summarise. En group_by se pueden incluir más de una variable agrupadora. Funciones que ayudan a resumir datos son: first(n), el primer elemento del vector x last(x), el ultimo elemento del vector x nth(x, n), el elemento n del vector x n(), el numero de filas en una tabla u observaciones en un grupo n_distinct(x), el numero de valores únicos en el vector x dat1 %&gt;% group_by(Gender) %&gt;% summarise(mean(Age)) ## # A tibble: 2 x 2 ## Gender `mean(Age)` ## &lt;chr&gt; &lt;dbl&gt; ## 1 female 9.84 ## 2 male 10.0 dat1 %&gt;% group_by(Gender,Smoke) %&gt;% summarise(mean(Age)) ## # A tibble: 4 x 3 ## Gender Smoke `mean(Age)` ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 female no 9.37 ## 2 female yes 13.3 ## 3 male no 9.69 ## 4 male yes 13.9 dat1 %&gt;% group_by(Gender) %&gt;% summarise(N=n(), mean(Age), mean(Height), mean(LungCap)) ## # A tibble: 2 x 5 ## Gender N `mean(Age)` `mean(Height)` `mean(LungCap)` ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 female 318 9.84 60.2 5.35 ## 2 male 336 10.0 62.0 6.44 3.4 Selección y renombre de variables Para seleccionar columnas la función es select, la cual puede usar números o nombres y los nombres no tienen que llevar comillas. Esto también permite reordenar las columnas de una tabla. Para el caso de obtener una columna como vector se usa pull con el numero o nombre de la columna a jalar. Durante la selección se puede cambiar el nombre de la variable, o usando rename. Funciones que ayudan a seleccionar variables son: starts_with('X'), todas las columnas que empiezan con ‘X’, ends_with('X'), todas las columnas que terminan con ‘X’, contains('X'), todas las columnas que contienen ‘X’, matches('X'), todas las columnas que coinciden con ‘X’ Aquí se mezcla funciones de resumen y selección para crear resumen de las variables seleccionadas. dat1 %&gt;% group_by(Gender) %&gt;% select(Age,Height) %&gt;% summarise_all(mean) ## # A tibble: 2 x 3 ## Gender Age Height ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 female 9.84 60.2 ## 2 male 10.0 62.0 dat1 %&gt;% group_by(Gender) %&gt;% select(Age,Height) %&gt;% summarise_all(.funs = list(~mean(.), ~sd(.))) ## # A tibble: 2 x 5 ## Gender Age_mean Height_mean Age_sd Height_sd ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 female 9.84 60.2 2.93 4.79 ## 2 male 10.0 62.0 2.98 6.33 Aquí se muestra la selección de variables, que resulta en un reordenamiento de las mismas. Así mismo se puede deseleccionar lo que no se quiere, usando - para indicar las columnas que no se quieren. airquality %&gt;% select(Temp,Wind,Ozone) ## # A tibble: 153 x 3 ## Temp Wind Ozone ## &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 67 7.4 41 ## 2 72 8 36 ## 3 74 12.6 12 ## 4 62 11.5 18 ## 5 56 14.3 NA ## 6 66 14.9 28 ## 7 65 8.6 23 ## 8 59 13.8 19 ## 9 61 20.1 8 ## 10 69 8.6 NA ## # … with 143 more rows dat1 %&gt;% select(-Smoke) ## # A tibble: 654 x 4 ## Age LungCap Height Gender ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 9 3.12 57 female ## 2 8 3.17 67.5 female ## 3 7 3.16 54.5 female ## 4 9 2.67 53 male ## 5 9 3.68 57 male ## 6 8 5.01 61 female ## 7 6 3.76 58 female ## 8 6 2.24 56 female ## 9 8 3.96 58.5 female ## 10 9 3.83 60 female ## # … with 644 more rows dat1 %&gt;% pull(Age) ## [1] 9 8 7 9 9 8 6 6 8 9 6 8 8 8 8 7 5 6 9 9 5 5 4 7 9 ## [26] 3 9 5 8 9 5 9 8 7 5 8 9 8 8 8 9 8 5 8 5 9 7 8 6 8 ## [51] 5 9 9 8 6 9 9 7 4 8 8 8 6 4 8 6 9 7 5 9 8 8 9 9 9 ## [76] 7 5 5 9 6 7 6 8 8 7 8 7 9 5 9 9 9 7 8 8 9 9 9 7 8 ## [101] 8 7 9 4 9 6 8 6 7 7 8 7 7 7 7 8 7 5 8 7 9 7 7 6 8 ## [126] 8 8 9 7 8 9 8 8 9 8 6 6 8 9 5 7 9 6 9 9 9 6 8 9 8 ## [151] 8 9 9 9 7 8 6 9 9 9 7 8 5 8 9 6 9 6 8 5 7 7 4 9 8 ## [176] 9 9 9 5 9 7 6 9 9 9 7 5 8 9 7 9 8 9 6 6 8 9 5 6 6 ## [201] 9 7 9 8 5 7 6 9 7 9 9 8 9 7 9 4 9 5 8 9 8 3 9 8 6 ## [226] 9 8 8 7 6 8 9 4 7 8 8 9 6 8 6 8 9 8 7 9 8 7 9 8 9 ## [251] 6 8 9 8 9 9 8 7 5 7 8 9 9 6 8 7 9 7 7 5 9 9 8 8 9 ## [276] 6 7 5 9 5 7 6 8 7 8 4 8 5 8 7 7 9 9 8 9 6 8 9 4 6 ## [301] 7 9 8 6 8 7 5 8 7 11 10 14 11 11 12 10 11 10 14 13 14 12 12 10 13 ## [326] 10 11 10 11 10 13 14 11 10 11 13 10 10 12 10 10 10 11 11 11 10 11 11 13 13 ## [351] 11 11 14 11 10 10 10 14 13 10 14 10 11 13 12 13 10 13 11 14 11 13 11 11 10 ## [376] 11 11 10 11 13 12 10 10 14 11 10 11 10 11 13 13 10 11 11 12 10 10 11 10 11 ## [401] 14 13 12 11 11 11 14 12 10 12 11 10 11 13 10 10 11 13 10 11 10 13 11 10 11 ## [426] 11 14 11 13 11 11 10 13 10 13 10 12 10 14 12 10 11 14 12 10 10 10 10 12 13 ## [451] 11 12 11 12 11 11 12 12 13 11 12 10 12 13 10 12 10 12 10 11 10 12 14 10 10 ## [476] 12 10 10 13 12 12 11 13 12 10 11 11 13 12 13 13 10 12 12 14 11 10 13 11 11 ## [501] 13 12 10 10 12 13 11 10 11 11 11 11 11 14 12 13 13 10 12 10 10 12 11 12 11 ## [526] 11 12 12 14 11 10 11 12 13 12 11 11 11 14 11 13 12 10 12 13 10 10 10 10 14 ## [551] 12 11 11 12 14 14 10 11 11 10 10 12 12 11 12 10 12 13 10 12 10 13 12 10 12 ## [576] 10 11 12 11 12 10 13 12 11 11 11 11 12 14 11 11 12 14 11 13 11 10 13 12 11 ## [601] 13 14 10 11 11 15 15 18 19 19 16 17 15 15 15 15 15 19 18 16 17 16 15 15 15 ## [626] 18 17 15 17 17 16 17 15 15 16 16 15 18 15 16 17 16 16 15 18 15 16 17 16 16 ## [651] 15 18 16 15 3.4.1 select helpers Se muestran diferentes usos y resultados de usar select helpers para facilidad de selección de columnas que cumplan con ciertos criterios. A su vez, se ejemplifica el renombrar las columnas durante la selección o usando rename (nuevo_nombre = nombre_actual). Un operador especial es everything() que selecciona todo; esto es útil cuando se quiere reordenar y poner una o varias columnas de primero y después el resto sin tener que escribir todos los nombres. select(storms, name:pressure) # columnas desde name hasta pressure ## # A tibble: 10,010 x 11 ## name year month day hour lat long status category wind pressure ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;ord&gt; &lt;int&gt; &lt;int&gt; ## 1 Amy 1975 6 27 0 27.5 -79 tropical d… -1 25 1013 ## 2 Amy 1975 6 27 6 28.5 -79 tropical d… -1 25 1013 ## 3 Amy 1975 6 27 12 29.5 -79 tropical d… -1 25 1013 ## 4 Amy 1975 6 27 18 30.5 -79 tropical d… -1 25 1013 ## 5 Amy 1975 6 28 0 31.5 -78.8 tropical d… -1 25 1012 ## 6 Amy 1975 6 28 6 32.4 -78.7 tropical d… -1 25 1012 ## 7 Amy 1975 6 28 12 33.3 -78 tropical d… -1 25 1011 ## 8 Amy 1975 6 28 18 34 -77 tropical d… -1 30 1006 ## 9 Amy 1975 6 29 0 34.4 -75.8 tropical s… 0 35 1004 ## 10 Amy 1975 6 29 6 34 -74.8 tropical s… 0 40 1002 ## # … with 10,000 more rows storms %&gt;% select(-c(name, pressure)) # columnas menos name y pressure ## # A tibble: 10,010 x 11 ## year month day hour lat long status category wind ts_diameter ## &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;ord&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1975 6 27 0 27.5 -79 tropi… -1 25 NA ## 2 1975 6 27 6 28.5 -79 tropi… -1 25 NA ## 3 1975 6 27 12 29.5 -79 tropi… -1 25 NA ## 4 1975 6 27 18 30.5 -79 tropi… -1 25 NA ## 5 1975 6 28 0 31.5 -78.8 tropi… -1 25 NA ## 6 1975 6 28 6 32.4 -78.7 tropi… -1 25 NA ## 7 1975 6 28 12 33.3 -78 tropi… -1 25 NA ## 8 1975 6 28 18 34 -77 tropi… -1 30 NA ## 9 1975 6 29 0 34.4 -75.8 tropi… 0 35 NA ## 10 1975 6 29 6 34 -74.8 tropi… 0 40 NA ## # … with 10,000 more rows, and 1 more variable: hu_diameter &lt;dbl&gt; iris %&gt;% select(starts_with(&quot;Sepal&quot;)) # columnas que empiezan con &#39;Sepal&#39; ## # A tibble: 150 x 2 ## Sepal.Length Sepal.Width ## &lt;dbl&gt; &lt;dbl&gt; ## 1 5.1 3.5 ## 2 4.9 3 ## 3 4.7 3.2 ## 4 4.6 3.1 ## 5 5 3.6 ## 6 5.4 3.9 ## 7 4.6 3.4 ## 8 5 3.4 ## 9 4.4 2.9 ## 10 4.9 3.1 ## # … with 140 more rows iris %&gt;% select(ends_with(&quot;Width&quot;)) # columnas que terminan con &#39;Width&#39; ## # A tibble: 150 x 2 ## Sepal.Width Petal.Width ## &lt;dbl&gt; &lt;dbl&gt; ## 1 3.5 0.2 ## 2 3 0.2 ## 3 3.2 0.2 ## 4 3.1 0.2 ## 5 3.6 0.2 ## 6 3.9 0.4 ## 7 3.4 0.3 ## 8 3.4 0.2 ## 9 2.9 0.2 ## 10 3.1 0.1 ## # … with 140 more rows storms %&gt;% select(contains(&quot;d&quot;)) # columnas que contienen &#39;d&#39; ## # A tibble: 10,010 x 4 ## day wind ts_diameter hu_diameter ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 27 25 NA NA ## 2 27 25 NA NA ## 3 27 25 NA NA ## 4 27 25 NA NA ## 5 28 25 NA NA ## 6 28 25 NA NA ## 7 28 25 NA NA ## 8 28 30 NA NA ## 9 29 35 NA NA ## 10 29 40 NA NA ## # … with 10,000 more rows iris %&gt;% select(Especie = Species, everything()) # renombrar seleccion y seleccionar el resto ## # A tibble: 150 x 5 ## Especie Sepal.Length Sepal.Width Petal.Length Petal.Width ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 setosa 5.1 3.5 1.4 0.2 ## 2 setosa 4.9 3 1.4 0.2 ## 3 setosa 4.7 3.2 1.3 0.2 ## 4 setosa 4.6 3.1 1.5 0.2 ## 5 setosa 5 3.6 1.4 0.2 ## 6 setosa 5.4 3.9 1.7 0.4 ## 7 setosa 4.6 3.4 1.4 0.3 ## 8 setosa 5 3.4 1.5 0.2 ## 9 setosa 4.4 2.9 1.4 0.2 ## 10 setosa 4.9 3.1 1.5 0.1 ## # … with 140 more rows iris %&gt;% rename(Especie = Species) # renombrar columna ## # A tibble: 150 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Especie ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa ## 7 4.6 3.4 1.4 0.3 setosa ## 8 5 3.4 1.5 0.2 setosa ## 9 4.4 2.9 1.4 0.2 setosa ## 10 4.9 3.1 1.5 0.1 setosa ## # … with 140 more rows 3.5 Filtrado de observaciones Para filtrar observaciones de acuerdo a uno a varios criterios se usa la función filter, así como operadores lógicos y funciones auxiliares. Funciones que ayudan a filtrar observaciones son las mismas de los Operadores lógicos. Dos de las funciones auxiliares más útiles son: between(x,left,right) que filtra observaciones para la variable x que se encuentren entre left (limite inferior) y right (limite superior); esta es más útil para variables numéricas, x %in% c(a,b,c) que filtra observaciones para la variable x que se encuentren en el vector c(a,b,c); esta es más útil para variables de texto o factor Se muestran diferentes ejemplos de como filtrar observaciones. Cuando se requiere que una observación cumpla varios criterios, estas condiciones se pueden separar por medio de comas (,), que es lo mismo que usar el operador lógico &amp;. Si se requiere una u otra condición se puede usar el operador lógico |, pero en ese caso y dependiendo de lo deseado es mejor usar between() o %in%. filter(airquality,Temp &gt; 85) ## # A tibble: 34 x 6 ## Ozone Solar.R Wind Temp Month Day ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 NA 273 6.9 87 6 8 ## 2 71 291 13.8 90 6 9 ## 3 39 323 11.5 87 6 10 ## 4 NA 259 10.9 93 6 11 ## 5 NA 250 9.2 92 6 12 ## 6 77 276 5.1 88 7 7 ## 7 97 267 6.3 92 7 8 ## 8 97 272 5.7 92 7 9 ## 9 85 175 7.4 89 7 10 ## 10 NA 291 14.9 91 7 14 ## # … with 24 more rows airquality %&gt;% filter(Temp &gt; 85) ## # A tibble: 34 x 6 ## Ozone Solar.R Wind Temp Month Day ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 NA 273 6.9 87 6 8 ## 2 71 291 13.8 90 6 9 ## 3 39 323 11.5 87 6 10 ## 4 NA 259 10.9 93 6 11 ## 5 NA 250 9.2 92 6 12 ## 6 77 276 5.1 88 7 7 ## 7 97 267 6.3 92 7 8 ## 8 97 272 5.7 92 7 9 ## 9 85 175 7.4 89 7 10 ## 10 NA 291 14.9 91 7 14 ## # … with 24 more rows airquality %&gt;% filter(Temp &gt; 75, Wind &gt; 10) ## # A tibble: 38 x 6 ## Ozone Solar.R Wind Temp Month Day ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 45 252 14.9 81 5 29 ## 2 NA 264 14.3 79 6 6 ## 3 71 291 13.8 90 6 9 ## 4 39 323 11.5 87 6 10 ## 5 NA 259 10.9 93 6 11 ## 6 NA 332 13.8 80 6 14 ## 7 NA 322 11.5 79 6 15 ## 8 21 191 14.9 77 6 16 ## 9 13 137 10.3 76 6 20 ## 10 NA 98 11.5 80 6 28 ## # … with 28 more rows airquality %&gt;% filter(between(Temp, 70, 80)) ## # A tibble: 53 x 6 ## Ozone Solar.R Wind Temp Month Day ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 36 118 8 72 5 2 ## 2 12 149 12.6 74 5 3 ## 3 7 NA 6.9 74 5 11 ## 4 11 320 16.6 73 5 22 ## 5 115 223 5.7 79 5 30 ## 6 37 279 7.4 76 5 31 ## 7 NA 286 8.6 78 6 1 ## 8 NA 287 9.7 74 6 2 ## 9 NA 264 14.3 79 6 6 ## 10 NA 332 13.8 80 6 14 ## # … with 43 more rows airquality %&gt;% filter(Temp &gt; 75, Wind &gt; 10) %&gt;% select(Ozone,Solar.R) ## # A tibble: 38 x 2 ## Ozone Solar.R ## &lt;int&gt; &lt;int&gt; ## 1 45 252 ## 2 NA 264 ## 3 71 291 ## 4 39 323 ## 5 NA 259 ## 6 NA 332 ## 7 NA 322 ## 8 21 191 ## 9 13 137 ## 10 NA 98 ## # … with 28 more rows babynames %&gt;% filter(name %in% c(&quot;Acura&quot;, &quot;Lexus&quot;, &quot;Yugo&quot;)) ## # A tibble: 57 x 5 ## year sex name n prop ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1990 F Lexus 36 0.0000175 ## 2 1990 M Lexus 12 0.00000558 ## 3 1991 F Lexus 102 0.0000502 ## 4 1991 M Lexus 16 0.00000755 ## 5 1992 F Lexus 193 0.0000963 ## 6 1992 M Lexus 25 0.0000119 ## 7 1993 F Lexus 285 0.000145 ## 8 1993 M Lexus 30 0.0000145 ## 9 1994 F Lexus 381 0.000195 ## 10 1994 F Acura 6 0.00000308 ## # … with 47 more rows 3.6 Orden de acuerdo a variables arrange se usa para ordenar los datos de acuerdo a una o más variables, donde por defecto lo hace de manera ascendente, para ordenarlos de manera descendente se encierra la variable dentro de desc(var). Si se ordena por una variable numérica se hará de menor a mayor o viceversa, si se ordena por una variable factor se hará de acuerdo al orden de los niveles del factor, y si se ordena por una variable de texto se hará por orden alfabético. airquality %&gt;% arrange(Temp) ## # A tibble: 153 x 6 ## Ozone Solar.R Wind Temp Month Day ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 NA NA 14.3 56 5 5 ## 2 6 78 18.4 57 5 18 ## 3 NA 66 16.6 57 5 25 ## 4 NA NA 8 57 5 27 ## 5 18 65 13.2 58 5 15 ## 6 NA 266 14.9 58 5 26 ## 7 19 99 13.8 59 5 8 ## 8 1 8 9.7 59 5 21 ## 9 8 19 20.1 61 5 9 ## 10 4 25 9.7 61 5 23 ## # … with 143 more rows airquality %&gt;% arrange(desc(Temp)) ## # A tibble: 153 x 6 ## Ozone Solar.R Wind Temp Month Day ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 76 203 9.7 97 8 28 ## 2 84 237 6.3 96 8 30 ## 3 118 225 2.3 94 8 29 ## 4 85 188 6.3 94 8 31 ## 5 NA 259 10.9 93 6 11 ## 6 73 183 2.8 93 9 3 ## 7 91 189 4.6 93 9 4 ## 8 NA 250 9.2 92 6 12 ## 9 97 267 6.3 92 7 8 ## 10 97 272 5.7 92 7 9 ## # … with 143 more rows gss_cat %&gt;% arrange(marital) ## # A tibble: 21,483 x 9 ## year marital age race rincome partyid relig denom tvhours ## &lt;int&gt; &lt;fct&gt; &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; ## 1 2000 No answ… 28 Other $10000 - 1… Ind,near dem Buddhi… Not appl… 2 ## 2 2006 No answ… NA White Not applic… Strong repu… Protes… Other NA ## 3 2006 No answ… NA White No answer Strong repu… None Not appl… 2 ## 4 2006 No answ… 63 White No answer Strong demo… None Not appl… NA ## 5 2006 No answ… 40 Other $20000 - 2… Not str dem… Protes… No denom… NA ## 6 2006 No answ… 45 White No answer No answer No ans… No answer NA ## 7 2006 No answ… NA White No answer No answer No ans… No answer NA ## 8 2008 No answ… 62 White Not applic… Strong demo… Protes… Episcopal NA ## 9 2008 No answ… 43 White No answer Independent Christ… No denom… 1 ## 10 2008 No answ… 50 White No answer Ind,near dem Protes… Other 4 ## # … with 21,473 more rows 3.7 Creación de variables Para crear o modificar variables se usa mutate. Algunas veces se requiere o desea categorizar una variable continua de acuerdo a ciertos criterios o puntos de quiebre; lo anterior puede realizarse por medio de lo que se conoce como if statements, donde una función que realiza la misma tarea pero de forma más eficiente es case_when. En el primer ejemplo se trabaja con la tabla del titanic, donde se tienen varias variables como texto (‘Pclass’, ‘Survived’, ‘Sex’) y se quieren convertir a factor, por lo que simplemente se re-definen estas variables. Este cambio se puede ver con glimpse para el antes y después, donde el tipo de variable cambia. glimpse(titanic) ## Rows: 891 ## Columns: 12 ## $ PassengerId &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17… ## $ Survived &lt;int&gt; 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, … ## $ Pclass &lt;int&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, … ## $ Name &lt;chr&gt; &quot;Braund, Mr. Owen Harris&quot;, &quot;Cumings, Mrs. John Bradley (F… ## $ Sex &lt;chr&gt; &quot;male&quot;, &quot;female&quot;, &quot;female&quot;, &quot;female&quot;, &quot;male&quot;, &quot;male&quot;, &quot;ma… ## $ Age &lt;dbl&gt; 22, 38, 26, 35, 35, NA, 54, 2, 27, 14, 4, 58, 20, 39, 14,… ## $ SibSp &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, … ## $ Parch &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, … ## $ Ticket &lt;chr&gt; &quot;A/5 21171&quot;, &quot;PC 17599&quot;, &quot;STON/O2. 3101282&quot;, &quot;113803&quot;, &quot;3… ## $ Fare &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625… ## $ Cabin &lt;chr&gt; &quot;&quot;, &quot;C85&quot;, &quot;&quot;, &quot;C123&quot;, &quot;&quot;, &quot;&quot;, &quot;E46&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;G6&quot;, &quot;… ## $ Embarked &lt;chr&gt; &quot;S&quot;, &quot;C&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;Q&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;C&quot;, &quot;S&quot;, &quot;S… titanic = titanic %&gt;% mutate(Pclass = as_factor(Pclass), Survived = as_factor(Survived), Sex = as_factor(Sex)) glimpse(titanic) ## Rows: 891 ## Columns: 12 ## $ PassengerId &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17… ## $ Survived &lt;fct&gt; 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, … ## $ Pclass &lt;fct&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, … ## $ Name &lt;chr&gt; &quot;Braund, Mr. Owen Harris&quot;, &quot;Cumings, Mrs. John Bradley (F… ## $ Sex &lt;fct&gt; male, female, female, female, male, male, male, male, fem… ## $ Age &lt;dbl&gt; 22, 38, 26, 35, 35, NA, 54, 2, 27, 14, 4, 58, 20, 39, 14,… ## $ SibSp &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, … ## $ Parch &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, … ## $ Ticket &lt;chr&gt; &quot;A/5 21171&quot;, &quot;PC 17599&quot;, &quot;STON/O2. 3101282&quot;, &quot;113803&quot;, &quot;3… ## $ Fare &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625… ## $ Cabin &lt;chr&gt; &quot;&quot;, &quot;C85&quot;, &quot;&quot;, &quot;C123&quot;, &quot;&quot;, &quot;&quot;, &quot;E46&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;G6&quot;, &quot;… ## $ Embarked &lt;chr&gt; &quot;S&quot;, &quot;C&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;Q&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;C&quot;, &quot;S&quot;, &quot;S… Se pueden crear variables nuevas que dependen de otra en la tabla. En el ejemplo se calcula la altura en centímetros a partir de la altura en pulgadas (1 pulgada = 2.54 cm) dat1 %&gt;% mutate(Altura = Height*2.54) ## # A tibble: 654 x 6 ## Age LungCap Height Gender Smoke Altura ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 9 3.12 57 female no 145. ## 2 8 3.17 67.5 female no 171. ## 3 7 3.16 54.5 female no 138. ## 4 9 2.67 53 male no 135. ## 5 9 3.68 57 male no 145. ## 6 8 5.01 61 female no 155. ## 7 6 3.76 58 female no 147. ## 8 6 2.24 56 female no 142. ## 9 8 3.96 58.5 female no 149. ## 10 9 3.83 60 female no 152. ## # … with 644 more rows En el tercer ejemplo se re define la variable ‘Month’ pasándola a factor donde se le cambian las etiquetas a algo más explicito. A su vez, se define una nueva variable condicionada en los valores de otra (sensación dependiendo del valor de la temperatura). Aquí se ejemplifica case_when, donde la estructura es: case_when(condicion1 ~ resultado1, condicion2 ~ resultado2, T ~ resultado3) airq = airquality %&gt;% mutate(Month = factor(Month, levels = 5:9, labels = c(&quot;Mayo&quot;, &quot;Junio&quot;, &quot;Julio&quot;, &quot;Agosto&quot;, &quot;Setiembre&quot;)), Sensation = case_when(Temp &lt; 60 ~ &#39;Cold&#39;, Temp &lt; 70 ~ &#39;Cool&#39;, Temp &lt; 85 ~ &#39;Warm&#39;, T ~ &#39;Hot&#39;) %&gt;% as.factor()) airq ## # A tibble: 153 x 7 ## Ozone Solar.R Wind Temp Month Day Sensation ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;fct&gt; &lt;int&gt; &lt;fct&gt; ## 1 41 190 7.4 67 Mayo 1 Cool ## 2 36 118 8 72 Mayo 2 Warm ## 3 12 149 12.6 74 Mayo 3 Warm ## 4 18 313 11.5 62 Mayo 4 Cool ## 5 NA NA 14.3 56 Mayo 5 Cold ## 6 28 NA 14.9 66 Mayo 6 Cool ## 7 23 299 8.6 65 Mayo 7 Cool ## 8 19 99 13.8 59 Mayo 8 Cold ## 9 8 19 20.1 61 Mayo 9 Cool ## 10 NA 194 8.6 69 Mayo 10 Cool ## # … with 143 more rows airquality %&gt;% as_tibble() ## # A tibble: 153 x 6 ## Ozone Solar.R Wind Temp Month Day ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 41 190 7.4 67 5 1 ## 2 36 118 8 72 5 2 ## 3 12 149 12.6 74 5 3 ## 4 18 313 11.5 62 5 4 ## 5 NA NA 14.3 56 5 5 ## 6 28 NA 14.9 66 5 6 ## 7 23 299 8.6 65 5 7 ## 8 19 99 13.8 59 5 8 ## 9 8 19 20.1 61 5 9 ## 10 NA 194 8.6 69 5 10 ## # … with 143 more rows 3.8 Conteo de variables cualitativas Para contar casos de variables discretas de una manera más expedita se puede usar count. Esta función realiza un agrupamiento (group_by) y resumen (summarise) a la vez. mpg %&gt;% count(manufacturer, year) ## # A tibble: 30 x 3 ## manufacturer year n ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 audi 1999 9 ## 2 audi 2008 9 ## 3 chevrolet 1999 7 ## 4 chevrolet 2008 12 ## 5 dodge 1999 16 ## 6 dodge 2008 21 ## 7 ford 1999 15 ## 8 ford 2008 10 ## 9 honda 1999 5 ## 10 honda 2008 4 ## # … with 20 more rows 3.9 Tabla interactiva Este es un ejemplo de como convertir una tabla estática a interactiva. Se usa el paquete DT (Xie, Cheng, &amp; Tan, 2019) y la función datatable, donde se pueden definir otra serie de argumentos. Tiene la ventaja de que para columnas numéricas puedo filtrar por medio de sliders, y para columnas de facto puedo seleccionar los niveles. airq %&gt;% DT::datatable(filter = &#39;top&#39;, options = list(dom = &#39;t&#39;)) 3.10 Datos relacionales En caso de tener datos de observaciones en diferentes tablas, estas se pueden unir para juntar los datos en una única tabla (uniones de transformación), o relacionar para filtrar los datos de una tabla con respecto a otra (uniones de filtro). De manera general las uniones se van a realizar de acuerdo a las columnas que tengan el mismo nombre en ambas tablas. Si se desea especificar una columna en especifico se usa el argumento by = 'col'. Si el nombre difiere entre las tablas se define la unión de acuerdo a by = c('a' = 'b'), donde 'a' corresponde con el nombre de la columna en la primer tabla, y 'b' corresponde con el nombre de la columna en la segunda tabla. Esto aplica para todas las funciones de unión (*_join). 3.10.1 Uniones de transformación Estas uniones agregan columnas de una tabla a otra. Un tipo de unión es left_join(x, y), donde se unen los datos de la tabla de la derecha (y) a la de la izquierda (x) de acuerdo a una columna en común, y manteniendo todas las observaciones de x. flights %&gt;% left_join(airlines) ## # A tibble: 336,776 x 20 ## year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 2013 1 1 517 515 2 830 819 ## 2 2013 1 1 533 529 4 850 830 ## 3 2013 1 1 542 540 2 923 850 ## 4 2013 1 1 544 545 -1 1004 1022 ## 5 2013 1 1 554 600 -6 812 837 ## 6 2013 1 1 554 558 -4 740 728 ## 7 2013 1 1 555 600 -5 913 854 ## 8 2013 1 1 557 600 -3 709 723 ## 9 2013 1 1 557 600 -3 838 846 ## 10 2013 1 1 558 600 -2 753 745 ## # … with 336,766 more rows, and 12 more variables: arr_delay &lt;dbl&gt;, ## # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, ## # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;, ## # name &lt;chr&gt; flights %&gt;% left_join(airports, c(&quot;dest&quot; = &quot;faa&quot;)) ## # A tibble: 336,776 x 26 ## year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 2013 1 1 517 515 2 830 819 ## 2 2013 1 1 533 529 4 850 830 ## 3 2013 1 1 542 540 2 923 850 ## 4 2013 1 1 544 545 -1 1004 1022 ## 5 2013 1 1 554 600 -6 812 837 ## 6 2013 1 1 554 558 -4 740 728 ## 7 2013 1 1 555 600 -5 913 854 ## 8 2013 1 1 557 600 -3 709 723 ## 9 2013 1 1 557 600 -3 838 846 ## 10 2013 1 1 558 600 -2 753 745 ## # … with 336,766 more rows, and 18 more variables: arr_delay &lt;dbl&gt;, ## # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, ## # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;, ## # name &lt;chr&gt;, lat &lt;dbl&gt;, lon &lt;dbl&gt;, alt &lt;int&gt;, tz &lt;dbl&gt;, dst &lt;chr&gt;, ## # tzone &lt;chr&gt; Otro tipo de unión es inner_join(x, y), donde se mantienen observaciones que se encuentran en ambas tablas. df1 &lt;- tibble(x = c(1, 2), y = 2:1) df2 &lt;- tibble(x = c(1, 3), a = 10, b = &quot;a&quot;) df1 %&gt;% inner_join(df2) ## # A tibble: 1 x 4 ## x y a b ## &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 1 2 10 a Otro tipo de unión es full_join(x, y), donde se mantienen todas las observaciones de ambas tablas. df1 %&gt;% full_join(df2) ## # A tibble: 3 x 4 ## x y a b ## &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 1 2 10 a ## 2 2 1 NA &lt;NA&gt; ## 3 3 NA 10 a 3.10.2 Uniones de filtro Se filtran las observaciones de una tabla de acuerdo a si coinciden o no con las de otra tabla. Un tipo es semi_join(x, y), donde se mantienen todas las observaciones de x que coinciden con observaciones en y, pero sin agregar columnas de y. El opuesto seria anti_join(x, y), donde se eliminan todas las observaciones de x que coinciden con observaciones en y, pero sin agregar columnas de y. df1 &lt;- tibble(x = c(1, 1, 3, 4), y = 1:4) df2 &lt;- tibble(x = c(1, 1, 2), z = c(&quot;a&quot;, &quot;b&quot;, &quot;a&quot;)) df1 %&gt;% semi_join(df2) ## # A tibble: 2 x 2 ## x y ## &lt;dbl&gt; &lt;int&gt; ## 1 1 1 ## 2 1 2 df1 %&gt;% anti_join(df2) ## # A tibble: 2 x 2 ## x y ## &lt;dbl&gt; &lt;int&gt; ## 1 3 3 ## 2 4 4 3.11 Datos ordenados (Tidy data) 3.11.1 Formatos largo y ancho Los datos ordenados corresponden con cada variable en su columna, cada fila corresponde con una observación, y en las celdas van los valores correspondientes. Esto corresponde con un formato largo (Figura 3.1). Figura 3.1: Estructura e ideología de datos ordenados (Grolemund &amp; Wickham, 2016). El ejemplo que se muestra a continuación no esta ordenado. La tabla tiene 3 variables pero no definidas correctamente. Una variable seria el país, otra seria el año (las columnas), y la tercera seria el numero de casos (las celdas). Esto se conoce como datos en formato ancho (En algunos casos puede ser necesario este formato, pero en la mayoría de ocasiones se prefiere el formato largo). casos &lt;- tribble( ~pais, ~&quot;2011&quot;, ~&quot;2012&quot;, ~&quot;2013&quot;, &quot;FR&quot;, 7000, 6900, 7000, &quot;DE&quot;, 5800, 6000, 6200, &quot;US&quot;, 15000, 14000, 13000 ) Para pasar de un formato ancho a largo, se usa la función pivot_longer(cols, names_to, values_to), donde cols son las columnas a agrupar en una sola, names_to es el nombre que se le va a dar a la columna que va a contener las columnas a agrupar, y values_to es el nombre que se le va a dar a la columna que va a contener los valores de las celdas y que corresponden con una variable. En este caso se van a agrupar todas las columnas menos el país, se le va a llamar ‘anho’ y lo que estaba en las celdas pasa a ser la columna ‘casos’. casos_tidy = casos %&gt;% pivot_longer(cols = -pais, names_to = &#39;anho&#39;, values_to = &#39;casos&#39;) casos_tidy ## # A tibble: 9 x 3 ## pais anho casos ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 FR 2011 7000 ## 2 FR 2012 6900 ## 3 FR 2013 7000 ## 4 DE 2011 5800 ## 5 DE 2012 6000 ## 6 DE 2013 6200 ## 7 US 2011 15000 ## 8 US 2012 14000 ## 9 US 2013 13000 De igual manera se puede volver al formato ancho con pivot_wider(id_cols, names_from, values_from), donde id_cols es una columna que identifica a cada observación, names_from es la columna a usar para nuevas columnas, y values_from es la columna donde están los valores a poner en las celdas. casos_tidy %&gt;% pivot_wider(id_cols = pais, names_from = anho, values_from = casos) ## # A tibble: 3 x 4 ## pais `2011` `2012` `2013` ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 FR 7000 6900 7000 ## 2 DE 5800 6000 6200 ## 3 US 15000 14000 13000 3.11.2 Separar y unir Otro caso de datos no ordenados es cuando una columna contiene 2 o más datos, por lo que es necesario separar cada dato en un su propia columna. En el ejemplo la columna ‘tasa’ corresponde con ‘casos’ y ‘poblacion’, por lo que hay que separarla. La función separate tiene el argumento into que corresponde con un vector de texto donde se deben definir los nombres de las columnas resultantes. casos2 &lt;- tribble( ~pais, ~anho, ~tasa, &quot;Afghanistan&quot;, 2001, &#39;745/19987071&#39;, &quot;Brasil&quot;, 2001, &#39;37737/172006362&#39;, &quot;China&quot;, 2001, &#39;212258/1272915272&#39; ) casos2 %&gt;% separate(tasa, into = c(&#39;casos&#39;, &#39;poblacion&#39;)) ## # A tibble: 3 x 4 ## pais anho casos poblacion ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Afghanistan 2001 745 19987071 ## 2 Brasil 2001 37737 172006362 ## 3 China 2001 212258 1272915272 Por defecto separate va a separar la columna en cualquier carácter especial que encuentre. Si se quiere especificar se puede usar el argumento sep. casos2 %&gt;% separate(tasa, into = c(&#39;casos&#39;, &#39;poblacion&#39;), sep = &#39;/&#39;) ## # A tibble: 3 x 4 ## pais anho casos poblacion ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Afghanistan 2001 745 19987071 ## 2 Brasil 2001 37737 172006362 ## 3 China 2001 212258 1272915272 El tipo de columna resultante de separate es de texto, pero en algunos casos ese no es el tipo deseado, por lo que se le puede pedir a la función que trate de adivinar y convertir las columnas al tipo correcto por medio del argumento convert = TRUE. casos2_sep = casos2 %&gt;% separate(tasa, into = c(&#39;casos&#39;, &#39;poblacion&#39;), convert = T) casos2_sep ## # A tibble: 3 x 4 ## pais anho casos poblacion ## &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 Afghanistan 2001 745 19987071 ## 2 Brasil 2001 37737 172006362 ## 3 China 2001 212258 1272915272 El unir columnas se hace por medio de unite, donde se le pasan, primero, el nombre de la nueva columna, y segundo los nombres de las columnas a unir, así como el carácter a usar para separar los datos. casos2_sep %&gt;% unite(tasa, casos, poblacion, sep = &#39;-&#39;) ## # A tibble: 3 x 3 ## pais anho tasa ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 Afghanistan 2001 745-19987071 ## 2 Brasil 2001 37737-172006362 ## 3 China 2001 212258-1272915272 3.12 Datos anidados (Nesting) Esta es una de las ventajas de los tibbles, donde una columna puede ser una lista, y como una lista puede contener lo que sea, esto permite flexibilidad en el análisis y manipulación de datos, como se va a ver en el próximo capitulo. Esto es muy usado junto con group_by, donde primero se agrupa la tabla y luego se crea una columna donde para cada grupo se va a tener su tabla única (las observaciones que corresponden con ese grupo) y diferente al resto. iris %&gt;% group_by(Species) %&gt;% nest() ## # A tibble: 3 x 2 ## Species data ## &lt;fct&gt; &lt;list&gt; ## 1 setosa &lt;tibble [50 × 4]&gt; ## 2 versicolor &lt;tibble [50 × 4]&gt; ## 3 virginica &lt;tibble [50 × 4]&gt; airq %&gt;% group_by(Month) %&gt;% nest() ## # A tibble: 5 x 2 ## Month data ## &lt;fct&gt; &lt;list&gt; ## 1 Mayo &lt;tibble [31 × 6]&gt; ## 2 Junio &lt;tibble [30 × 6]&gt; ## 3 Julio &lt;tibble [31 × 6]&gt; ## 4 Agosto &lt;tibble [31 × 6]&gt; ## 5 Setiembre &lt;tibble [30 × 6]&gt; 3.13 Recursos Se presentan recursos a consultar para ahondar más en los temas presentados. tidyverse DT ModernDive Libro que cubre diversos temas desde una perspectiva moderna. Modern R with the tidyverse Strings in R Para manipular caracteres. Referencias "],
["gráficos-1.html", "Capítulo 4 Gráficos 4.1 Estáticos 4.2 Interactivos 4.3 Recursos", " Capítulo 4 Gráficos En este capitulo se muestra como crear diferentes tipos de gráficos, tanto estáticos usando el paquete ggplot2 (Wickham, 2016; Wickham et al., 2020), como dinámicos usando los paquetes highcharter (Kunst, 2019), plotly (Sievert et al., 2020), y dygraphs (Vanderkam, Allaire, Owen, Gromer, &amp; Thieurmel, 2018). En este capitulo se van a utilizar los siguientes paquetes: library(babynames) library(nycflights13) library(gapminder) library(dygraphs) library(highcharter) library(plotly) library(RColorBrewer) library(viridis) library(rio) library(cowplot) library(patchwork) library(tidymodels) library(tidyverse) Los tres primeros corresponden con conjuntos de datos. Así mismo se vuelven a importar y manipular los datos con que se venia trabajando: data(&quot;airquality&quot;) dat1 &lt;- import(&quot;data/LungCapData2.csv&quot;, setclass = &#39;tibble&#39;) titanic &lt;- import(&quot;data/titanic.csv&quot;, setclass = &#39;tibble&#39;) titanic = titanic %&gt;% mutate(Pclass = as_factor(Pclass), Survived = as_factor(Survived), Sex = as_factor(Sex)) airq = airquality %&gt;% mutate(Month = factor(Month, levels = 5:9, labels = c(&quot;Mayo&quot;, &quot;Junio&quot;, &quot;Julio&quot;, &quot;Agosto&quot;, &quot;Setiembre&quot;)), Sensation = case_when(Temp &lt; 60 ~ &#39;Cold&#39;, Temp &lt; 70 ~ &#39;Cool&#39;, Temp &lt; 85 ~ &#39;Warm&#39;, T ~ &#39;Hot&#39;) %&gt;% as.factor()) 4.1 Estáticos El paquete por excelencia, como se menciono al principio del capitulo, para crear gráficos en R es ggplot2. Este se basa en la gramática de gráficos (grammar of graphics), de ahí el gg en el nombre. La estructura básica de cualquier gráficos es: ggplot(data = &lt;DATA&gt;) + &lt;GEOM_FUNCTION&gt;(mapping = aes(&lt;MAPPINGS&gt;), stat = &lt;STAT&gt;, position = &lt;POSITION&gt;) + &lt;FACET_FUNCTION&gt; + &lt;SCALE_AESTHETIC_TYPE&gt; + &lt;THEME_FUNCTION&gt; donde las partes principales son ggplot y geom_*, el resto no son necesarias. Dentro de geom_* se mapean la variables de la tabla a los argumentos de la función (x, y, col, fill, size, shape, alpha). La idea básica es trabajar en capas para poder modificar el gráfico con mayor detalle y facilidad. 4.1.1 Histograma Este se utiliza para datos numéricos continuos. Dentro de geom_histogram hay 3 opciones para definir la discretizacion: bins = Numero de clases binwidth = El ancho de las clases breaks = Un vector con los puntos donde separar los datos El primer gráfico (Figura 4.1) muestra el resultado de geom_histogram por defecto. Aquí se esta graficando la temperatura (‘Temp’) de la tabla ‘airquality’ en el eje x, es el eje que hay que usar en los histogramas. p = ggplot(data = airquality, mapping = aes(x=Temp)) + geom_histogram() p Figura 4.1: Histograma básico La apariencia del gráfico anterior se puede mejorar usando los argumentos col y fill, donde el primero corresponde con el color del borde de las barras, y el segundo con el relleno de las barras (Figura 4.2). ggplot(airquality,aes(x=Temp)) + geom_histogram(bins = 20,col=&quot;black&quot;,fill=&quot;blue&quot;) Figura 4.2: Histograma modificando la cantidad de barras y apariencia El eje x, sobre el cual estamos graficando los datos, se puede modificar con más detalle usando las funciones scale_x_*, donde en este caso usamos scale_x_continuous() por estar trabajando con datos continuos (Figura 4.3). El primer argumento de estas funciones es el nombre que se le quiere dar al eje, y en el caso siguiente, se modifican las etiquetas del eje con el argumento labels, donde se puede usar una de tantas funciones que se encuentran en el paquete scales. ggplot(airquality,aes(x=Temp)) + geom_histogram(binwidth = 2,col=&quot;black&quot;,fill=&quot;blue&quot;) + scale_x_continuous(&#39;Temperatura&#39;, labels = label_number(suffix = &#39; ºC&#39;)) Figura 4.3: Histograma modificando la apariencia del eje x Otra de las capas que se puede usar son las facetas o paneles, que permiten separar un tipo de gráfico, en este caso un histograma, en diferentes gráficos de acuerdo a otra variable, por lo general categórica (Figura 4.4). La función para esto es facet_wrap(~ variable). Esta función es útil para una variable, para dos o más variables es mejor usar facet_grid(filas ~ cols) (Ver Figuras 4.12 y 4.13). ggplot(airquality,aes(x=Temp)) + geom_histogram(bins = 20,col=&quot;black&quot;,fill=&quot;blue&quot;) + facet_wrap(~ Month) Figura 4.4: Histograma en paneles Se venían rellenando las barras todas de un mismo color, por lo que el argumento fill se pone fuera del aes(). Si se quiere rellenar las barras de acuerdo al conteo o densidad es necesario insertar dentro del aes() de geom_histogram el fill=after_stat(.), donde el punto (.) puede corresponder con el conteo (count) o la densidad (density). Así como se modifica el eje x anteriormente con scale_x_*, se puede modificar el relleno con scale_fill_*. En este caso (Figura 4.5) se usa scale_fill_distiller() para usar una de las paletas disponibles en el paquete RColorBrewer (Neuwirth, 2014), donde se tiene que especificar el nombre de la paleta de colores a usar, en este caso palette = 'YlOrRd'. ggplot(airquality,aes(x=Temp)) + geom_histogram(bins = 20,aes(fill=after_stat(count)),col=&quot;black&quot;) + scale_fill_distiller(palette = &#39;YlOrRd&#39;) Figura 4.5: Histograma con relleno de acuerdo al conteo Las paletas disponibles se observan en la Figura 4.6, donde el primer bloque de colores corresponde con las paletas secuenciales (seq), el segundo bloque con las paletas cualitativas (qual), y el tercer bloque con las paletas divergentes (div). Figura 4.6: Paletas disponibles en RColorBrewer Así como se puede modificar el relleno de las barras, se puede modificar que el eje y no corresponda con el conteo sino con la densidad (Figura 4.7), para esto es necesario insertar dentro del aes() de geom_histogram el y=after_stat(density), y esto es necesario si se quiere agregar la curva de densidad de los datos (geom_density) para ver su distribución. ggplot(airquality,aes(x=Temp)) + geom_histogram(bins = 20,aes(y=after_stat(density)), col=&quot;black&quot;,fill=&quot;blue&quot;) + geom_density(col=&quot;red&quot;) Figura 4.7: Histograma mostrando la densidad en el eje y en vez del conteo, con la curva de densidad superpuesta La densidad no es lo mismo que la frecuencia relativa (Figura 4.8). La densidad es el ajuste a la función de densidad de los datos donde la integral suma a 1, la frecuencia relativa es el porcentaje de observaciones por clase. Para esto es necesario insertar dentro del aes() de geom_histogram el y=after_stat(count/sum(count)). ggplot(airquality,aes(x=Temp)) + geom_histogram(bins = 20,aes(y=after_stat(count/sum(count))), col=&quot;black&quot;,fill=&quot;blue&quot;) Figura 4.8: Histograma mostrando la frecuencia relativa en el eje y en vez del conteo o la densidad A veces se quiere representar la frecuencia acumulada (absoluta o relativa), con lo que el histograma va a presentar una tendencia ascendente hasta llegar al total de observaciones (absoluta) o hasta uno (relativa). Para lograr esto se hace uso de la función cumsum al definir aes(y), como se muestra en las Figuras 4.9 y 4.10, para frecuencias absolutas y relativas respectivamente. ggplot(airquality,aes(x=Temp)) + geom_histogram(bins = 20,aes(y=after_stat(cumsum(count))), col=&quot;black&quot;,fill=&quot;blue&quot;) Figura 4.9: Histograma mostrando la frecuencia absoluta acumulada. En este caso \\(N = 153\\). ggplot(airquality,aes(x=Temp)) + geom_histogram(bins = 20,aes(y=after_stat(cumsum(count/sum(count)))), col=&quot;black&quot;,fill=&quot;blue&quot;) Figura 4.10: Histograma mostrando la frecuencia relativa acumulada Combinando lo aprendido hasta ahora se pueden modificar el relleno junto con el eje y, así como agregar la curva de densidad, para generar un gráfico que brinda más información (Figura 4.11). ggplot(airquality,aes(x=Temp)) + geom_histogram(bins = 20, aes(y=after_stat(density),fill=after_stat(count)), col=&quot;black&quot;) + geom_density(col=&quot;red&quot;) Figura 4.11: Histograma mostrando la densidad en el eje y en vez del conteo, con la curva de densidad superpuesta, y relleno de acuerdo al conteo Estos últimos dos gráficos agregan más cosas que permiten crear gráficos más complejos e informativos sin mucho esfuerzo, incluyendo paneles de acuerdo a dos variables usando facet_grid. El primero (Figura 4.12) agrega el relleno de acuerdo a una variable categórica, así como un paneleo por dos variables definiendo filas y columnas. El segundo (Figura 4.13) construye sobre el primero pero modificando las etiquetas de los paneles usando el argumento labeller, donde se define labeller(variable = vector con nombres), ademas se cambia el relleno con scale_fill_viridis y se modifican las etiquetas con un vector (c('actual' = 'nuevo')). El vector con nombres de labeller y el vector de etiquetas llevan la estructura c('actual' = 'nuevo'), donde ‘actual’ es el valor que tiene la variable y ‘nuevo’ es el nombre que se quiere aparezca en el gráfico. ggplot(titanic, aes(x = Age, fill = Survived)) + facet_grid(Sex ~ Pclass) + geom_density(alpha = 0.5) Figura 4.12: Curva de densidad haciendo uso de varias variables categóricas ggplot(titanic, aes(x = Age, fill = Survived)) + facet_grid(Sex ~ Pclass, labeller = labeller(Sex = c(&#39;male&#39;=&#39;Masculino&#39;, &#39;female&#39;=&#39;Femenino&#39;), Pclass = c(&#39;1&#39;=&#39;1era&#39;,&#39;2&#39;=&#39;2nda&#39;,&#39;3&#39;=&#39;3era&#39;))) + geom_density(alpha = 0.5) + scale_fill_viridis_d(&#39;Sobrevivió&#39;, labels = c(&#39;1&#39;=&#39;Si&#39;,&#39;0&#39;=&#39;No&#39;)) Figura 4.13: Versión mejorada del gráfico anterior 4.1.2 Barras Este se utiliza para datos categóricos. Dentro de geom_bar el argumento position puede tener cualquiera de estos tres valores: stack: Apila barras una encima de otra dodge: Pone barras de manera adyacente fill: Las barras tienen la misma altura, normalizadas a 1 (proporciones) geom_bar hace el conteo de clases, en caso de tener ya el conteo hecho se usa geom_col. De manera general se puede pasar solo una variable para realizar el conteo, pero este tipo de gráficos es más útil cuando se pueden agregar otras variables categóricas. En el primer ejemplo (Figura 4.14) se hace el conteo por genero, y se rellena por si fuman o no, lo que brinda una visión de la cantidad (o proporción) de hombres y mujeres que fuman o no. En este ejemplo se utiliza position = &quot;fill&quot;, lo que hace que todas las barras tengan las misma altura y comprendan el rango de 0 a 1 en el eje y, lo que asemeja a una visión de proporciones. Adicionalmente, se modifica el eje y (scale_y_continuous) asignándole un nombre y cambiando las etiquetas a porcentaje (labels = label_percent()). ggplot(dat1, aes(Gender,fill=Smoke)) + geom_bar(position = &quot;fill&quot;) + scale_y_continuous(&#39;Proporción&#39;,labels = label_percent()) Figura 4.14: Gráfico de barras con el argumento de posición fill, para mostrar proporciones entre categorias El siguiente gráfico (Figura 4.15) es similar al primero, en que se grafican los mismos datos, pero de otra manera. Se usa position = &quot;dodge&quot;, lo que pone una barra a la par de la otra (esto para la categoría usada en el relleno); adicionalmente, se modifica el eje x (scale_x_discrete) asignándole un nombre y modificando los nombres de las etiquetas (labels); por ultimo, se modifica de forma manual el relleno (scale_fill_manual) asignándole un nombre, que es el que aparecer en la leyenda, las etiquetas (que deben tener el mismo orden de los niveles de la variable), y los valores (values) son los colores a usar para cada nivel. ggplot(dat1, aes(Gender,fill=Smoke)) + geom_bar(position = &quot;dodge&quot;) + scale_x_discrete(&#39;Genero&#39;, labels = c(&#39;Femenino&#39;,&#39;Masculino&#39;)) + scale_fill_manual(&#39;Fumado&#39;, labels = c(&#39;Si&#39;,&#39;No&#39;), values = c(&#39;darkred&#39;,&#39;green4&#39;)) Figura 4.15: Gráfico de barras con apariencia modificada y posición de las barras una a la par de la otra De igual manera se pueden generar paneles de acuerdo a una variable categórica (Figura 4.16). ggplot(titanic, aes(x = Sex, fill = Survived)) + facet_wrap(~ Pclass) + geom_bar() Figura 4.16: Gráfico de barras en paneles Cuando se gráfica una variable únicamente el orden de las barras va a estar en función del orden de los niveles (Figura 4.17), pero esta representación puede que no sea la más clara visualmente. Para corregir lo anterior se pueden reordenar los niveles de la variable (únicamente para el gráfico) de acuerdo a la frecuencia (de mayor a menor), usando fct_infreq del paquete forcats (Figura 4.18). gss_cat %&gt;% ggplot(aes(marital)) + geom_bar() Figura 4.17: Gráfico de barras básico con orden de barras de acuerdo al orden de los niveles gss_cat %&gt;% ggplot(aes(fct_infreq(marital))) + geom_bar() Figura 4.18: Gráfico de barras ordenado de acuerdo a la frecuencia de los niveles Los ejemplos anteriores usaban geom_bar, pero en el caso de que ya se tenga el conteo se puede usar geom_col. En este caso hay que especificar la variable a graficar en x y el conteo en y, el resto de modificaciones se pueden aplicar de igual manera a como se venia mostrando. En este ejemplo (Figura 4.19) debido a que los niveles corresponden con nombres largos y hay muchos, se usa el cambiar los ejes por medio de coord_flip, lo que va a poner en ‘y’ lo que estaba en ‘x’ y viceversa. mpg %&gt;% count(manufacturer, year) %&gt;% mutate(year = as.factor(year)) %&gt;% ggplot(aes(manufacturer,n,fill=year)) + geom_col(position = &#39;dodge&#39;) + coord_flip() + scale_fill_brewer(palette = &#39;Dark2&#39;) Figura 4.19: Gráfico de barras precontado y cambiando ejes para mayor claridad 4.1.3 Boxplot Este tipo se usa para datos numéricos continuos que normalmente se separan por una variable categórica. Los datos continuos se grafican en el eje y, por lo que hay que especificar esto explícitamente en el aes() (Figura 4.20), y si se quiere separar por una variable categórica, esta se asigna al eje x (Figura 4.21). ggplot(airq,aes(y=Temp)) + geom_boxplot() Figura 4.20: Gráfico boxplot básico ggplot(airq,aes(x = Month,y = Temp)) + geom_boxplot() Figura 4.21: Gráfico boxplot separado por variable categórica En el tercer ejemplo (Figura 4.22) se agregan un par de funciones que no se habían visto: labs y theme_bw. labs permite modificar los nombres de los ejes y estéticas (col, fill, etc.) sin tener que usar las funciones scale_*_*. theme_bw es uno de los tantos temas que vienen definidos y cambia la apariencia a un gráfico en blanco y negro, removiendo el fondo gris que en muchos casos no es lo mejor. ggplot(airq,aes(x = Month,y = Temp)) + geom_boxplot(fill=&quot;white&quot;,col=&quot;red&quot;) + labs(x=&quot;Mes&quot;,y=&quot;Temperatura&quot;) + theme_bw() Figura 4.22: Gráfico boxplot con apariencia modificada 4.1.4 Dispersión Estos aplican para datos numéricos continuos en ambos ejes. Un gráfico básico se muestra en el primer ejemplo (Figura 4.23). ggplot(airquality, aes(Ozone,Temp)) + geom_point() Figura 4.23: Gráfico de dispersión básico Para el caso de puntos se puede cambiar el tipo de icono con el argumento shape, este puede definirse de manera global para todos los puntos o de acuerdo a una variable categórica (Figura 4.24). ggplot(airq, aes(Ozone,Temp,shape=Month)) + geom_point() Figura 4.24: Gráfico de dispersión con la forma de los puntos de acuerdo a una variable categórica Una tarea común en gráficos de dispersión es agregar líneas de tendencia. Para agregar líneas de tendencia en ggplot2 se usa la función geom_smooth. Por defecto ajusta una curva loess, pero para cambiarlo se usa el argumento method = 'lm' (Figura 4.25), y para especificar una ecuación diferente a la regresión simple (y ~ x) se usa formula, donde y y x son genéricos (Figura 4.26), NO hay que poner el nombre de las variables que se esta graficando. ggplot(airquality, aes(Wind,Temp)) + geom_point() + geom_smooth(method = &quot;lm&quot;) Figura 4.25: Gráfico de dispersión con línea de tendencia lineal ggplot(airquality, aes(Ozone,Temp)) + geom_point() + geom_smooth(method = &quot;lm&quot;, formula = y~poly(x,2)) Figura 4.26: Gráfico de dispersión con línea de tendencia polinomial En este caso (Figura 4.27) cuando se aplica el paneleo (facet_wrap) se obtiene una gráfico de dispersión con su respectiva línea de tendencia para cada uno de los niveles de la variable categórica. ggplot(airquality, aes(Wind,Temp)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + facet_wrap(~ Month) Figura 4.27: Gráfico de dispersión en paneles con línea de tendencia para cada panel 4.1.5 líneas Estos gráficos son una versión del gráfico de dispersión, donde el eje x corresponde con una variable continua que tiene cierta secuencia o patrón, por lo general tiempo o espacio. El primer gráfico (Figura 4.28) muestra como ha cambiado el uso del nombre ‘Max’ a lo largo del tiempo. Primero se filtran los datos para el nombre de interés, y se seleccionan las variables a usar en el gráfico. Como el eje y corresponde con proporción, se modifica para que muestre el porcentaje. babynames %&gt;% filter(name == &quot;Max&quot;) %&gt;% select(year, prop, sex) %&gt;% ggplot(mapping = aes(x = year, y = prop)) + geom_line(mapping = aes(color = sex)) + scale_y_continuous(labels = label_percent()) Figura 4.28: Gráfico de línea básico En el segundo gráfico de líneas (Figura 4.29) se grafica el numero de tormentas por año, de nuevo, realizando una manipulación de los datos para obtener la información que se desea desplegar. El ultimo gráfico (Figura 4.30) simplemente hace la separación de diferentes líneas de acuerdo a una variable categórica. storms %&gt;% group_by(year) %&gt;% summarize(n_storm = n_distinct(name)) %&gt;% ggplot() + geom_line(mapping = aes(x = year, y = n_storm)) Figura 4.29: Gráfico de línea básico con otros datos storms %&gt;% group_by(year,status) %&gt;% summarize(n_storm = n_distinct(name)) %&gt;% ggplot() + geom_line(mapping = aes(x = year, y = n_storm, col = status)) Figura 4.30: Gráfico de línea básico, con diferentes líneas de acuerdo a una variable categórica 4.1.6 Gráficos estadísticos Estos sirven para resumir los datos. Los ejemplos que aquí se muestran corresponden con el despliegue de intervalos de confianza de una variable numérica para diferentes niveles de una variable categórica. ggplot(airquality, aes(Month, Temp)) + stat_summary(fun.y = mean, geom = &quot;point&quot;, color = &quot;black&quot;) + stat_summary(fun.data = mean_cl_normal, geom = &quot;errorbar&quot;, width = 0.2) + theme_bw() Figura 4.31: Gráfico estadístico mostrando intervalo de confianza como barras de error ggplot(airquality, aes(Month, Temp)) + stat_summary(fun.data = mean_cl_normal, geom = &quot;pointrange&quot;, color = &quot;red&quot;, size=1) + theme_bw() Figura 4.32: Gráfico estadístico mostrando intervalo de confianza como punto y rango 4.1.7 Transformación de ejes En algunas ocasiones, dependiendo de la escala y rango que tenga los datos, una transformación de uno o ambos ejes sea necesaria, siendo los más típico para datos numéricos continuos. El ejemplo más típico es la transformacional logarítmica (natural o base 10), para los casos donde los datos comprenden varios ordenes de magnitud. En ggplot2 esto puede hacerse de dos maneras: scale_&lt;eje&gt;_&lt;tipo&gt;(trans = '#'), coord_trans(&lt;eje&gt; = '#') donde # corresponde con la transformacional a realizar, y puede tomar los siguientes valores: “asn”, “atanh”, “boxcox”, “date”, “exp”, “hms”, “identity”, “log”, “log10”, “log1p”, “log2”, “logit”, “modulus”, “probability”, “probit”, “pseudo_log”, “reciprocal”, “reverse”, “sqrt”, y “time”. Siendo las más comunes las resaltadas en negrita, donde “log” se refiere al logaritmo natural, “log10” al logaritmo base 10, y “reverse” para invertir el eje. La diferencia de usar scale_* o coord_trans radica en cuando se aplica la transformacional. Con scale_* la transformación es aplicada a los datos antes de ser graficados, por lo que se grafica son los datos transformados (Figura 4.33, B); con coord_trans la transformación se aplica después de ser graficados, o sea se aplica sobre el eje, modificando la apariencia y no los datos en si (Figura 4.33, C). La Figura 4.33, es una grilla de gráficos, la cual fue realizada por medio de cowplot (Wilke, 2019). Otro paquete para generar grillas de gráficos es patchwork (Pedersen, 2019), y este ofrece más flexibilidad con la manipulación y posicionamiento de los gráficos (Figura 4.34). En ambos casos, se ve claramente en el subgráfico A que el eje x tiene varios ordenes de magnitud. En el subgráfico B se aplico scale_x_continuous(trans = 'log10'), lo cual aplica una transformación logarítmica a los datos antes de plotearlos y por eso los diferentes valores. En el subgráfico C se aplico coord_trans(x = 'log10'), lo cual simplemente modifica la apariencia del eje, donde se observa esa escala logarítmica, manteniendo los valores originales; adicionalmente se cambian los valores del eje (scale_x_continuous(breaks = c(10,100,1000,10000))) para que no se vean tan apilados. cow1 = ggplot(msleep) + geom_point(aes(bodywt,sleep_total)) cow2 = ggplot(msleep) + geom_point(aes(bodywt,sleep_total)) + scale_x_continuous(trans = &#39;log10&#39;) cow3 = ggplot(msleep) + geom_point(aes(bodywt,sleep_total)) + coord_trans(x = &#39;log10&#39;) + scale_x_continuous(breaks = c(10,100,1000,10000)) plot_grid(cow1, cow2, cow3, ncol = 1, labels = &#39;AUTO&#39;) Figura 4.33: Ejemplo de transformación de ejes, en este caso solo el eje x, usando cowplot. A es el gráfico sin datos tranformados; B es el gráfico usando scale_*; C es el gráfico usando coord_trans cow1 / (cow2 | cow3) + plot_annotation(tag_levels = &#39;A&#39;) &amp; theme_bw() Figura 4.34: Ejemplo de transformación de ejes, en este caso solo el eje x, usando patchwork. A es el gráfico sin datos tranformados; B es el gráfico usando scale_*; C es el gráfico usando coord_trans 4.1.8 Limites de ejes (Zoom) Otra acción que tal vez se quiera realizar puede ser delimitar los valores mínimos y máximos de los ejes, ya sea para tener control sobre estos, o para realizar una especie de acercamiento (zoom) en una región del gráfico. La manera apropiada de realizar esto es por medio de coord_cartesian(*lim), donde *lim se refiere al eje x o y. la otra forma que tal vez aparezca por ahí, pero no da los resultados deseados es usando scale_&lt;eje&gt;_&lt;tipo&gt;(limits). En ambos casos se brinda un vector de mínimo y máximo. La Figura 4.35 muestra el gráfico inicial, y como afectan las diferentes funciones. De manera similar a la transformación, scale_* aplica los limites antes de graficar, por lo que los datos que caen fuera de esos limites son descartados y no ploteados (de ahí la advertencia). En cambio, coord_cartesian aplica los limites después de graficados los datos, por lo que simplemente es un cambio en la representación del eje y no en los datos. z1 = gss_cat %&gt;% ggplot(aes(y=marital)) + geom_bar() z2 = gss_cat %&gt;% ggplot(aes(y=marital)) + geom_bar() + scale_x_continuous(limits = c(0,5000)) z3 = gss_cat %&gt;% ggplot(aes(y=marital)) + geom_bar() + coord_cartesian(xlim = c(0,5000)) z1 / (z2 | z3) + plot_annotation(tag_levels = &#39;A&#39;) &amp; theme_bw() Figura 4.35: Ejemplo de modificar los límites del eje y en este caso. A es el gráfico original B es el gráfico usando scale_*; C es el gráfico usando coord_cartesian 4.1.9 Salvando gráficos Se muestran funciones para salvar gráficos, donde las extensiones más usadas son .png, .tiff, y .pdf. Por defecto ggsave salva el ultimo gráfico creado, a menos que se haya guardado el gráfico en un objeto y se le pase dicho objeto al argumento plot. El resto de argumentos son claros en lo que representan. Para el caso de un .pdf hay que remover el argumento type. ggsave(filename = &quot;figures/Testgg.png&quot;, plot = p, dpi = 300, width = 7, height = 4, units = &quot;in&quot;, type = &quot;cairo&quot;) ggsave(filename = &quot;figures/Testgg.pdf&quot;, plot = p, dpi = 300, width = 7, height = 4, units = &quot;in&quot;) 4.2 Interactivos Una vez sabiendo utilizar ggplot2 la forma más sencilla de hacer un gráfico interactivo es mediante plotly::ggplotly(). El paquete plotly (Sievert et al., 2020) se usa para gráficos interactivos y tiene una sintaxis un poco diferente a ggplot2, por lo que hay ciertos gráficos que no van a ser convertidos apropiadamente, pero la mayoría de gráficos debieran funcionar. Otros paquetes para gráficos interactivos son: highcarter: Sintaxis similar a ggplot, con ciertas limitantes, rbokeh: Gráficos interactivos generales, dygraphs: Series temporales, mapview y leaflet: Mapas En las siguientes secciones se va a recrear alguno de los gráficos anteriores para hacerlo interactivo con ggplotly, y se va a crear uno similar con highcharter. El ejercicio de entender como funciona highcharter queda a cargo del lector, en general los ejemplos y funciones son claras. Una característica de estos gráficos interactivos, cuando tienen leyenda, es que al hacer click sobre una de la entradas de la leyenda, esta serie de datos es escondida del gráfico, dejando visible únicamente lo otro. En el caso de highcharter los ejes se ajustan automáticamente, este no es el caso para plotly. 4.2.1 Histograma La versión interactiva de la Figura 4.11 se muestra en la Figura 4.36, la versión usando highcharter se muestra en la Figura 4.37. (ggplot(airquality,aes(x=Temp)) + geom_histogram(bins = 20, aes(y=after_stat(density),fill=after_stat(count)), col=&quot;black&quot;) + geom_density(col=&quot;red&quot;)) %&gt;% plotly::ggplotly() Figura 4.36: Gráfico interactivo de un histograma con plotly with(airq, hchist(Temp,color=&#39;red&#39;,name=&#39;Temp&#39;)) %&gt;% hc_xAxis(title = list(text = &#39;Temperatura&#39;)) %&gt;% hc_exporting(enabled=T) Figura 4.37: Gráfico interactivo de un histograma con highcharter 4.2.2 Barras La versión interactiva de la Figura 4.19 se muestra en la Figura 4.38, la versión usando highcharter se muestra en la Figura 4.39. En la versión de highcharter, si se cambia ‘bar’ por ‘column’, el gráfico cambia orientación. (mpg %&gt;% count(manufacturer, year) %&gt;% mutate(year = as.factor(year)) %&gt;% ggplot(aes(manufacturer,n,fill=year)) + geom_col(position = &#39;dodge&#39;) + coord_flip() + scale_fill_brewer(palette = &#39;Dark2&#39;)) %&gt;% plotly::ggplotly() Figura 4.38: Gráfico interactivo de barras con plotly mpg %&gt;% count(manufacturer, year) %&gt;% hchart(&#39;bar&#39;, hcaes(x = manufacturer, y = n, group = year)) %&gt;% hc_xAxis(title = list(text = &#39;Constructor&#39;)) %&gt;% hc_yAxis(title = list(text = &#39;Cantidad&#39;)) %&gt;% hc_exporting(enabled=T) Figura 4.39: Gráfico interactivo de barras con highcharter 4.2.3 Boxplot La versión interactiva de la Figura 4.21 se muestra en la Figura 4.40, la versión usando highcharter se muestra en la Figura 4.41. (ggplot(airq,aes(x = Month,y = Temp)) + geom_boxplot()) %&gt;% plotly::ggplotly() Figura 4.40: Gráfico interactivo boxplot con plotly with(airq, hcboxplot(x = Temp, var = Month)) %&gt;% hc_yAxis(title = list(text = &#39;Temperatura&#39;)) %&gt;% hc_xAxis(title = list(text = &#39;Mes&#39;)) %&gt;% hc_exporting(enabled=T) Figura 4.41: Gráfico interactivo boxplot con highcharter 4.2.4 Dispersión La versión interactiva de la Figura 4.25 se muestra en la Figura 4.42, la versión usando highcharter se muestra en la Figura 4.43, con el agregado de que muestra la ecuación de cada línea de tendencia. (ggplot(airquality, aes(Wind,Temp)) + geom_point() + geom_smooth(method = &quot;lm&quot;)) %&gt;% plotly::ggplotly() Figura 4.42: Gráfico interactivo de dispersión con plotly hchart(airq, &#39;scatter&#39;, hcaes(Wind, Temp, group=Month), regression = T) %&gt;% hc_xAxis(title = list(text = &#39;Viento&#39;)) %&gt;% hc_yAxis(title = list(text = &#39;Temperatura&#39;)) %&gt;% hc_colors(viridis(n_distinct(airq$Month))) %&gt;% hc_add_dependency(&#39;plugins/highcharts-regression.js&#39;) %&gt;% hc_exporting(enabled=T) Figura 4.43: Gráfico interactivo de dispersión con highcharter 4.2.5 líneas La versión interactiva de la Figura 4.30 se muestra en la Figura 4.44, la versión usando highcharter se muestra en la Figura 4.45, y la versión usando dygraphs se muestra en la Figura 4.46. En este ultimo caso es necesario que los datos estén en formato ancho, donde la primer columna corresponde con el eje x, y el resto de columnas corresponden con las series temporales/espaciales a graficar por separado. (storms %&gt;% group_by(year,status) %&gt;% summarize(n_storm = n_distinct(name)) %&gt;% ggplot() + geom_line(mapping = aes(x = year, y = n_storm, col = status))) %&gt;% plotly::ggplotly() Figura 4.44: Gráfico interactivo de líneas con plotly storms %&gt;% group_by(year,status) %&gt;% summarize(n_storm = n_distinct(name)) %&gt;% hchart(&#39;line&#39;, hcaes(year, n_storm, group = status)) %&gt;% hc_xAxis(title = list(text = &#39;Año&#39;)) %&gt;% hc_yAxis(title = list(text = &#39;Cantidad&#39;)) %&gt;% hc_exporting(enabled=T) %&gt;% hc_tooltip(shared=T,crosshairs=T, backgroundColor=&#39;rgba(247,247,247,0.5)&#39;,shadow=F) %&gt;% hc_chart(zoomType=&#39;x&#39;)%&gt;% hc_add_theme(hc_theme_google()) %&gt;% hc_plotOptions(line = list(marker = list( enabled = F, radius = 2 ) )) Figura 4.45: Gráfico interactivo de líneas con highcharter storms %&gt;% group_by(year,status) %&gt;% summarize(n_storm = n_distinct(name)) %&gt;% pivot_wider(names_from = status,values_from = n_storm) %&gt;% dygraph() %&gt;% dyAxis(&#39;x&#39;, label = &#39;Año&#39;) %&gt;% dyAxis(&#39;y&#39;, label = &#39;Cantidad&#39;) %&gt;% dyRangeSelector() Figura 4.46: Gráfico interactivo de líneas con dygraphs 4.2.6 Transformación de ejes La versión interactiva, usando highcharter, de la Figura 4.33 C se muestra en la Figura 4.47; la versión con ggplotly seria igual que las anteriores. hchart(msleep, &#39;scatter&#39;, hcaes(bodywt, sleep_total)) %&gt;% hc_xAxis(title = list(text = &#39;Body Weight&#39;), type = &#39;logarithmic&#39;) %&gt;% hc_yAxis(title = list(text = &#39;Sleep&#39;)) %&gt;% hc_chart(zoomType=&#39;xy&#39;) %&gt;% hc_add_theme(hc_theme_gridlight()) Figura 4.47: Gráfico interactivo con eje logarítmico 4.3 Recursos Se presentan recursos a consultar para ahondar más en los temas presentados. tidyverse ggplot2 Libro de ggplot2. highcharter rbokeh dygraphs Referencias "],
["iteración-con-purrr.html", "Capítulo 5 Iteración con purrr 5.1 Iterando sobre un objeto 5.2 Iterando sobre dos objetos 5.3 Leyendo archivos y combinándolos 5.4 Datos anidados, caso 1 5.5 Datos anidados, caso 2 5.6 Recursos", " Capítulo 5 Iteración con purrr En este capitulo se muestra como iterar funciones sobre diferentes objetos (vectores, tablas, listas). La idea de las iteraciones es ser más eficiente a la hora de realizar cálculos repetitivos. Se va a introducir al paquete purrr (Henry &amp; Wickham, 2019) que brinda funciones para realizar diferentes tareas que requieren iterar sobre 1 o más objetos. En este capitulo se van a utilizar los siguientes paquetes: library(gapminder) library(fs) library(rio) library(tidymodels) library(tidyverse) Así mismo se vuelven a importar y manipular los datos con que se venia trabajando: data(&quot;airquality&quot;) airq = airquality %&gt;% mutate(Month = factor(Month, levels = 5:9, labels = c(&quot;Mayo&quot;, &quot;Junio&quot;, &quot;Julio&quot;, &quot;Agosto&quot;, &quot;Setiembre&quot;)), Sensation = case_when(Temp &lt; 60 ~ &#39;Cold&#39;, Temp &lt; 70 ~ &#39;Cool&#39;, Temp &lt; 85 ~ &#39;Warm&#39;, T ~ &#39;Hot&#39;) %&gt;% as.factor()) 5.1 Iterando sobre un objeto La función básica de purrr es map(.x, .f, ...), donde .x es el objeto sobre el cual iterar (vector, tabla o lista), .f es la función o tarea a realizar durante la iteración, y ... son argumentos extra dependiendo de la función. Esta función (map) siempre va a resultar en una lista; existen variantes de esta que son especificas para cuando se conoce cual va a ser el tipo de dato de salida. Por ejemplo, map_dbl se usa cuando el resultado de la función es un numero con decimales. En el siguiente bloque de código se generan dos listas ficticias, ambas de 7 elementos, donde la primera corresponde con notas de estudiantes en pruebas durante un semestre, y la segunda son puntos extra para cada estudiante. set.seed(4101) n = 8 minima = 60 maxima = 100 exams &lt;- list( student1 = round(runif(n, minima, maxima)), student2 = round(runif(n, minima, maxima)), student3 = round(runif(n, minima, maxima)), student4 = round(runif(n, minima, maxima)), student5 = round(runif(n, minima, maxima)), student6 = round(runif(n, minima, maxima)), student7 = round(runif(n, minima, maxima)) ) extra_credit &lt;- list(10, 5, 0, 15, 5, 0, 5) Usando los datos generados anteriormente, se muestra la funcionalidad de varias de las funciones map_*. Estas funciones se pueden usar con el pipe operator (%&gt;%). El primer ejemplo muestra como con map se obtiene una lista de la nota media de los exámenes por estudiante. Se itera sobre la lista ‘exams’, y a cada elemento de la lista (en este caso vectores) se le calcula la media. map(exams, mean) # media ## $student1 ## [1] 79.25 ## ## $student2 ## [1] 75.875 ## ## $student3 ## [1] 80.25 ## ## $student4 ## [1] 85.125 ## ## $student5 ## [1] 84.875 ## ## $student6 ## [1] 79.625 ## ## $student7 ## [1] 81.875 En el segundo ejemplo se utiliza el pipe (%&gt;%) y una de las variantes de map (map_dbl), ya que lo que se va a calcular (nota máxima) se sabe es un numero con decimales. exams %&gt;% map_dbl(max) # nota maxima ## student1 student2 student3 student4 student5 student6 student7 ## 100 96 91 99 95 93 100 En el tercer ejemplo se itera sobre una tabla, donde en este caso la iteración es sobre las columnas. Recordemos que una tabla es una lista donde las columnas son los elementos de la lista. Lo que se quiere hacer es obtener el valor de la media para cada columna de la tabla ‘airq’. Al hacer esto encontramos dos situaciones; la primera que dice que hay un argumento no numérico o lógico (en este caso se refiere a las columnas ‘Month’ y ‘Sensation’ que son factor), por lo que al ser un factor no se le puede aplicar una función numérica; la segunda que hay valores ‘NA’ aun en columnas que son numéricas (‘Ozone’, ‘Solar.R’), esto porque en esas columnas hay NAs y por defecto la función mean no los remueve a la hora de hacer el calculo. airq %&gt;% map_dbl(mean) ## Ozone Solar.R Wind Temp Month Day Sensation ## NA NA 9.957516 77.882353 NA 15.803922 NA Por lo anterior, hay dos soluciones dependiendo de lo que se quiera resolver. Si solo se quiere lidiar con los ‘NA’, se puede agregar el argumento na.rm = T de la función mean, pero las columnas de tipo factor van a seguir estando presentes y dar ‘NA’ como resultado. airq %&gt;% map_dbl(mean, na.rm = T) ## Ozone Solar.R Wind Temp Month Day Sensation ## 42.129310 185.931507 9.957516 77.882353 NA 15.803922 NA La solución más adecuada en este caso es primero seleccionar las columnas de tipo numérico (select_if(is.numeric)) y a estas aplicarle el calculo de la media removiendo los ‘NA’. Esta ultima forma de aplicar la función es, a mi parecer, la más practica y clara. Se tiene que escribir la función empezando con el símbolo ~, esto le dice a purrr que lo que va a estar a al derecha va a ser una función, seguido de este símbolo se escribe la función de manera normal, con la excepción de que en el lugar donde iría típicamente el vector se pone .x, para decirle a purrr donde incrustar los elementos del objeto sobre el cual se esta iterando. airq %&gt;% select_if(is.numeric) %&gt;% map_dbl(~ mean(.x, na.rm = T)) ## Ozone Solar.R Wind Temp Day ## 42.129310 185.931507 9.957516 77.882353 15.803922 5.2 Iterando sobre dos objetos Los ejemplos anteriores se estaba iterando únicamente sobre un objeto. Para iterar sobre dos objetos (que tienen que tener la misma cantidad de elementos), existen las funciones map2_*, que tienen al estructura map2(.x, .y, .f, ...), donde .x es el primer objeto, .y es el segundo objeto, y .f es al función a utilizar sobre los dos objetos. Un ejemplo de esto es calcular la nota final de los estudiantes por medio de la media de los exámenes y agregarle el crédito extra. exams %&gt;% map2_dbl(extra_credit, ~ mean(.x) + .y) ## student1 student2 student3 student4 student5 student6 student7 ## 89.250 80.875 80.250 100.125 89.875 79.625 86.875 5.3 Leyendo archivos y combinándolos Un caso típico donde se desea iterar es leer varios archivos de texto que tienen el mismo formato y como combinarlos en una sola tabla para posterior manipulación. En este caso se usa la función dir_ls del paquete fs (Hester &amp; Wickham, 2020), donde se define la carpeta donde se encuentran los archivos (path) y con glob se define un patrón en el nombre de los archivos (en este caso todos los archivos empiezan con ‘datos_’). archivos &lt;- dir_ls(path = &#39;data&#39;, glob = &quot;*datos_*&quot;) archivos ## data/datos_cuarto_grado.csv data/datos_quinto_grado.csv ## data/datos_tercer_grado.csv file_info(archivos) ## # A tibble: 3 x 18 ## path type size permissions modification_time user group device_id ## &lt;fs::path&gt; &lt;fct&gt; &lt;fs:&gt; &lt;fs::perms&gt; &lt;dttm&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 data/dato… file 1.79K rw-r--r-- 2019-07-01 16:52:58 maxi… staff 16777220 ## 2 data/dato… file 1.84K rw-r--r-- 2019-07-01 16:52:58 maxi… staff 16777220 ## 3 data/dato… file 1.81K rw-r--r-- 2019-07-01 16:52:58 maxi… staff 16777220 ## # … with 10 more variables: hard_links &lt;dbl&gt;, special_device_id &lt;dbl&gt;, ## # inode &lt;dbl&gt;, block_size &lt;dbl&gt;, blocks &lt;dbl&gt;, flags &lt;int&gt;, generation &lt;dbl&gt;, ## # access_time &lt;dttm&gt;, change_time &lt;dttm&gt;, birth_time &lt;dttm&gt; Una vez se tiene le objeto con los nombres de los archivos (‘archivos’), se puede proceder a realizar la iteración. Como estamos importando archivos de texto (.csv) usamos la función import del paquete rio. Primeramente podemos generar una lista donde iteramos sobre el objeto ‘archivos’ e importamos cada uno, para posteriormente “pegar” uno tras otro con la función bind_rows de dplyr. map(archivos, import) %&gt;% bind_rows() ## # A tibble: 144 x 5 ## fecha nombre matematica ingles matricula ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 1/1/2015 Hernandez, Rodrigo 90 60 100 ## 2 1/2/2015 Hernandez, Rodrigo 85 70 100 ## 3 1/3/2015 Hernandez, Rodrigo 70 80 100 ## 4 1/4/2015 Hernandez, Rodrigo 75 85 100 ## 5 1/5/2015 Hernandez, Rodrigo 70 90 100 ## 6 1/6/2015 Hernandez, Rodrigo 66 90 100 ## 7 1/1/2015 Sanchez, Juan 60 80 102 ## 8 1/2/2015 Sanchez, Juan 70 80 102 ## 9 1/3/2015 Sanchez, Juan 80 90 102 ## 10 1/4/2015 Sanchez, Juan 85 85 102 ## # … with 134 more rows Con lo anterior logramos generar una tabla con todos los datos pero no sabemos cuales datos corresponden con cual archivo (y consecuentemente con que nivel). Para remediar lo anterior la función bind_rows tiene un argumento .id, al cual se le pasa el nombre de la columna que se quiere agregar mostrando el nombre del archivo al cual pertenece cada observación. archivos %&gt;% map_dfr(import, .id = &quot;archivo&quot;) ## # A tibble: 144 x 6 ## archivo fecha nombre matematica ingles matricula ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 data/datos_cuarto_grado… 1/1/2015 Hernandez, Rod… 90 60 100 ## 2 data/datos_cuarto_grado… 1/2/2015 Hernandez, Rod… 85 70 100 ## 3 data/datos_cuarto_grado… 1/3/2015 Hernandez, Rod… 70 80 100 ## 4 data/datos_cuarto_grado… 1/4/2015 Hernandez, Rod… 75 85 100 ## 5 data/datos_cuarto_grado… 1/5/2015 Hernandez, Rod… 70 90 100 ## 6 data/datos_cuarto_grado… 1/6/2015 Hernandez, Rod… 66 90 100 ## 7 data/datos_cuarto_grado… 1/1/2015 Sanchez, Juan 60 80 102 ## 8 data/datos_cuarto_grado… 1/2/2015 Sanchez, Juan 70 80 102 ## 9 data/datos_cuarto_grado… 1/3/2015 Sanchez, Juan 80 90 102 ## 10 data/datos_cuarto_grado… 1/4/2015 Sanchez, Juan 85 85 102 ## # … with 134 more rows La siguiente situación que podemos encontrar es que el nombre del archivo (o cualquier otra columna de la tabla) tiene más información de la necesaria, por lo que hay que separar los contenidos de la columna. Para esto usamos separate de tidyr para separar la columna en varias. En el caso de la columna ‘archivo’ podemos esperar tres columnas si especificamos el separador (sep = '_'), pero hay columnas que no ofrecen ninguna información (de las 3, la 1 y la 3, la 2 es la que tiene el nombre del nivel); para descartar estas columnas a la hora de separarlas se puede incluir NA en la posición de las columnas que se desea descartar. archivos %&gt;% map_dfr(import, .id = &quot;archivo&quot;) %&gt;% separate(archivo, into = letters[1:3], sep = &#39;_&#39;) ## # A tibble: 144 x 8 ## a b c fecha nombre matematica ingles matricula ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 data/dat… cuarto grado.c… 1/1/20… Hernandez, Rod… 90 60 100 ## 2 data/dat… cuarto grado.c… 1/2/20… Hernandez, Rod… 85 70 100 ## 3 data/dat… cuarto grado.c… 1/3/20… Hernandez, Rod… 70 80 100 ## 4 data/dat… cuarto grado.c… 1/4/20… Hernandez, Rod… 75 85 100 ## 5 data/dat… cuarto grado.c… 1/5/20… Hernandez, Rod… 70 90 100 ## 6 data/dat… cuarto grado.c… 1/6/20… Hernandez, Rod… 66 90 100 ## 7 data/dat… cuarto grado.c… 1/1/20… Sanchez, Juan 60 80 102 ## 8 data/dat… cuarto grado.c… 1/2/20… Sanchez, Juan 70 80 102 ## 9 data/dat… cuarto grado.c… 1/3/20… Sanchez, Juan 80 90 102 ## 10 data/dat… cuarto grado.c… 1/4/20… Sanchez, Juan 85 85 102 ## # … with 134 more rows archivos %&gt;% map_dfr(import, .id = &quot;archivo&quot;) %&gt;% separate(archivo, into = c(NA, &#39;grado&#39;, NA), sep = &#39;_&#39;) ## # A tibble: 144 x 6 ## grado fecha nombre matematica ingles matricula ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 cuarto 1/1/2015 Hernandez, Rodrigo 90 60 100 ## 2 cuarto 1/2/2015 Hernandez, Rodrigo 85 70 100 ## 3 cuarto 1/3/2015 Hernandez, Rodrigo 70 80 100 ## 4 cuarto 1/4/2015 Hernandez, Rodrigo 75 85 100 ## 5 cuarto 1/5/2015 Hernandez, Rodrigo 70 90 100 ## 6 cuarto 1/6/2015 Hernandez, Rodrigo 66 90 100 ## 7 cuarto 1/1/2015 Sanchez, Juan 60 80 102 ## 8 cuarto 1/2/2015 Sanchez, Juan 70 80 102 ## 9 cuarto 1/3/2015 Sanchez, Juan 80 90 102 ## 10 cuarto 1/4/2015 Sanchez, Juan 85 85 102 ## # … with 134 more rows Por ultimo, en este caso también se puede separar la columna ‘nombre’ en ‘apellido’ y ‘nombre’, usando los mismos principios anteriores. archivos %&gt;% map_dfr(import, .id = &quot;archivo&quot;) %&gt;% separate(archivo, into = c(NA, &#39;grado&#39;, NA), sep = &#39;_&#39;) %&gt;% separate(nombre, into = c(&#39;apellido&#39;, &#39;nombre&#39;), sep = &#39;, &#39;) ## # A tibble: 144 x 7 ## grado fecha apellido nombre matematica ingles matricula ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 cuarto 1/1/2015 Hernandez Rodrigo 90 60 100 ## 2 cuarto 1/2/2015 Hernandez Rodrigo 85 70 100 ## 3 cuarto 1/3/2015 Hernandez Rodrigo 70 80 100 ## 4 cuarto 1/4/2015 Hernandez Rodrigo 75 85 100 ## 5 cuarto 1/5/2015 Hernandez Rodrigo 70 90 100 ## 6 cuarto 1/6/2015 Hernandez Rodrigo 66 90 100 ## 7 cuarto 1/1/2015 Sanchez Juan 60 80 102 ## 8 cuarto 1/2/2015 Sanchez Juan 70 80 102 ## 9 cuarto 1/3/2015 Sanchez Juan 80 90 102 ## 10 cuarto 1/4/2015 Sanchez Juan 85 85 102 ## # … with 134 more rows 5.4 Datos anidados, caso 1 Como se había mencionado en la Sección 3.12 del Capitulo Funcionamiento avanzado de R, una de las ventajas de los tibbles es que permiten tener columnas tipo lista, las cuales son muy útiles para iterar y realizar cálculos de manera expedita. En este caso 1 se trabaja con los datos de ‘airq’, que era la tabla modificada de ‘airquality’. Un caso típico de datos anidados es el agrupar la tabla de acuerdo a una variable categórica y aplicar la función nest de tidyr. Esto genera una columna ‘data’, del tipo lista, donde se almacena una tabla para cada nivel de la variable agrupadora. airq_nest = airq %&gt;% group_by(Month) %&gt;% nest() El poder de los datos anidados es la combinación de mutate (dplyr) para generar nuevas columnas, y de las funciones map (purrr) para iterar sobre una columna tipo lista. De forma general esta combinación se plasma de la siguiente forma: mutate(nueva_columna = map(columna_lista, ~ .f(.x))), donde ‘nueva_columna’ es el nombre de la columna a crear, ‘columna_lista’ es el nombre de la columna tipo lista sobre la cual se va a iterar, y ~ .f(.x) es la función o secuencia de funciones a realizar sobre cada elemento (.x) de la ‘columna_lista’. Aplicando lo mencionado anteriormente sobre la tabla anidada ‘airq_nest’ se tienen los siguientes pasos, en diferentes mutate: mod = map(data, ~lm(Wind ~ Temp, data = .x)): Crea una nueva columna ‘mod’, que va a ser el resultado de un modelo lineal para cada mes (iterando sobre ‘data’), en función del viento (‘Wind’) y la temperatura (‘Temp’). La función para modelos lineales es lm y el primer argumento es la formula que lleva la estructura y ~ x, el argumento data se pone de forma explicita y aquí es donde se le indica los elementos sobre los cuales iterar (.x). El resultado es una lista, de ahí que se usara map y no una de sus versiones. slope = map_dbl(mod, ~tidy(.) %&gt;% filter(term == 'Temp') %&gt;% pull(estimate)): Crea una nueva columna ‘slope’, que va a almacenar la pendiente del modelo lineal (‘mod’) anteriormente calculado, como se sabe que es un numero se usa map_dbl. r2 = map_dbl(mod, ~glance(.) %&gt;% pull(r.squared)): Crea una nueva columna ‘r2’, donde se va a almacenar el valor del coeficiente de determinación (\\(R^2\\)), como se sabe que es un numero se usa map_dbl. plot = map2(data,Month, ~ggplot(.x, aes(Temp, Wind)) + geom_point() + geom_smooth(method = 'lm') + labs(title = .y) + theme_bw(base_size = 12)): Crea una nueva columna, donde se va a almacenar el gráfico de dispersión para cada mes, y se le agrega un titulo para saber a que mes corresponde. En este caso se esta iterando sobre dos objetos, por lo que se usa map2: la columna tipo lista donde están los datos a graficar (‘data’), y la columna tipo factor (vector) donde esta la variable agrupadora (‘Month’) para poder poner el titulo correspondiente. airq_nest = airq_nest %&gt;% mutate(mod = map(data, ~lm(Wind ~ Temp, data = .x))) %&gt;% mutate(slope = map_dbl(mod, ~tidy(.) %&gt;% filter(term == &#39;Temp&#39;) %&gt;% pull(estimate)), r2 = map_dbl(mod, ~glance(.) %&gt;% pull(r.squared)), plot = map2(data,Month, ~ggplot(.x, aes(Temp, Wind)) + geom_point() + geom_smooth(method = &#39;lm&#39;) + labs(title = .y) + theme_bw(base_size = 12))) airq_nest ## # A tibble: 5 x 6 ## Month data mod slope r2 plot ## &lt;fct&gt; &lt;list&gt; &lt;list&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;list&gt; ## 1 Mayo &lt;tibble [31 × 6]&gt; &lt;lm&gt; -0.192 0.139 &lt;gg&gt; ## 2 Junio &lt;tibble [30 × 6]&gt; &lt;lm&gt; -0.0691 0.0146 &lt;gg&gt; ## 3 Julio &lt;tibble [31 × 6]&gt; &lt;lm&gt; -0.215 0.0932 &lt;gg&gt; ## 4 Agosto &lt;tibble [31 × 6]&gt; &lt;lm&gt; -0.249 0.258 &lt;gg&gt; ## 5 Setiembre &lt;tibble [30 × 6]&gt; &lt;lm&gt; -0.236 0.325 &lt;gg&gt; 5.4.1 Efectos secundarios En algunas ocasiones el resultado de una iteración no corresponde con un vector, tabla o lista, sino que puede ser la creación de gráficos o el exportar objetos (lo que se conoce en ingles como ‘side effect’); para estos casos existe la función walk y sus variantes. En el primer ejemplo se quiere imprimir cada gráfico en la columna ‘plot’, por lo que se itera sobre la columna deseada, y se llama a la función ~ print(.) para que despliegue cada uno de los elementos. walk(airq_nest$plot, ~print(.)) Un resultado similar se puede obtener usando pull, donde se jala como vector los elementos de la columna deseada. airq_nest %&gt;% pull(plot) ## [[1]] ## ## [[2]] ## ## [[3]] ## ## [[4]] ## ## [[5]] El ultimo ejemplo hace uso de walk2 ya que se desea iterar sobre dos objetos: la columna de gráficos (‘plot’) y la columna agrupadora (‘Month’). Lo que se desea realizar es exportar cada gráfico por separado, de ahí la necesidad de usar ambos objetos, el gráfico a exportar y la variable agrupadora para incluirla en el nombre del archivo. Para esto ultimo se usa la función str_glue de stringr que lo que hace es crear una linea de texto donde se pueden ingresar variables usando {variable}. En el ejemplo específicamente, se guarda cada gráfico en la carpeta ‘figures’, con el nombre ‘regresion_{.y}.png’, donde ‘{.y}’ corresponde con el segundo objeto a iterar, en este caso el mes (‘Month’). walk2(airq_nest$plot, airq_nest$Month, ~ggsave(filename = str_glue(&quot;figures/regresion_{.y}.png&quot;), plot = .x, dpi = 300, width = 7, height = 4, units = &quot;in&quot;, type = &quot;cairo&quot;)) 5.5 Datos anidados, caso 2 En este caso 2 se trabaja con los datos de ‘gapminder’, donde se agrupa por país (‘country’), y se crea una tabla para cada país. Este caso es bastante ilustrativo del poder de los tibbles y la iteración, ya que la tabla anidada cuenta con 142 filas (1 por país), y si se quisiera realizar una tarea por país a pie, seria muy tedioso y poco eficiente. gap_nest = gapminder %&gt;% group_by(country) %&gt;% nest() De manera similar al caso 1, se genera un modelo lineal para cada país en función de la expectativa de vida (‘lifeExp’) por año (‘year’), y adicionalmente se calcula el coeficiente de determinación (\\(R^2\\)) para cada modelo lineal. gap_nest = gap_nest %&gt;% mutate(mod = map(data, ~lm(lifeExp ~ year, data = .x))) %&gt;% mutate(r2 = map_dbl(mod, ~glance(.) %&gt;% pull(r.squared))) gap_nest ## # A tibble: 142 x 4 ## country data mod r2 ## &lt;fct&gt; &lt;list&gt; &lt;list&gt; &lt;dbl&gt; ## 1 Afghanistan &lt;tibble [12 × 5]&gt; &lt;lm&gt; 0.948 ## 2 Albania &lt;tibble [12 × 5]&gt; &lt;lm&gt; 0.911 ## 3 Algeria &lt;tibble [12 × 5]&gt; &lt;lm&gt; 0.985 ## 4 Angola &lt;tibble [12 × 5]&gt; &lt;lm&gt; 0.888 ## 5 Argentina &lt;tibble [12 × 5]&gt; &lt;lm&gt; 0.996 ## 6 Australia &lt;tibble [12 × 5]&gt; &lt;lm&gt; 0.980 ## 7 Austria &lt;tibble [12 × 5]&gt; &lt;lm&gt; 0.992 ## 8 Bahrain &lt;tibble [12 × 5]&gt; &lt;lm&gt; 0.967 ## 9 Bangladesh &lt;tibble [12 × 5]&gt; &lt;lm&gt; 0.989 ## 10 Belgium &lt;tibble [12 × 5]&gt; &lt;lm&gt; 0.995 ## # … with 132 more rows Con los datos anteriores se pueden filtrar los países que hayan tenido un \\(R^2\\) por debajo de 0.25, lo que seria indicio de un comportamiento no lineal, lo que podría estar asociado a problemas de desarrollo en esos países. Para poder graficar los datos es necesario desanidarlos (unnest) para volver a contar con las columnas a como estaban en la tabla original, pero ahora con las columnas calculadas en las iteraciones. gap_nest %&gt;% # ungroup() %&gt;% # arrange(r2) %&gt;% # slice(1:10) %&gt;% filter(r2 &lt; .25) %&gt;% unnest(data) %&gt;% ggplot() + geom_line(aes(year, lifeExp, col = country, group = country)) 5.6 Recursos Se presentan recursos a consultar para ahondar más en los temas presentados. tidyverse Modern R with the tidyverse (Capítulo 8) Referencias "],
["datos-espaciales.html", "Capítulo 6 Datos espaciales 6.1 Paquetes para datos espaciales 6.2 Sistemas de Referencias de Coordenadas (CRS) 6.3 Importar datos 6.4 Exportar datos 6.5 Mapas 6.6 Recursos", " Capítulo 6 Datos espaciales En este capitulo se presenta una breve introducción al uso de R como ambiente para trabajar datos espaciales. Los paquetes a utilizar son: library(sp) library(sf) library(ggspatial) library(raster) library(stars) library(viridis) library(rgeos) library(rgdal) library(mapview) library(RColorBrewer) library(ggrepel) library(rio) library(tmap) library(tidymodels) library(tidyverse) library(rayshader) 6.1 Paquetes para datos espaciales La comunidad de R ha desarrollado una gran variedad de paquetes para datos espaciales, algunos de los cuales han ido evolucionando y facilitando la manipulación y presentación de los mismos. Dentro de los paquetes más usados están: sf (Pebesma, 2020): Para datos vectoriales dentro de la filosofía tidyverse sp (Pebesma &amp; Bivand, 2019): El predecesor de sf para datos vectoriales y en grilla (no exactamente raster) raster (Hijmans, 2020): Para datos raster stars (Pebesma, 2019): El candidato a suceder a raster rgeos y rgdal (Bivand et al., 2019; Bivand &amp; Rundel, 2019): Interfaces para librerías básicas de manipulación de datos espaciales ggplot2 y tmap (Tennekes, 2019): Creación de mapas estáticos (tmap puede crear mapas interactivos) mapview y leaflet (Appelhans, Detsch, Reudenbach, &amp; Woellauer, 2020; Cheng, Karambelkar, &amp; Xie, 2018): Creación de mapas interactivos Otro montón de paquetes brindan funciones adicionales y funciones para tareas especificas. 6.2 Sistemas de Referencias de Coordenadas (CRS) Los datos espaciales tienen por lo general un sistema de coordenadas asociado (geográficas, lambert, UTM, etc.). Estos sistemas se pueden identificar por medio de códigos EPSG que han sido estandarizados para uso general. Como ejemplo, las coordenadas geográficas en grados (WGS84) tiene el código 4326, las coordenadas geográficas en metros (WGS84/pseudo-mercator; son las utilizadas por GoogleMaps y otros) tiene el codigo 3857. Las coordenadas para Costa Rica con la proyección CRTM05 tienen el codigo 5367, mientras que para la proyección Lambert Norte tienen el codigo 5456. Todos estos se pueden obtener por medio del sitio web epsg.io o en QGIS a la hora de buscar sistemas de coordenadas ahí aparece el codigo. 6.3 Importar datos 6.3.1 Desde archivos de texto Datos en archivos de texto (.txt, .csv, etc. y principalmente para datos puntuales) se pueden importar de manera convencional con rio::import. datos &lt;- rio::import(&quot;data/BroomsBarn.txt&quot;, setclass = &#39;tibble&#39;) %&gt;% mutate(x = x*40, y = y*40, logK = log(K), logP = log(P)) Posteriormente pueden convertirse a datos espaciales (st_as_sf), indicando la posición o el nombre de las columnas con las coordenadas X,Y y asignándole un CRS. datos_sf = st_as_sf(datos, coords = 1:2, crs = NA, remove = F) La ventaja de sf es que permite manipular los dato asociados al objeto espacial haciendo uso de los verbos del tidyverse. datos_sf %&gt;% filter(pH &gt; 8) ## # A tibble: 163 x 8 ## x y K logK pH P logP geometry ## &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;POINT&gt; ## 1 80 1240 14 2.64 8.2 6.6 1.89 (80 1240) ## 2 120 40 28 3.33 8.2 4.2 1.44 (120 40) ## 3 120 80 26 3.26 8.2 7.5 2.01 (120 80) ## 4 120 120 23 3.14 8.2 5.1 1.63 (120 120) ## 5 120 160 21 3.04 8.2 4 1.39 (120 160) ## 6 120 240 22 3.09 8.3 4.8 1.57 (120 240) ## 7 120 280 24 3.18 8.3 4.8 1.57 (120 280) ## 8 120 320 41 3.71 8.2 4 1.39 (120 320) ## 9 120 1240 15 2.71 8.2 8.4 2.13 (120 1240) ## 10 160 80 24 3.18 8.2 6.7 1.90 (160 80) ## # … with 153 more rows Para algunas funciones todavía es necesario usar objetos sp por lo que se pueden crear estos a partir de los objetos sf. datos_sp = as(datos_sf, &#39;Spatial&#39;) coordnames(datos_sp) = c(&#39;X&#39;,&#39;Y&#39;) 6.3.2 Desde archivos espaciales 6.3.2.1 Shapefiles De igual manera se pueden importar/leer directamente datos en muchos formatos espaciales (ejemplo: shapefiles, geopackage, raster, etc.). Las funciones para leer datos son: st_read y read_sf; la primera importa los datos como DataFrame, la segunda como tibble. fallas = read_sf(&#39;data/fallas.shp&#39;) geomorfo = read_sf(&#39;data/geomorfo.shp&#39;) En este caso no reconocen los metadatos de la proyeccion por lo que se les puede asignar por medio de st_set_crs, donde el argumento necesario es el codigo EPSG. fallas_ln = fallas %&gt;% st_set_crs(5456) geomorfo_ln = geomorfo %&gt;% st_set_crs(5456) Si se desean transformar a otro sistema se usa st_transform, donde, de nuevo, el argumento necesario es el codigo EPSG del sistema destino (En el caso del ejemplo a coordenadas geográficas). fallas_geog = fallas_ln %&gt;% st_transform(4326) geomorfo_geog = geomorfo_ln %&gt;% st_transform(4326) 6.3.2.2 Geopackage Si se tiene un archivo .gpkg es necesario explorar primero las capas disponibles para luego importar los datos deseados. Esto se realiza con st_layers y la dirección del archivo geopackage. st_layers(dsn = &#39;data/espaciales.gpkg&#39;) ## Driver: GPKG ## Available layers: ## layer_name geometry_type features fields ## 1 fallas Line String 2028 7 ## 2 geomorfo Polygon 467 6 Una vez se han identificado las capas se pueden importar con cualquiera de los métodos deseados, donde el argumento a especificar es layer y el nombre de la capa a importar. fallas2 = read_sf(&#39;data/espaciales.gpkg&#39;, layer = &#39;fallas&#39;) geomorfo2 = read_sf(&#39;data/espaciales.gpkg&#39;, layer = &#39;geomorfo&#39;) 6.3.2.3 Raster Para leer rasters de una banda se usa la función raster, para rasters multi-banda se puede usar brick. Para objetos stars es indiferente y se pueden leer por medio de read_stars. Para convertir de raster a stars se usa st_as_stars. La lectura de un raster de una banda se ejemplifica con un modelo de elevación digital del Pacifico. pacifico = raster(&#39;data/pacifico.tif&#39;) pacifico ## class : RasterLayer ## dimensions : 300, 300, 90000 (nrow, ncol, ncell) ## resolution : 0.01661111, 0.01661111 (x, y) ## extent : -87.99167, -83.00833, 5.008333, 9.991667 (xmin, xmax, ymin, ymax) ## crs : +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0 ## source : /Users/maximiliano/Documents/UCR/Docencia/Extras/R/bookdown/geolonum/data/pacifico.tif ## names : pacifico ## values : -4770, 3601 (min, max) pacifico_stars = read_stars(&#39;data/pacifico.tif&#39;) pacifico_stars = st_as_stars(pacifico) pacifico_stars ## stars object with 2 dimensions and 1 attribute ## attribute(s): ## pacifico ## Min. :-4770 ## 1st Qu.:-3144 ## Median :-2417 ## Mean :-2155 ## 3rd Qu.:-1627 ## Max. : 3601 ## dimension(s): ## from to offset delta refsys point values ## x 1 300 -87.9917 0.0166111 +proj=longlat +datum=WGS8... NA NULL [x] ## y 1 300 9.99167 -0.0166111 +proj=longlat +datum=WGS8... NA NULL [y] La lectura de un raster multi-banda se ejemplifica con un geotiff que viene con el paquete stars. sat_ras = brick(system.file(&#39;tif/L7_ETMs.tif&#39;, package = &#39;stars&#39;)) sat_ras ## class : RasterBrick ## dimensions : 352, 349, 122848, 6 (nrow, ncol, ncell, nlayers) ## resolution : 28.5, 28.5 (x, y) ## extent : 288776.3, 298722.8, 9110729, 9120761 (xmin, xmax, ymin, ymax) ## crs : +proj=utm +zone=25 +south +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs ## source : /Library/Frameworks/R.framework/Versions/3.6/Resources/library/stars/tif/L7_ETMs.tif ## names : L7_ETMs.1, L7_ETMs.2, L7_ETMs.3, L7_ETMs.4, L7_ETMs.5, L7_ETMs.6 ## min values : 0, 0, 0, 0, 0, 0 ## max values : 255, 255, 255, 255, 255, 255 sat_df = as.data.frame(sat_ras,xy=T) sat_stars = read_stars(system.file(&#39;tif/L7_ETMs.tif&#39;, package = &#39;stars&#39;)) sat_stars ## stars object with 3 dimensions and 1 attribute ## attribute(s): ## L7_ETMs.tif ## Min. : 1.00 ## 1st Qu.: 54.00 ## Median : 69.00 ## Mean : 68.91 ## 3rd Qu.: 86.00 ## Max. :255.00 ## dimension(s): ## from to offset delta refsys point values ## x 1 349 288776 28.5 NA FALSE NULL [x] ## y 1 352 9120761 -28.5 NA FALSE NULL [y] ## band 1 6 NA NA NA NA NULL 6.4 Exportar datos 6.4.1 Vectoriales Para exportar datos vectoriales se puede usar st_write, donde se define el objeto espacial a exportar y el tipo de archivo a generar (.shp, .gpkg, etc.). Las opciones layer_options = 'OVERWRITE=YES' y delete_layer = T permiten reescribir un objeto si ya se encontraba presente en la carpeta destino. st_write(fallas_geog, dsn = &#39;data/espaciales_geog.gpkg&#39;, layer = &#39;fallas&#39;, layer_options = &#39;OVERWRITE=YES&#39;, quiet = T, delete_layer = T) st_write(geomorfo_geog, dsn = &#39;data/espaciales_geog.gpkg&#39;, layer = &#39;geomorfo&#39;, layer_options = &#39;OVERWRITE=YES&#39;, quiet = T, delete_layer = T) Se puede revisar que el objeto haya sido creado apropiadamente, de nuevo usando st_layers. st_layers(dsn = &#39;data/espaciales_geog.gpkg&#39;) ## Driver: GPKG ## Available layers: ## layer_name geometry_type features fields ## 1 fallas Line String 2028 7 ## 2 geomorfo Polygon 467 6 6.4.2 Raster Dependiendo de si el objeto es raster o stars, se deberá usar la función respectiva, writeRaster o write_stars. en el caso de writeRaster se tiene que especificar el formato (para esto se puede consultar la ayuda de la función). writeRaster(sat_ras, &#39;data/imagen_satelite.tif&#39;, format=&quot;GTiff&quot;, overwrite=TRUE) write_stars(sat_stars, &#39;data/imagen_satelite_stars.tif&#39;) 6.5 Mapas Existen diferentes formas de graficar datos espaciales, aquí se presentan las más usadas, donde se recomienda ggplot2 o tmap. El primero ya que se esta familiarizado con el funcionamiento del mismo y es nada más agregar un par de funciones especificas para datos espaciales; el segundo ya que es especifico para datos espaciales siguiendo una idea similar a ggplot2. 6.5.1 Estáticos 6.5.1.1 básico Todos los objetos espaciales tienen un método de ploteo básico (plot). Si el objeto tiene más de 1 atributo va a plotear todos o los que pueda. Para evitar esto se puede especificar cual atributo se quiere plotear. En general esto se puede usar más para una visualización rápida pero no para mapas finales. Se muestran diferentes opciones para visualizar los diferentes tipos de datos, pero no se muestra el mapa final por ser muy básico. plot(fallas_ln) plot(datos_sf[,&#39;K&#39;]) plot(geomorfo_ln[,&#39;CODIGO&#39;]) plot(pacifico) plot(pacifico_stars) 6.5.1.2 ggplot El paquete ggplot tiene geometrías especificas para objetos sf (vector) y stars (raster o grillas), por lo que facilita la creación de mapas en un ambiente ya conocido. La forma más básica de crear un mapa vectorial usando ggplot es usando geom_sf y especificando el argumento data que corresponde con el objeto espacial, pero por defecto despliega coordenadas geográficas (Figura 6.1). ggplot() + geom_sf(data = fallas_ln) Figura 6.1: Mapa básico en ggplot2 Para que el mapa se despliegue en las coordenadas del objeto y no geográficas, hay que cambiar el argumento datum en coord_sf al CRS del archivo deseado (Figura 6.2). ggplot() + geom_sf(data = fallas_ln) + coord_sf(datum = st_crs(fallas_ln)) Figura 6.2: Mapa en ggplot2 con el datum modificado El paquete ggspatial (Dunnington, 2018) ofrece algunas capas adicionales especificas (elementos cartográficos) para datos espaciales, con las cuales se pueden agregar una escala (annotation_scale) y el norte (annotation_north_arrow), ademas de poder agregar un mapa de fondo (annotation_map_tile), donde zoom define el nivel de detalle, a menor zoom menor detalle (Figura 6.3). ggplot() + annotation_map_tile(zoom = 8) + geom_sf(data = fallas_ln) + coord_sf(datum = st_crs(fallas_ln)) + annotation_scale(location = &#39;bl&#39;) + annotation_north_arrow(location = &#39;tr&#39;, height = unit(.75, &quot;cm&quot;), width = unit(.75, &quot;cm&quot;)) Figura 6.3: Mapa en ggplot con elementos cartográficos (escala y norte) Para datos puntuales (Figura 6.4) o de polígonos (Figura 6.5) se puede especificar una columna de los datos, por la cual colorear los puntos. ggplot() + geom_sf(data = datos_sf, aes(col = K), size = 3, alpha = 0.6) + scale_color_viridis_c() Figura 6.4: Mapa de puntos en ggplot coloreados por la variable “K” ggplot() + geom_sf(aes(fill = as_factor(FORMA)), data = geomorfo_ln) + coord_sf(datum = st_crs(geomorfo_ln)) + scale_fill_brewer(palette = &#39;Set3&#39;) Figura 6.5: Mapa de polígonos en ggplot coloreados por la variable “FORMA” La forma de crear un mapa a partir de un objeto stars (grilla de una banda) es por medio de geom_stars, donde, de nuevo, se especifica el objeto espacial en el argumento data. En este caso automáticamente se aplica al relleno (fill) la variable del objeto. Ademas, es necesario agregar coord_equal para que los ejes de coordenadas tengan las misma escala (Figura 6.6). ggplot() + geom_stars(data = pacifico_stars) + scale_fill_gradient(low = &#39;black&#39;, high = &#39;white&#39;, na.value = &#39;white&#39;) + coord_equal() Figura 6.6: Mapa de objeto stars en ggplot. Se especifica el relleno como un gradiente y se aplica la misma escala a ámbos ejes Para imágenes multi-banda es necesario transforma el objeto espacial en una tabla (sat_df = as.data.frame(sat_ras,xy=T)) y graficar el relleno (fill) usando la función rgb, donde se especifica el nombre de las bandas que corresponde con cada uno de los canales rgb, y se debe definir maxColorValue=255 (Figura 6.7). Como lo que se va a graficar es una grilla se usa la función geom_tile, y de nuevo es necesario definir los ejes de coordenadas iguales con coord_equal. ggplot(sat_df, aes(x, y, fill=rgb(red = L7_ETMs.3, green = L7_ETMs.2, blue = L7_ETMs.1, maxColorValue = 255))) + geom_tile() + scale_fill_identity() + coord_equal() + scale_x_continuous(expand = c(0,0)) + scale_y_continuous(expand = c(0,0)) + theme(axis.text.y = element_text(angle = 90, hjust = .5)) Figura 6.7: Mapa de color verdadero para una imagen satelital multi-banda 6.5.1.3 tmap El paquete tmap es una opción especifica para datos espaciales y sigue la misma ideología de ggplot al trabajar en capas. Por defecto no despliega la grilla de coordenadas, hay que agregárselas con tm_grid. Para revertir los colores en la paleta se le agrega un menos (-) antes del nombre, y para colocar la leyenda fuera del área del mapa se debe usar tm_layout(legend.outside = T). Existen opciones globales para los mapas generados con tmap, estas se pueden modificar con tmao_options, y uno de los argumentos es la leyenda afuera, así no hay que aplicarlo en cada mapa por separado. tmap_options(legend.outside = T) La estructura básica de cualquier gráfico es: tm_shape(shp = &lt;DATA&gt;) + &lt;tm_function&gt;(col = &lt;&#39;VARIABLE&#39;&gt;, palette = &#39;&#39;, style = &#39;&#39;, n = 5) + &lt;tm_layout&gt; + &lt;tm_xlab&gt; + &lt;tm_ylab&gt; + &lt;tm_grid&gt; + &lt;tm_scale_bar&gt; + &lt;tm_compass&gt; + Se pueden agregar diferentes objetos espaciales agregando diferentes tm_shape. A diferencia de ggplot y geom_sf que era una función para todo objeto vectorial, es necesario definir el tipo de objeto con las diferentes funciones tm_*. Lo que se va a hacer es recrear los mapas de la sección anterior pero con tmap. Un mapa básico se observa en la Figura 6.8, donde se grafican las líneass de falla. tm_shape(fallas_ln) + tm_lines() Figura 6.8: Mapa básico con tmap El mapa de puntos se crea por medio de tm_dots. Por defecto tmap discretiza los datos (Figura 6.9), pero si se quiere representar como un gradiente (Figura 6.10) es necesario definir style = 'cont', para continuo. tm_shape(datos_sf) + tm_dots(&#39;K&#39;, size = .3, palette = &#39;viridis&#39;) Figura 6.9: Mapa de puntos con tmap coloreado de acuerdo a una variable tm_shape(datos_sf) + tm_dots(&#39;K&#39;, size = .3, palette = &#39;viridis&#39;, style = &#39;cont&#39;) + tm_layout(legend.outside = T) Figura 6.10: Mapa de puntos con tmap coloreado de acuerdo a una variable, con la leyenda tipo gradiente En la Figura 6.11 se observa un mapa de polígonos, donde ademas se agrega la grilla de coordenadas pero sin las líneas. geomorfo_ln %&gt;% mutate(FORMA = as_factor(FORMA)) %&gt;% tm_shape() + tm_polygons(&#39;FORMA&#39;) + tm_grid(lines = F) Figura 6.11: Mapa de poligonos con tmap, agregando la grilla de coordenadas sin la líneas internas Para graficar objetos raster de una banda se usa tm_raster (Figura 6.12), donde hay que definir la paleta de colores a usar. Si se desea invertir simplemente se le agrega un - en frente del nombre. tm_shape(pacifico) + tm_raster(palette = &#39;-Greys&#39;, style = &#39;cont&#39;) Figura 6.12: Mapa raster con tmap Para ver las opciones de las paletas de color se puede usar: tmaptools::palette_explorer() Para graficar objetos raster multi-banda se debe usar tm_rgb (Figura 6.13) y especificar el orden de las bandas que corresponde con cada uno de los canales rgb. tm_shape(sat_ras) + tm_rgb(r = 3, g = 2, b = 1) Figura 6.13: Mapa de color verdadero con tmap Finalmente, tmap trae incorporadas funciones para agregar escala (tm_scale_bar) y norte (tm_compass) (Figura 6.14). tm_shape(fallas_ln) + tm_lines() + tm_scale_bar(width = .2,position = c(&#39;left&#39;,&#39;bottom&#39;)) + tm_compass(position = c(&#39;right&#39;,&#39;top&#39;)) Figura 6.14: Mapa incorporando elementos de escala y norte Para salvar un mapa de tmap como imagen se usa tmap_save. Idealmente hay que guardar el mapa en un objeto. mapa1 = tm_shape(fallas_ln) + tm_lines() + tm_scale_bar(width = .2,position = c(&#39;left&#39;,&#39;bottom&#39;)) + tm_compass(position = c(&#39;right&#39;,&#39;top&#39;)) tmap_save(mapa1, &#39;figures/mapa_fallas.png&#39;, dpi = 300) 6.5.2 Dinámicos Una de la opciones con mapas interactivos es que se pueden definir diferentes mapas de fondo. Dentro de los más usados están los que se muestran a continuación: mybasemaps = c(&#39;CartoDB.Positron&#39;, &#39;OpenStreetMap&#39;, &#39;OpenTopoMap&#39;, &#39;Esri.WorldImagery&#39;, &#39;Esri.WorldTopoMap&#39;, &#39;Esri.OceanBasemap&#39;) De manera general se pueden asignar mapas de fondo para todos los mapas de una sesión definiéndolos en las opciones de tmap y mapview: tmap_options(basemaps = mybasemaps) mapviewOptions(basemaps = mybasemaps) La Figura 6.15 muestra las diferentes opciones para manipular un mapa dinámico creado con mapview. Las mismas opciones y elementos se pueden agregar a un mapa de leaflet pero requieren ser especificadas explícitamente (haciendo más largo el codigo), mientras que mapview ya agrega muchos de estos por defecto. Figura 6.15: Partes de un mapa dinámico creado con mapview 6.5.2.1 tmap Este paquete ofrece la opción de visualizar un mapa estático como dinámico, cambiando el modo de visualización (tmap_mod(mode = c('plot','view'))), donde plot es para mapas estático y view para mapas dinámicos y traduce el mapa a un mapa leaflet. Lo anterior cambia el modo para todos los mapas que se creen a partir de que esto se modifica. Para visualizar de manera dinámica un mapa guardado en un objeto se puede usar tmap_leaflet, que genera un mapa leaflet a partir de uno de tmap, pero solo para el mapa que se quiere (Figura 6.16). Para demostrar esto se genera el mapa dinámico a partir del mapa que se salvo anteriormente (mapa1), que corresponde con la Figura 6.8. tmap_leaflet(mapa1) Figura 6.16: Mapa interactivo leaflet a partir de un mapa estático tmap 6.5.2.2 mapview Este paquete permite generar mapas interactivos de manera eficiente y rápida, pero no brinda la personalización de leaflet, el cual es mucho más complejo y para generar un mapa similar se requiere aproximadamente de 4 a 5 veces mas líneass de codigo. La función básica es mapview donde se le pasa el objeto espacial. Por defecto le asigna un color único. El argumento layer_name es para definir el nombre que se quiere aparezca en la leyenda. Si se desean agregar diferentes capas simplemente se agregan funciones mapview con el operador + (Figura 6.17). mapview es inteligente en el sentido de que dependiendo del tipo de objeto (polígono, líneas, punto) lo va a graficar en el orden jerarquico visual (puntos por encima de líneass, líneass por encima de polígonos). mapview(fallas_ln, layer.name = &#39;Fallas&#39;, color = &#39;red&#39;) + mapview(geomorfo_ln, layer.name = &#39;Geomorfologia&#39;) Figura 6.17: Mapa con mapview, donde se pueden combinar objetos espaciales usando el operador + Se pueden colorear objetos espaciales definiendo una columna de la tabla de atributos por medio del argumento zcol (Figura 6.18). mapview(datos_sf, zcol = &#39;logK&#39;, layer.name = &#39;logK&#39;) Figura 6.18: Mapa de puntos con mapview coloreados de acuerdo a una variable Para graficar objetos raster de una banda simplemente se pasa el objeto a la función mapview (Figura 6.19). Para raster multi-banda se debe usar viewRGB y definir el orden de las bandas de acuerdo a los canales rgb (Figura 6.20). mapview(pacifico) Figura 6.19: Mapa raster con mapview viewRGB(sat_ras, r = 3, g = 2, b = 1) Figura 6.20: Mapa de color verdradero con mapview Con mapview se pueden crear diferentes mapas y sincronizarlos por medio de sync del paquete leafsync (Simplemente se muestra el codigo). m1 = mapview(franconia, zcol = &#39;district&#39;, layer.name = &#39;Distrito&#39;) m2 = mapview(breweries, legend = F) leafsync::sync(m1, m2) 6.5.3 Modelos de sombras Para generar modelos de sombras en 2D y 3D se usa el paquete rayshader (Morgan-Wall, 2019), el cual funciona a partir de objetos raster. Funciona con el pipe operator (%&gt;%), por lo que es familiar a trabajar en el tidyverse. Primero hay que pasar el raster a matriz. pacifico_mat = raster_to_matrix(pacifico) Para mejorar la apariencia del modelo de sombras es recomendado agregar diferentes sombras (‘shades’), las cuales son calculadas de diferente manera para resaltar diferentes aspectos del modelo. zscale = 200 elmat = pacifico_mat raymat = ray_shade(elmat, zscale = zscale) ambmat = ambient_shade(elmat, zscale = zscale) lambmat = lamb_shade(elmat, zscale = zscale) Para generar un modelo de sombras en 2D, se empieza con la matriz de elevación, se le agregan las diferentes capas, y para mostrar el mapa se termina la cadena de comandos con plot_map (Figura 6.21). elmat %&gt;% sphere_shade(texture = &quot;bw&quot;) %&gt;% add_shadow(raymat, 0.5) %&gt;% add_shadow(lambmat, 0.5) %&gt;% add_shadow(ambmat, 0.5) %&gt;% plot_map() Figura 6.21: Modelo de sombras en 2D Para generar el modelo en 3D (Figura 6.22), simplemente se termina la cadena de comandos con plot_3d. Esto abre una ventana interactiva donde se puede manipular el modelo, en este caso simplemente se toma una captura de la apariencia en 3D. elmat %&gt;% sphere_shade(texture = &quot;imhof1&quot;) %&gt;% add_shadow(raymat, 0.5) %&gt;% add_shadow(lambmat, 0.5) %&gt;% add_shadow(ambmat, 0.5) %&gt;% plot_3d(elmat, zscale = zscale, water = T, theta = 0, phi = 40, zoom = .5, windowsize = c(1000,600)) render_snapshot(clear=TRUE) Figura 6.22: Model de sombras en 3D Adicionalmente se puede crear una pequeña película o animación con render_movie (No se presenta aquí pero se muestra el codigo). elmat %&gt;% sphere_shade(texture = &quot;imhof1&quot;) %&gt;% add_shadow(raymat, 0.5) %&gt;% add_shadow(lambmat, 0.5) %&gt;% add_shadow(ambmat, 0.5) %&gt;% plot_3d(elmat, zscale = zscale, water = T, theta = 0, phi = 40, zoom = .5, windowsize = c(1000,600)) render_movie(filename = &#39;modelo3D&#39;) rgl::rgl.close() 6.6 Recursos Se presentan recursos a consultar para ahondar más en los temas presentados. Geocomputatio with R Es un libro virtual donde se introducen conceptos de como usar R para análisis espacial y creación de mapas. Spatial Data Sience Intro to GIS and Spatial Analysis RSpatial Geoestadistica con R (El sitio web está en polaco, pero se puede traducir en Chrome) Introducción a estadística con R (Capítulo 7) Spatial workshop notes sf tmap stars mapview leaflet rayshader Referencias "],
["álgebra-lineal.html", "Capítulo 7 Álgebra lineal 7.1 Tensores 7.2 Eigenvectors y Eigenvalues", " Capítulo 7 Álgebra lineal Este capitulo hace una introducción básica a conceptos y técnicas en álgebra lineal. 7.1 Tensores En general cualquier arreglo de datos numéricos se considera un tensor de dimensión variable, dependiendo de la estructura de los datos. Un tensor es una representación matemática que cuantifica la variación de la magnitud con respecto a la dirección. Numéricamente se representa como una matriz y gráficamente como un elipsoide, en el caso de 3 dimensiones (Figura 7.1). Figura 7.1: Tensor como elipsoide. Tomado de: http://www.geosci.usyd.edu.au/users/prey/Teaching/Geol-3101/Strain/ellipse.gif Los tensores más conocidos son: Escalar: Tensor de orden 0, cantidad que tiene magnitud pero no dirección. Ejemplos: densidad y temperatura. Vector: Tensor de orden 1, cantidad que tiene magnitud y dirección. Ejemplos: velocidad, aceleración, fuerza. Matriz: Tensor de orden 2 o mas, arreglo de vectores en 2 o más dimensiones, con magnitud y 2 o más direcciones. Ejemplos: esfuerzo, deformación. 7.1.1 Vectores Los vectores son representaciones univariables de datos, ya que pueden almacenar únicamente un tipo de datos. En el sentido estricto de álgebra los datos tienen que ser del tipo numérico. Los vectores se denotan con letras minúsculas (ej: \\(x\\)). La estructura y representación matemática de un vector se presenta en Ecuación (7.1), mientras que la representación gráfica se presenta en la Figura 7.2: \\[\\begin{equation} x = \\left( \\begin{matrix} x_1\\\\ x_2\\\\ \\vdots\\\\ x_n \\end{matrix} \\right) \\tag{7.1} \\end{equation}\\] donde \\(n\\) corresponde con la dimensión del vector. Figura 7.2: Representacion grafica de un vector. Tomado de: http://www.cyberphysics.co.uk/graphics/diagrams/forces/vector_components4.gif 7.1.1.1 Operaciones con vectores Suma: \\[\\begin{equation} x + y = \\left( \\begin{matrix} x_1\\\\ x_2\\\\ \\vdots\\\\ x_n \\end{matrix} \\right) + \\left( \\begin{matrix} y_1\\\\ y_2\\\\ \\vdots\\\\ y_n \\end{matrix} \\right) \\tag{7.2} \\end{equation}\\] Se requiere que ambos vectores tengan la misma dimensión. Un ejemplo seria cuando un vector contiene la concentración de \\(Fe^{2+}\\) y otro la de \\(Fe^{3+}\\), al sumarlos se obtiene la concentración total de \\(Fe\\) en la roca. En R esto se realiza simplemente creando los vectores respectivos y sumandolos, porque por defecto hace la suma elemento por elemento. Fe2 = c(2,5,4,7,10) Fe3 = c(4,8,3,5,9) Fe = Fe2 + Fe3 Fe ## [1] 6 13 7 12 19 Multiplicación por escalar: \\[\\begin{equation} \\alpha x = \\left( \\begin{matrix} \\alpha x_1\\\\ \\alpha x_2\\\\ \\vdots\\\\ \\alpha x_n \\end{matrix} \\right) \\tag{7.3} \\end{equation}\\] El escalar multiplica a cada uno de los elementos. Un ejemplo seria cuando se tienen mediciones (decenas o cientos) de la longitud de fósiles en pulgadas y se desean convertir a milímetros, entonces se multiplica el vector por 25.4. Para demostralo en R primero estoy creando un vector aleatorio de 20 datos con limite inferior de 10 y limite superior de 30. Imprimo los resultados para ver los valores, y posteriormente multiplico el vector por el escalar respectivo, de nuevo donde la operacion es elemento por elemento. set.seed(4101) longitud = runif(n = 20, min = 10, max = 30) longitud ## [1] 20.27580 15.18745 17.46071 15.10536 29.76256 16.82955 19.37020 22.68005 ## [9] 20.54253 10.93677 12.86850 23.29475 17.20729 28.22859 13.06465 17.29120 ## [17] 22.63767 20.98795 25.27941 23.90460 25.4 * longitud ## [1] 515.0054 385.7612 443.5020 383.6761 755.9691 427.4706 492.0031 576.0732 ## [9] 521.7804 277.7939 326.8600 591.6867 437.0653 717.0062 331.8420 439.1964 ## [17] 574.9968 533.0940 642.0970 607.1768 Producto punto: \\[\\begin{equation} x y = \\left( \\begin{matrix} x_1\\\\ x_2\\\\ \\vdots\\\\ x_n \\end{matrix} \\right) \\left( \\begin{matrix} y_1 &amp; y_2 &amp; \\dotsb &amp; y_n \\end{matrix} \\right) = x_1 y_1 + x_2 y_2 + \\dotsb + x_n y_n \\tag{7.4} \\end{equation}\\] Se requiere que ambos vectores tengan la misma dimensión. Un ejemplo seria cuando el precio de los diferentes agregados (piedra de construcción) se encuentra en un vector y la cantidad del tipo de agregado se tiene en otro vector; el precio a ganar al vender dicha cantidad de acuerdo al precio establecido es el resultado del producto punto. En R la forma de calcular el producto punto es haciendo uso del multiplicador matricial %*%, lo que arroja un resultado de una matriz de \\(1 \\times 1\\). Lo anterior es lo mismo a hacer la suma del producto entre los vectores. Estos procedimientos se muestran a continuación. precio = c(500, 700, 1200, 400) cantidad = c(30, 15, 12, 23) precio %*% cantidad ## [,1] ## [1,] 49100 sum(precio * cantidad) ## [1] 49100 7.1.2 Matrices Una matriz es una representación bivariable (2 columnas) o multivariable (&gt; 2 columnas) de datos. Similar a los vectores, en el sentido estricto de álgebra los datos tienen que ser del tipo numérico. Las matrices se denotan con letras mayúsculas (ej: \\(A\\)). La estructura y representación matemática de una matriz se presenta en Ecuación (7.5) \\[\\begin{equation} A = \\left( \\begin{matrix} a_{11} &amp; a_{12} &amp; a_{13}\\\\ a_{21} &amp; a_{22} &amp; a_{23}\\\\ a_{31} &amp; a_{32} &amp; a_{33} \\end{matrix} \\right) \\tag{7.5} \\end{equation}\\] La dimensión de una matriz es el numero de filas (por lo general denominado \\(i\\)) por el numero de columnas (por lo general denominado \\(j\\)), por lo que en el caso de la matriz mostrada en (7.5) la dimensión es 9 (\\(i \\times j\\)). Los subíndices denotan la ubicación del elemento, siendo el primer subíndice la fila y el segundo la columna; el elemento \\(a_{23}\\) corresponde al elemento en la fila 2 y columna 3. 7.1.2.1 Operaciones con matrices Suma: \\[\\begin{equation} A + B = \\left( \\begin{matrix} a_{11} &amp; a_{12} &amp; a_{13}\\\\ a_{21} &amp; a_{22} &amp; a_{23}\\\\ a_{31} &amp; a_{32} &amp; a_{33} \\end{matrix} \\right) + \\left( \\begin{matrix} b_{11} &amp; b_{12} &amp; b_{13}\\\\ b_{21} &amp; b_{22} &amp; b_{23}\\\\ b_{31} &amp; b_{32} &amp; b_{33} \\end{matrix} \\right) \\tag{7.6} \\end{equation}\\] Se requiere que ambas matrices tengan no solo la misma dimensión, pero la misma cantidad de filas y columnas. En este caso la operación es elemento por elemento \\(a_{11} + b_{11}\\). Un ejemplo seria donde una matriz contiene la producción de diversos tipos arcilla para un año dado y la otra tiene la producción para el año siguiente, la matriz resultante tiene la producción sobre esos dos años En R simplemente se hace la suma (o resta) de las matrices, ya que hace la operación elemento por elmento. A1 = matrix(data = c(105,218,220,63,80,76,5,2,1), nrow = 3) A2 = matrix(data = c(84,240,302,102,121,28,4,1,0), nrow = 3) A1 + A2 ## [,1] [,2] [,3] ## [1,] 189 165 9 ## [2,] 458 201 3 ## [3,] 522 104 1 Multiplicación por escalar: \\[\\begin{equation} \\alpha A = \\left( \\begin{matrix} \\alpha a_{11} &amp; \\alpha a_{12} &amp; \\alpha a_{13}\\\\ \\alpha a_{21} &amp; \\alpha a_{22} &amp; \\alpha a_{23}\\\\ \\alpha a_{31} &amp; \\alpha a_{32} &amp; \\alpha a_{33} \\end{matrix} \\right) \\tag{7.7} \\end{equation}\\] El escalar multiplica a cada uno de los elementos. Un ejemplo seria cuando se tienen mediciones de los ejes de cantos de piedra en pulgadas para diversos especímenes y se requiere tenerlos en milímetros, como se muestra en el siguiente ejemplo. cantos = matrix(data = c(3.4,4.6,5.4,2.2,4.3,4.7,1.8,4.3,4.7), nrow = 3) 25.4 * cantos ## [,1] [,2] [,3] ## [1,] 86.36 55.88 45.72 ## [2,] 116.84 109.22 109.22 ## [3,] 137.16 119.38 119.38 Multiplicación: \\[\\begin{equation} A B = \\left( \\begin{matrix} a_{11} &amp; a_{12} &amp; a_{13}\\\\ a_{21} &amp; a_{22} &amp; a_{23}\\\\ a_{31} &amp; a_{32} &amp; a_{33} \\end{matrix} \\right) \\left( \\begin{matrix} b_{11} &amp; b_{12} &amp; b_{13}\\\\ b_{21} &amp; b_{22} &amp; b_{23}\\\\ b_{31} &amp; b_{32} &amp; b_{33} \\end{matrix} \\right) \\tag{7.8} \\end{equation}\\] Se requiere que la matriz izquierda tenga la misma cantidad de columnas que filas de la matriz derecha, resultando en una matriz con dimensiones de las filas de la izquierda por las columnas de la derecha (\\(A(i,j)B(m,n)=C(i,n)\\)). Se demuestra con un ejemplo trivial, pero retomando el operador de multipliación matricial %*% presentado anteriormente. Si se utiliza solo * el resultado es elemento por elemento y las matrices debieran ser de exactamente el mismo tamaño. A1 = matrix(data = 1:9, nrow = 3) A2 = matrix(data = 1:9, nrow = 3, byrow = T) A1 %*% A2 ## [,1] [,2] [,3] ## [1,] 66 78 90 ## [2,] 78 93 108 ## [3,] 90 108 126 Determinante: \\[\\begin{equation} A = \\left( \\begin{matrix} a_{11} &amp; a_{12}\\\\ a_{21} &amp; a_{22} \\end{matrix} \\right)\\\\ det(A) = |A| = a_{11} a_{22} - a_{21} a_{12} \\tag{7.9} \\end{equation}\\] Esto aplica para matrices cuadradas, o sea que tienen la misma cantidad de filas y columnas (\\(i \\times i\\)). Aquí se presenta la forma manual para una matriz de \\(2 \\times 2\\) ya que es la más sencilla, para matrices de mayor dimensión se puede hacer uso del software R, como se realiza en el siguiente ejemplo. El comando para calcular el determinante es det(). A = matrix(data = c(4,10,10,30), nrow = 2) det(A) ## [1] 20 7.1.2.2 Tipos de matrices Hay ciertos tipos de matrices que de acuerdo a su estructura reciben nombres especiales. Dentro de estas matrices están: Diagonal: Hay entradas diferentes de cero en la diagonal y el resto de los elementos son ceros. la diagonal es donde el numero de fila y columna es el mismo (ej: \\(a_{22}\\)). \\[\\begin{equation} \\left( \\begin{matrix} 3 &amp; 0 &amp; 0\\\\ 0 &amp; 4 &amp; 0\\\\ 0 &amp; 0 &amp; 2 \\end{matrix} \\right) \\tag{7.10} \\end{equation}\\] Identidad: Es una matriz diagonal donde la diagonal tiene únicamente unos, y tiene una denominación especial \\(I\\). \\[\\begin{equation} I = \\left( \\begin{matrix} 1 &amp; 0 &amp; 0\\\\ 0 &amp; 1 &amp; 0\\\\ 0 &amp; 0 &amp; 1 \\end{matrix} \\right) \\tag{7.11} \\end{equation}\\] Transpuesta: Se “rota” la matriz y lo que antes eran las filas ahora son las columnas y viceversa. Se denota por medio de \\(A^T\\). Si las dimensiones originales eran \\((i,j)\\), las dimensiones de la transpuesta son \\((j,i)\\). \\[\\begin{equation} A = \\left( \\begin{matrix} 3 &amp; 4 &amp; 1\\\\ 2 &amp; 7 &amp; 5 \\end{matrix} \\right)\\\\ A^T = \\left( \\begin{matrix} 3 &amp; 2\\\\ 4 &amp; 7\\\\ 1 &amp; 5 \\end{matrix} \\right) \\tag{7.12} \\end{equation}\\] Simétrica: Se puede pensar como un espejo en los elementos no de la diagonal, donde se pueden intercambiar los subíndices y la matriz no cambia (\\(a_{21} = a_{12}\\)) \\[\\begin{equation} \\left( \\begin{matrix} 2 &amp; 5 &amp; 3\\\\ 5 &amp; 1 &amp; 4\\\\ 3 &amp; 4 &amp; 9 \\end{matrix} \\right) \\tag{7.13} \\end{equation}\\] Un caso típico de una matriz simétrica es el tensor de esfuerzos, presentado gráficamente en la Figura 7.3 y en la Ecuación (7.14). Figura 7.3: Tensor de esfuerzos, un ejemplo de una matriz simetrica. Tomado de: https://www.efunda.com/formulae/solid_mechanics/mat_mechanics/images/StressState3D.gif \\[\\begin{equation} \\sigma = \\left( \\begin{matrix} \\sigma_{xx} &amp; \\sigma_{xy} &amp; \\sigma_{xz}\\\\ \\sigma_{yx} &amp; \\sigma_{yy} &amp; \\sigma_{yz}\\\\ \\sigma_{zx} &amp; \\sigma_{zx} &amp; \\sigma_{zz} \\end{matrix} \\right) \\tag{7.14} \\end{equation}\\] Inversa: Cuando se multiplica la matriz original por la inversa se obtiene la matriz identidad \\(I\\). Se denota por medio de \\(A^{-1}\\). Aquí no se pretende demostrar o indicar como obtener la matriz inversa, esta se puede calcular con software dedicado para ello. \\[\\begin{equation} A A^{-1} = I \\tag{7.15} \\end{equation}\\] 7.1.2.3 Usos Las matrices son usadas de forma rutinaria aun cuando uno no se de cuenta. Muchas de las operaciones que se realizan se pueden presentar en notación matricial, y de hecho así es como se procesan los datos a lo interno de muchas funciones. Aquí se presentan dos usos típicos y conocidos: resolver sistemas de ecuaciones y obtener predicciones para un modelo lineal. Sistemas de ecuaciones Se puede resolver de dos maneras: haciendo uso de la matriz inversa (Ecuación (7.16)) o de la Regla de Cramer usando determinantes (Ecuación (7.18)). Haciendo uso de la matriz inversa seria de la siguiente manera: \\[\\begin{align*} A x &amp;= b\\\\ A A^{-1} x &amp;= A^{-1} b\\\\ x &amp;= A^{-1} b \\tag{7.16} \\end{align*}\\] Se muestra en el siguiente ejemplo, donde se hace uso de operaciones anteriormente demostradas, primero de forma manual y seguido en R. La idea es descomponer el sistema de ecuaciones en matrices y vectores, una matriz para los coeficientes de las incógnitas, un vector para las incógnitas, y un vector para la solución de la ecuación. A partir de esto se encuentra la matriz inversa de los coeficientes, se multiplica a ambos lados de la ecuación (recordando que al multiplicar \\(A A^{-1} = I\\)), lo que despeja a las incógnitas y se termina de resolver el problema. \\[\\begin{align*} 4 x_1 + 10 x_2 &amp;= 38\\\\ 10 x_1 + 30 x_2 &amp;= 110\\\\ A x &amp;= b\\\\ \\left( \\begin{matrix} 4 &amp; 10\\\\ 10 &amp; 30 \\end{matrix} \\right) \\left( \\begin{matrix} x_1\\\\ x_2 \\end{matrix} \\right) &amp;= \\left( \\begin{matrix} 38\\\\ 110 \\end{matrix} \\right)\\\\ A^{-1} b &amp;= x\\\\ \\left( \\begin{matrix} 1.5 &amp; -0.5\\\\ -0.5 &amp; 2 \\end{matrix} \\right) \\left( \\begin{matrix} 38\\\\ 110 \\end{matrix} \\right) &amp;= \\left( \\begin{matrix} 2\\\\ 3 \\end{matrix} \\right) \\tag{7.17} \\end{align*}\\] En R la inversa de una matriz se obtiene por medio de solve(). A = matrix(data = c(4,10,10,30), nrow = 2) b = c(38,110) Ainv = solve(A) Ainv ## [,1] [,2] ## [1,] 1.5 -0.5 ## [2,] -0.5 0.2 Ainv %*% b ## [,1] ## [1,] 2 ## [2,] 3 Haciendo uso de la Regla de Cramer se muestra en el siguiente ejemplo. La idea es primero calcular el determinante de la matriz de coeficientes. Posteriormente se reemplaza la primer columna por el vector de las soluciones en la matriz de coeficientes, se calcula el determinante de esta nueva matriz y la primer incógnita (\\(x_1\\)) seria la división entre el determinante de la matriz modificada sobre el determinante de la matriz original. Se prosigue de manera similar para el resto de incógnitas. \\[\\begin{equation} \\left| \\begin{matrix} 4 &amp; 10\\\\ 10 &amp; 30 \\end{matrix} \\right| = 4 \\times 30 - 10 \\times 10 = 20\\\\ \\left| \\begin{matrix} 30 &amp; 110\\\\ 10 &amp; 30 \\end{matrix} \\right| = 38 \\times 30 - 110 \\times 10 = 40\\\\ x_1 = \\frac{40}{20} = 2\\\\ \\left| \\begin{matrix} 4 &amp; 10\\\\ 30 &amp; 110 \\end{matrix} \\right| = 4 \\times 110 - 10 \\times 38 = 60\\\\ x_2 = \\frac{60}{20} = 3\\\\ \\tag{7.18} \\end{equation}\\] Obtener predicciones para un modelo lineal El procedimiento se demuestra en la Ecuación (7.19), para una regresión lineal simple (\\(y = b_0 + b_1 x\\)). Aquí la idea es que los valores a predecir no se toman como un vector o serie de vectores, sino que se ordenan en una matriz, donde se incluye una columna de unos para el intercepto (\\(A\\)). Se cuenta con un vector de los coeficientes de la regresión lineal (\\(b\\)). Para obtener las predicciones se realiza una multiplicación entre estas dos matrices, resultando en un vector de las predicciones deseadas (\\(y\\)). \\[\\begin{equation} A = \\left( \\begin{matrix} 1 &amp; 3.24\\\\ 1 &amp; 1.37\\\\ 1 &amp; 4.52\\\\ 1 &amp; 4.63\\\\ 1 &amp; 4.21 \\end{matrix} \\right); b = \\left( \\begin{matrix} 0.5\\\\ 8.1 \\end{matrix} \\right)\\\\ y = b_0 + b_1 x\\\\ y = A b = \\left( \\begin{matrix} 1 &amp; 3.24\\\\ 1 &amp; 1.37\\\\ 1 &amp; 4.52\\\\ 1 &amp; 4.63\\\\ 1 &amp; 4.21 \\end{matrix} \\right) \\left( \\begin{matrix} 0.5\\\\ 8.1 \\end{matrix} \\right) = \\left( \\begin{matrix} 26.74\\\\ 11.59\\\\ 37.08\\\\ 38.03\\\\ 34.56 \\end{matrix} \\right)\\\\ \\text{donde } y_1 = 0.5 \\cdot 1 + 8.1 \\cdot 3.24 = 26.74 \\tag{7.19} \\end{equation}\\] En R se hace uso de las operaciones matriciales convencionales. A = matrix(data = c(rep(1,5), 3.24, 1.37, 4.52, 4.63, 4.21), ncol = 2) A ## [,1] [,2] ## [1,] 1 3.24 ## [2,] 1 1.37 ## [3,] 1 4.52 ## [4,] 1 4.63 ## [5,] 1 4.21 a = c(0.5,8.1) a ## [1] 0.5 8.1 y = A %*% a y ## [,1] ## [1,] 26.744 ## [2,] 11.597 ## [3,] 37.112 ## [4,] 38.003 ## [5,] 34.601 7.2 Eigenvectors y Eigenvalues 7.2.1 Definición Los eigenvectors (vectores característicos) son vectores especiales para una dada matriz, que al ser multiplicados por esta matriz no cambian de dirección, lo cual si ocurre con vectores no característicos. Al multiplicar la matriz por el eigenvector se obtiene un vector, el cual va a ser simplemente el eigenvector escalado (dimensionado) de acuerdo al eigenvalue (valor característico), ver Ecuación (7.20). El eigenvalue (\\(\\lambda\\)) indica si el eigenvector es estirado (\\(&gt;1\\)), comprimido (\\(&lt;1\\)), invertido (valor negativo), o dejado sin cambios (\\(1\\)). \\[\\begin{equation} A x = \\lambda x \\tag{7.20} \\end{equation}\\] donde \\(x\\) es el eigenvector de \\(A\\) y \\(\\lambda\\) es el eigenvalue de \\(A\\) para un eigenvector dado. 7.2.2 Cálculo Primero y los más fácil es encontrar los eigenvalues, para esto se sigue el procedimiento mostrado en la Ecuación (7.21), donde la idea es despejar pasar todo a un lado de la ecuación igualando a cero, factorizar el eigenvector \\(x\\) y multiplicar la matriz identidad por los eigenvalues. Posteriormente a la parte factorizada se le calcula el determinante y se iguala a cero para resolver la ecuación (cuadrática en el caso de una matriz de \\(2 \\times 2\\)) y encontrar los eigenvalues. \\[\\begin{equation} \\left( A - \\lambda I \\right) x = 0\\\\ \\left| A - \\lambda I \\right| = 0 \\tag{7.21} \\end{equation}\\] Se puede mostrar con el siguiente ejemplo. \\[\\begin{equation} A = \\left( \\begin{matrix} 17 &amp; -6\\\\ 45 &amp; -16 \\end{matrix} \\right)\\\\ \\left( A - \\lambda I \\right) = \\left( \\begin{matrix} 17-\\lambda &amp; -6\\\\ 45 &amp; -16-\\lambda \\end{matrix} \\right)\\\\ \\left| \\begin{matrix} 17-\\lambda &amp; -6\\\\ 45 &amp; -16-\\lambda \\end{matrix} \\right| = 0\\\\ (17-\\lambda)(-16-\\lambda) - (45)(-6) = 0\\\\ \\lambda^2 - \\lambda - 2 = 0\\\\ (\\lambda - 2)(\\lambda + 1) = 0\\\\ \\lambda_1 = 2, \\lambda_2 = -1 \\tag{7.22} \\end{equation}\\] Una vez encontrados los eigenvalues se puede corroborar que cumplan con dos criterios: El producto de los eigenvalues es igual al determinante de la matriz original La suma de los eigenvalues es igual a la suma de la diagonal de la matriz original En el caso del ejemplo mostrado en (7.22): \\[\\begin{equation} \\left| \\begin{matrix} 17 &amp; -6\\\\ 45 &amp; -16 \\end{matrix} \\right| = (17)(-16) - (45)(-6) = -2\\\\ \\lambda_1 = 2, \\lambda_2 = -1\\\\ \\lambda_1 \\times \\lambda_2 = -2 \\to determinante = -2\\\\ \\lambda_1 + \\lambda_2 = 1 \\to 17 - 16 = 1 \\tag{7.23} \\end{equation}\\] Aquí se va a obviar el procedimiento manual del cálculo de los eigenvectors, pero e muestra el resultado de los eigenvectors del ejemplo mostrado en (7.22). Para \\(\\lambda_1\\): \\[\\begin{equation} A x = \\lambda x\\\\ \\left( \\begin{matrix} 17 &amp; -6\\\\ 45 &amp; -16 \\end{matrix} \\right) \\left( \\begin{matrix} 2\\\\ 5 \\end{matrix} \\right) = \\left( \\begin{matrix} 4\\\\ 10\\\\ \\end{matrix} \\right)\\\\ \\left( \\begin{matrix} 17 &amp; -6\\\\ 45 &amp; -16 \\end{matrix} \\right) \\left( \\begin{matrix} 2\\\\ 5 \\end{matrix} \\right) = 2 \\left( \\begin{matrix} 2\\\\ 5\\\\ \\end{matrix} \\right) \\tag{7.24} \\end{equation}\\] Para \\(\\lambda_2\\): \\[\\begin{equation} A x = \\lambda x\\\\ \\left( \\begin{matrix} 17 &amp; -6\\\\ 45 &amp; -16 \\end{matrix} \\right) \\left( \\begin{matrix} 1\\\\ 3 \\end{matrix} \\right) = \\left( \\begin{matrix} -1\\\\ -3\\\\ \\end{matrix} \\right)\\\\ \\left( \\begin{matrix} 17 &amp; -6\\\\ 45 &amp; -16 \\end{matrix} \\right) \\left( \\begin{matrix} 1\\\\ 3 \\end{matrix} \\right) = -1 \\left( \\begin{matrix} 1\\\\ 3\\\\ \\end{matrix} \\right) \\tag{7.25} \\end{equation}\\] En el siguiente ejemplo se muestra como obtener en R tanto los eigenvectors como eigenvalues, lo que se realiza mediante la función eigen(). A = matrix(data = c(17,45,-6,-16), nrow = 2) eigen(A) ## eigen() decomposition ## $values ## [1] 2 -1 ## ## $vectors ## [,1] [,2] ## [1,] 0.3713907 0.3162278 ## [2,] 0.9284767 0.9486833 Como se menciona en los términos generales a continuación, y se ve comparando el resultado de (7.24) y (7.25) con el resultado de R, los valores de los elementos de los eigenvectors no son de importancia, sino la relación entre esos elementos. En (7.24) se muestra que el eigenvector es \\(x_1=(2,5)\\), pero en el ejemplo anterior es \\(x_1=(0.371,0.928)\\); si se hace la relación del segundo elemento por el primer elemento se obtiene \\(2.5\\) en ambos casos, lo mismo pasa para \\(x_2\\) donde la relación es de \\(3\\). En términos generales: Los eigenvectors apuntan en la dirección que se esparcen los datos, y lo que importa es la relación entre los elementos del vector, no sus magnitudes. Los eigenvalues es cuaánto se esparcen los datos. En matrices simétricas los eigenvectors van a ser ortogonales. "],
["introducción-a-estadística.html", "Capítulo 8 Introducción a estadística 8.1 Tipos 8.2 Modelos 8.3 Nomenclatura 8.4 Variables 8.5 Métodos de análisis 8.6 Muestreo 8.7 Incertidumbre", " Capítulo 8 Introducción a estadística Este capitulo da una introducción a estadística, en qué consiste, para qué se usa, los tipos, modelos y nomenclatura que se usan. Estadística es la ciencia que estudia la manera en que se recolecta, se analiza, se interpreta la información proveniente de una población, así como el modo en que se extrapola esos resultados a otros casos similares. Tiene como objetivo principal analizar datos y transformarlos en información útil para tomar decisiones y sacar conclusiones, donde hay incertidumbre y variación. 8.1 Tipos En general hay dos tipos de estadística: Descriptiva: Lo que se hace es recopilar, organizar, resumir y presentar datos para facilitar su análisis y aplicación (Tablas y/o gráficos). En este tipo es donde se ubica lo que se conoce como análisis exploratorio de datos (AED o EDA en inglés), y consiste en el proceso para utilizar herramientas estadísticas (como gráficas, medidas de tendencia central y medidas de variación), con la finalidad de investigar conjuntos de datos para comprender sus características importantes. Un ejemplo se observa en la Figura 8.1. Figura 8.1: Ejemplo de estadística desciptiva y análisis exploratorio de datos. Tomado de: http://www.universoformulas.com/imagenes/estadistica/descriptiva/estadistica-descriptiva.jpg Inferencial: El objetivo es hacer inferencias en base a una muestra, con la intención de generalizar a una población de interés (Figura 8.2). En este caso los resultados se usan para corroborar o refutar creencias sobre la población de interés y sacar conclusiones con sustento estadístico. Figura 8.2: Proceso de estadística inferencial. Tomado de: http://www.universoformulas.com/imagenes/estadistica/inferencia/proceso-estadistica-inferencial.jpg 8.2 Modelos Determinístico: Donde las mismas entradas producirán las mismas salidas, sin variación, esto debido a que no hay incertidumbre en los datos, se conocen con certeza. Probabilístico (aleatorio, estocástico): Donde los resultados (salidas) dependen de las entradas y de los componentes aleatorios (incertidumbre), pudiendo producir resultados distintos a partir de una misma entrada. Los resultados se expresan en términos de probabilidad, que refleja la incertidumbre del modelo. 8.3 Nomenclatura En estadística se maneja cierta nomenclatura (definiciones) que es importante conocer y saber usar apropiadamente. Dentro de las definiciones que se van a trabajar a los largo del curso son: Población Conjunto con alguna característica de interés Normalmente muy grande para poder abarcarlo (estudiarlo) por completo Muestra Subconjunto de la población de interés sobre el cual se hacen las observaciones y análisis Debería ser representativa Variable Característica observable de los componentes de una población (muestra) y que puede tomar distintos valores Observación o dato Valor obtenido para los componentes de la muestra, como resultado de algún tipo de medición Los conceptos de población y muestra se muestran en la siguiente figura. Figura 8.3: Ejemplo de una población a la cual se le toma una muestra. Tomado de: http://aprendiendoadministracion.com/wp-content/uploads/2016/01/muestra-estadistica.jpg No hay que confundir los conceptos de muestra estadistica y muestra geologica. Una muestra estadistica es un conjunto de observaciones o datos, mientras que una muestra geologica en terminos estadisticos es una observacion o dato. Entonces una muestra estadistica es un conjunto de muestras geologicas. 8.4 Variables Hay dos tipos generales de variables: Cualitativa y Cuantitativa. 8.4.1 Cualitativa Lo que se conoce como datos categóricos, donde las entradas o datos toman valores de clases o niveles. Dentro de R estas son las que so codifican como factores. Dentro de este tipo podemos encontrar una subdivisión: Nominal (nom): donde las clases o niveles no tienen un orden específico, Ordinal (ord): donde las clases o niveles tienen un orden relativo, que se puede pensar como una escala. Ejemplos de datos cualitativos son: color (nom), grado de meteorización (ord), nivel de fisuramiento (ord), intensidad (ord), escala de dureza de Mohs (ord), etc. 8.4.2 Cuantitativa Corresponden con datos numéricos, es el tipo de dato que por lo general se asocia a técnicas estadísticas y de análisis de datos, pero no se deben obviar los datos cualitativos. Se puede dividir en: Intervalo: donde datos los datos se encuentran igualmente espaciados y no hay un cero absoluto, o sea pueden haber valores negativos, Ratio: donde hay un cero absoluto, correspondiendo con valores positivos. También se puede dividir en: Discretos (disc): por medio de conteos, corresponde con números enteros, Continuos (cont): por medio de mediciones (magnitudes), corresponde con infinitos valores entre enteros, puede expresarse con decimales. Ejemplos de datos cuantitativos son: edad (cont), orientación (cont), espesor (cont), número de fisuras (disc), magnitud (cont), esfuerzos (cont), deformaciones (cont), longitud (cont), superficie (cont), volumen (cont), tiempo (cont), temperatura (cont), etc. En las ciencias geológicas y de la tierra se manejan varios tipos de datos especiales, que van a requerir de adaptar técnicas de análisis generales para los casos específicos. Dentro de estos datos se tiene: Cerrados: Las variables son expresadas como proporciones y suman hasta un valor fijo total (Ej: 100%), en general el interés es más en la razón entre las variables y no el valor de la variable. Composiciones (Ej: tipo de roca) representan la mayoría de este tipo de datos. Espaciales: La(s) variable(e) de interés posee(n) componentes en 2D o 3D representando su distribución espacial (ubicación en un área determinada). Ejemplos: distribución de un tipo de fósil, cambios en el espesor de una capa de arenisca, distribución de trazas en el agua subterránea. Direccionales: Los datos son expresados en ángulos/orientaciones entre 0 y 360 y pueden tener ademas una inclinación. Ejemplos: rumbo o buzamiento de una capa, orientación de fósiles elongados, dirección del flujo de una colada de lava. Una representación gráfica de los tipos de datos se observa en la Figura 8.4. Figura 8.4: Representación gráfica de los tipos de datos. Los datos cerrados (closed) y direccionales (directional) son más típicos de la ciencias geológicas (Swan &amp; Sandilands, 1995). 8.5 Métodos de análisis Existen diferentes métodos de análisis de datos. Éstos van a depender del tipo de dato y la cantidad de variables que se tengan. Dentro de las principales metodologías se tienen y una representación gráfica de las variable de interés se presenta en la Figura 8.5: Univariable: Se analiza cada variable por separado, el interés está en enfocarse en una variable por si sola a la vez y sin considerar la relación que pueda tener con otras. Bivariable: Se analizan dos variables en conjunto, enfocándose en su relación y/o dependencia. Es la versión simple de un análisis multivariable. Multivariable: Cuando el análisis involucra 2 o más variable de interés a la vez y se requiere determinar la relación e interacción entre dichas variables. Secuencias: Cuando los datos se presentan como secuencias (por lo general implicando algún patrón o ciclicidad) en el tiempo/espacio, donde la forma más simple es un análisis bivariable donde una de las variables es el tiempo/espacio. Espacial: Cuando la ubicación de las muestras es de interés y se requiere entender o determinar cómo se dispone una variable en un área determinada. Por lo general tres (o cuatro) variables analizadas a la vez, donde dos (o tres) corresponden con la ubicación espacial y la otra corresponde con alguna medida de interés geológico, existen opciones univariables y multivariables. Figura 8.5: Representación gráfica de las variables correspondientes a diferentes metodologías de análisis de datos (Swan &amp; Sandilands, 1995). 8.6 Muestreo El muestreo es un procedimiento para obtener datos/observaciones de una población, con la finalidad de usar esta información para realizar inferencias acerca de dicha población (Davis, 2002). Las muestras son subconjuntos de los datos. El conjunto de todas las muestras que se pueden obtener de la población se denomina espacio muestral. La(s) muestra(s) debe(n) ser representativa(s), donde esto va a depender de la adecuada implementación de alguna de las técnicas de muestreo presentadas más adelante. En la Figura 8.6 se presenta y retoma la el concepto de muestra geológica, donde la población de interés es un afloramiento especifico, pero dicho afloramiento es demasiado grande para muestrear por completo, por lo que se deben tomar varias observaciones (muestras geológicas) para obtener una muestra que representa a la población meta. Figura 8.6: Representación de una población de interés geológico donde es necesaria la toma de observaciones (muestras geológicas) para obtener una muestra representativa de dicha población (Trauth, 2015). 8.6.1 Tipos 8.6.1.1 Aleatorio Simple Una muestra se selecciona de modo que todos los elementos de la población tengan la misma probabilidad de ser elegidos. En general es poco recomendado cuando la población es muy grande o heterogénea (Figura 8.7). Figura 8.7: Representación de un muestreo aleatorio simple. Tomado de: http://www.universoformulas.com/imagenes/estadistica/inferencia/muestreo-probabilistico.jpg 8.6.1.2 Sistemático Se elige un punto de partida y luego seleccionamos cada k-ésimo (por ejemplo cada quincuagésimo) elemento en la población. Conlleva algunos riesgos cuando el marco muestral es repetitivo o de naturaleza cíclica (Figura 8.8). Figura 8.8: Representación de un muestreo sistematico. Tomado de: http://www.universoformulas.com/imagenes/estadistica/inferencia/muestreo-sistematico.jpg 8.6.1.3 Estratificado Consiste en definir previamente los estratos (grupos) que posee una población a partir de características comunes entre sus elementos y distintas con los elementos de los otros estratos. A partir de eso se deben tomar muestras aleatorias en cada estrato (Figura 8.9). Figura 8.9: Representación de un muestreo estratificado. Tomado de: http://www.universoformulas.com/imagenes/estadistica/inferencia/muestreo-estratificado.jpg 8.6.1.4 Bloques (conglomerados) Cuando la población está agrupada en conglomerados naturales, después se seleccionan aleatoriamente algunos de estos conglomerados, y luego se elige a todos los miembros de los conglomerados seleccionados o se muestrean los conglomerados con alguna otra técnica. Se usa cuando los conglomerados son muy heterogéneos y no existen muchas diferencias entre conglomerados (Figura 8.10). Figura 8.10: Representación de un muestreo en bloques o por conglomerados. Tomado de: http://www.universoformulas.com/imagenes/estadistica/inferencia/muestreo-estratificado.jpg En geología muchas veces nos vemos forzados por disposición de afloramientos (clustered) o accesibilidad (traverse – cortes de carretera, ríos, etc), especialmente en climas tropicales, ver Figura 8.11, siendo estas las localidades donde se encuentra disponible la población a estudiar. Idealmente un muestreo exhaustivo y de alta resolución seria el que se define en grilla (regular). Figura 8.11: Típicas disposiciones de afloramientos en ciencias geológicas, especialmente en climas tropicales (Swan &amp; Sandilands, 1995). 8.7 Incertidumbre Además de los retos de recolectar muestras representativas, las mediciones geológicas tienen incertidumbre. No es posible realizar una medición exacta (que siempre es la misma) y equipos de alta precisión aún van a tener incertidumbre, reducida pero existe. El objetivo durante la recolección de muestras es reducir la incertidumbre a la hora de tomar mediciones, haciéndolas más precisas y exactas. Con lo anterior se puede diferenciar entre error reproducible y sistemático. El error reproducible es donde se tienen diferencias entre mediciones repetidas y se asocia con precisión, donde se puede detectar por medio de la dispersión de los datos, a menor dispersión mayor precisión. El error sistemático es más difícil de detectar, no se puede estimar únicamente a partir de mediciones repetidas, a menos que se tenga un valor de referencia (valor verdadero); se asocia con exactitud, donde mientras más cerca del valor de referencia mayor la exactitud. Estos conceptos se pueden visualizar en la Figura 8.12. Figura 8.12: Diferencia entre precisión y exactitud. Tomado de: https://www.diferenciador.com/diferencia-entre-exactitud-y-precision/ Referencias "],
["estadística-descriptiva-univariable.html", "Capítulo 9 Estadística Descriptiva Univariable 9.1 Tablas de frecuencias 9.2 Gráficas 9.3 Resúmenes numéricos 9.4 Resumen general", " Capítulo 9 Estadística Descriptiva Univariable Como se mencionó en la introducción, la estadística univariable se enfoca en describir una variable a la vez, sin considerar la relación con cualquier otra variable. La descripción y métodos a usar va a estar en función del tipo de variable: cualitativa o cuantitativa. Las tres formas en que se pueden describir los datos son: tabularmente (datos cualitativos o cuantitativos discretos), gráficamente, y por medio de resúmenes numéricos. 9.1 Tablas de frecuencias La idea es presentar un resumen de los datos, por lo general por medio de conteos de observaciones por clases. Con datos cualitativos simplemente se cuenta la cantidad de observaciones en cada clase, para datos cuantitativos discretos se cuenta la cantidad de observaciones para cada valor único observado, y para datos cuantitativos continuos lo común es dividir el rango de los valores en una cierta cantidad de clases y contar las observaciones que caen en cada clase. Las tablas pueden contener diferentes tipos de frecuencias: Absoluta: Conteo de elementos por clase (\\(n\\)) Relativa: Porcentaje de elementos por clase Absoluta acumulada: Conteo de elementos que toman un valor menor o igual a una clase, suma a la cantidad de observaciones (\\(N\\)) Relativa acumulada: Porcentaje de elementos que toman un valor menor o igual a una clase, suma a 1 o \\(100\\%\\) Para datos cualitativos hay diferentes formas de generar tablas de frecuencias, y dependiendo de lo que se quiera mostrar. Lo más fácil es usar tabyl del paquete janitor y formatearla (Tabla 9.1). Se va a ejemplificar con los datos gss_cat y la variable marital que vienen con el paquete forcats. Por defecto cuando se usa solo una variable realiza el conteo y calcula el porcentaje de cada categoría. En el ejemplo se redondea a 3 dígitos y se ordena de forma descendente de acuerdo al conteo. gss_cat %&gt;% tabyl(marital) %&gt;% adorn_rounding(3) %&gt;% arrange(-n) Tabla 9.1: Tabla de frecuencias para una variable cualitativa marital n percent Married 10117 0.471 Never married 5416 0.252 Divorced 3383 0.157 Widowed 1807 0.084 Separated 743 0.035 No answer 17 0.001 En el caso de datos cuantitativos continuos, donde hay que dividir el rango de valores en cierta cantidad de clases, no hay una manera única o definida de escoger el número de clases, pero hay algunas sugerencias. Una de las sugerencias se muestra en la Ecuación (9.1). \\[\\begin{equation} k = 1 + 3.33 log_{10}(N) \\tag{9.1} \\end{equation}\\] donde \\(k\\) es el número de clases y \\(N\\) es el total de observaciones (datos). Otra sugerencia se muestra en la Tabla 9.2 Tabla 9.2: Sugerencia para el número de clases de acuerdo a la cantidad de observaciones N k &lt; 50 5 - 7 50 - 100 6 - 10 100 - 250 7 - 12 &gt; 250 10 - 20 Un ejemplo de una tabla de frecuencia se muestra a continuación en la Tabla 9.3, usando los datos: 3.1 4.5 2.9 2.7 3.8 5.1 4.9 3.5 2.1 4.2 2.2 1.8 2.5 3.6 3.6 4.3 5.1 6.1 5.7 2.8 2.8 3.7 3.5 4.4 2.5 5.6 5.1 4.7 4.9 4.2 3.6 4.1 4.1 3.7 2.9 6.2 4.8 3.9 4.6 3.1. Tabla 9.3: Tabla de frecuencias para una variable continua Clase Frecuencia absoluta Frecuencias relativa Frec. Abs. Acumulada Frec. Rel. Acumulada 1-2 1 0.025 1 0.025 2-3 9 0.225 10 0.250 3-4 11 0.275 21 0.525 4-5 12 0.300 33 0.825 5-6 5 0.125 38 0.950 6-7 2 0.050 40 1.000 El código para generar la tabla fue el siguiente, donde x corresponde con el vector de datos, breaks con las divisiones para las clases, y labels con los nombres de la clases: Freq(x, breaks = 1:7, labels = c(&#39;1-2&#39;,&#39;2-3&#39;,&#39;3-4&#39;,&#39;4-5&#39;,&#39;5-6&#39;,&#39;6-7&#39;)) 9.2 Gráficas Dependiendo del tipo de variable así será la representación gráfica. Para datos cualitativos y cuantitativos discretos lo típico es usar gráficos de barras, mientras que para datos cuantitativos continuos se usa el histograma o gráfico de caja. El gráfico de barras correspondiente a los datos de la Tabla 9.1 se muestra en la Figura 9.1. Para refrescar cómo se pueden construir estos gráficos ir a Gráficos. La finalidad de esto gráficos es brindar una idea del balance entre las categorías o niveles de una clase y ver si hay alguna categoría o nivel que sobre salga tanto por valores altos como por valores bajos. Figura 9.1: Gráfico de barras para una variable cualitativa El histograma (Figura 9.2) permite dar una primera mirada al tipo de distribución de los datos: Si las alturas de las barras son similares se dice que tiene distribución tipo “uniforme”. Si las alturas son mayores en la zona central se dice que tiene forma tipo “campana” (distribución normal) y puede ser simétrica o asimétrica, con sesgo hacia el lado positivo o al lado negativo. Si hay barras muy alejadas del grupo, se dice que son datos atípicos. Figura 9.2: Ejemplos de histogramas. Tomado de: http://pro.arcgis.com/en/pro-app/tool-reference/spatial-statistics/ El gráfico de caja (Figura 9.3) también puede brindar una idea de la distribución de los datos. Recordar que este tipo de gráfico se compone de los cuartiles \\(Q_1\\) (límite inferior de la caja), \\(Q_2\\) o mediana (barra dentro de la caja), y \\(Q_3\\) (límite superior de la caja). Si los datos presentan una distribución normal tipo campana la mediana aparecería cerca del centro de la caja. Si los datos presentan una asimetría la mediana va a estar más cerca de uno de los bordes, y van a observarse puntos al extremo opuesto de la mediana, los cuales podrían representar valores extremos o atípicos. Figura 9.3: Gráficos de caja, donde las cruces representan la media. A mostrando datos con distribución normal donde la mediana está cerca del medio de la caja. B mostrando datos asimétricos donde la mediana está más cerca de uno de los extremos y además se presentan posibles valores atípisoc (puntos). Siguiendo con los datos del ejemplo de la Tabla 9.3, se pueden generar los histogramas (Figura 9.4) correspondientes a las columnas. Para refrescar cómo se pueden construir estos gráficos ir a Gráficos. Figura 9.4: Histogramas de los datos de ejemplo. A Frecuencia absoluta, B Frecuencia relativa, C Frecuencia absoluta acumulada, D Frecuencia relativa acumulada. 9.3 Resúmenes numéricos Dependiendo del dato que se quiera presentar, éstos se pueden dividir en diferentes tipos. En esta sección se muestran y explican estos diferentes tipos, así como las funciones para calcularlas, enfocándose más en datos cuantitativos continuos. 9.3.1 Medidas de tendencia central Esta estadística es la más conocida, ya que representa el centro de la distribución de los datos, siendo la más conocida y usada la media aritmética o promedio (\\(\\bar{x}\\)). Además de la media, otras medidas de tendencia central son la media ponderada, media geométrica (\\(\\bar{x}_g\\)), mediana, y moda. 9.3.1.1 Media La media aritmética o promedio se muestra en la Ecuación (9.2) y tiene la característica de ser sensible a valores extremos (atípicos), por lo que no es muy recomendable para distribuciones asimétricas. \\[\\begin{equation} \\bar{x} = \\frac{\\sum_{i=1}^{N}{x_i}}{N} \\tag{9.2} \\end{equation}\\] La media ponderada (Ecuación (9.3)) se usa cuando los elementos del vector tienen diferentes pesos (\\(f\\)). La media aritmética es de hecho una simplificación de la media ponderada donde todos los elementos tienen el mismo peso. \\[\\begin{equation} \\bar{x} = \\frac{\\sum_{i=1}^{k}{f_i m_i}}{\\sum f} \\tag{9.3} \\end{equation}\\] 9.3.1.2 Media geométrica La media geométrica (Ecuación (9.4)) es típicamente usada para distribuciones con asimetría positiva (hacia la derecha), y es menos sensible a valores extremos (atípicos). Tiene la condición de que únicamente aplica para valores positivos, no pueden ser cero ni negativos. \\[\\begin{equation} \\bar{x}_g = \\left(x_1 * x_2 * \\cdots * x_N \\right)^\\frac{1}{N} \\tag{9.4} \\end{equation}\\] Los anteriores conceptos se muestran con un ejemplo donde se tiene las notas de exámenes (70, 50, 80, 95) y cada examen tiene diferente peso (20, 20, 20, 40). La media sería \\(\\bar{x} = \\frac{70+50+80+95}{4} = 73.75\\), la media ponderada sería \\(\\bar{x} = \\frac{70*20+50*20+80*20+95*40}{4} = 78\\), y la media geométrica sería \\(\\bar{x}_g = \\left(70 * 50 * 80 * 95 \\right)^\\frac{1}{4} = 71.81\\). En R se realizaría de la siguiente manera: notas = c(70, 50, 80, 95) pesos = c(20, 20, 20, 40) mean(notas) ## [1] 73.75 weighted.mean(notas, pesos) ## [1] 78 Gmean(notas) ## [1] 71.81587 9.3.1.3 Mediana La mediana (Ecuación (9.5)) es el valor de los datos que los divide en dos partes iguales. No se ve afectada por valores extremos, lo que la hace una medida robusta para distribuciones asimétricas. \\[\\begin{equation} \\text{si N es impar} \\rightarrow Me = X_\\frac{N+1}{2}\\\\ \\text{si N es par} \\rightarrow Me = 0.5 \\left(X_\\frac{N}{2} + X_\\frac{N+1}{2} \\right)\\\\ \\tag{9.5} \\end{equation}\\] Ejemplos de la mediana y cómo no se ve afectada por valores extremos serían: \\(1, 2, 4, 5, 6, 6, 8 \\rightarrow Me = 5\\) \\(1, 2, 4, 5, 6, 6, 6, 8 \\rightarrow Me = (5+6)/2 = 5.5\\) \\(1, 2, 4, 5, 6, 6, 80 \\rightarrow Me = 5\\) 9.3.1.4 Moda La moda es el valor más frecuente o que se repite más, es más utilizada para datos discretos, aunque para datos continuos se puede calcular la curva de densidad de los datos y encontrar el pico de dicha curva. También existe la posibilidad de que los datos presenten más de una moda (Figura 9.5). Figura 9.5: Distribuciones de datos con más de una moda (Trauth, 2015). En variables con distribución simétrica los valores de media, mediana y moda coinciden. En las distribuciones asimétricas se van distanciando conforme incrementa la asimetría (Figura 9.6). Figura 9.6: Diferencias entre medidas de tendencia central conforme la distribución presenta mayor asimetría (Trauth, 2015). 9.3.2 Medidas de dispersión Estas medidas brindan una idea de la dispersión o variabilidad que presentan los datos con respecto a una medida de tendencia central, típicamente la media. Siempre son positivas e idealmente para reducir la incertidumbre se busca que estas medidas sean lo más pequeñas posibles. 9.3.2.1 Rango (\\(R\\)) El rango toma en cuenta el valor mínimos y máximo de la variable, sin tomar en cuenta el resto de valores intermedios. Se puede expresar de dos maneras: como un vector indicando los valores máximo y mínimo, o como la diferencia entre estos valores (Ecuación (9.6)). Una desventaja de presentarlo como al diferencia es que se pierde el contexto de la escala de los datos, ya que una misma diferencia puede estar presente a diferentes escalas. Ejemplo: Los datos pueden tener un rango de 5, pero los datos pueden estar entre 100 y 95 o 25 y 20. Para ambos casos aunque el rango es el mismo no confiere la misma información; en el primer caso la dispersión se puede considerar menor ya que representa un 5% con respecto al valor máximo, mientras que en el segundo caso representa un 20%. \\[\\begin{equation} (a) R = (x_{min},x_{max})\\\\ (b) R = x_{max}-x_{min}\\\\ \\tag{9.6} \\end{equation}\\] Una ventaja de esta medida es la facilidad de calcularla e interpretarla, mientras que la desventaja es que considera únicamente los datos extremos y no la totalidad de los mismos, por lo que pudiera verse afectada por valores atípicos. Usando los datos 2, 6, 11, 8, 11, 4, 7, 5 como ejemplo se puede determinar que \\(R=(2,11)=9\\). En R la función range calcula el rango dando los valores mínimo y máximo, si se quiere la diferencia se puede usar diff, donde toma el segundo elemento y le resta el primero. vec = c(2, 6, 11, 8, 11, 4, 7, 5) range(vec) ## [1] 2 11 diff(range(vec)) ## [1] 9 9.3.2.2 Varianza (\\(s^2\\)) La varianza toma en cuenta todos los datos y su diferencia al cuadrado con respecto a la media, esto se puede visualizar en la Figura 9.7, donde la línea vertical roja representa la media, los puntos azules los datos, y las lineas horizontales azules las diferencias cuadradas entre la media y los datos. Una desventaja es que al elevar las diferencias al cuadrado la medida NO se encuentra en las mismas unidades (escala) de la variable original. Figura 9.7: Representación de la varianza La varianza se calcula mediante la Ecuación (9.7): \\[\\begin{equation} s^2 = \\frac{\\sum_{i=1}^{N}{\\left(x_i - \\bar{x}\\right)^2}}{N-1}\\\\ \\sigma^2 = \\frac{\\sum_{i=1}^{N}{\\left(x_i - \\mu\\right)}}{N} \\tag{9.7} \\end{equation}\\] En la ecuación anterior \\(s^2\\) es la varianza muestral, \\(\\sigma^2\\) la varianza poblacional, \\(\\bar{x}\\) la media muestral, y \\(\\mu\\) la media poblacional. En el caso de la varianza muestral se usa en el denominador \\(N-1\\), lo que se conoce como grados de libertad (\\(df \\ o \\ \\nu\\)). Porqué \\(N-1\\), porque para poder calcular la varianza se necesita saber la media, y si se conoce la media no importa la cantidad de datos que tenga el último dato va a estar condicionado para satisfacer el valor de la media, o sea todos los datos menos uno pueden variar libremente. Un ejemplo de puede mostrar con los datos 8, 10, 5, 12, 10, 15. En este caso \\(N=6,\\ \\bar{x}=60/6=10,\\ \\sum_{i=1}^{N}{\\left(x_i - \\bar{x}\\right)^2}=58,\\ s^2=\\frac{58}{6-1}=11.6 \\ unidades^2\\). En R se usa la función var para obtener la varianza de un vector. vec = c(8, 10, 5, 12, 10, 15) var(vec) ## [1] 11.6 9.3.2.3 Desviación estándar (\\(s\\)) Esta medida es la más utilizada, ya que se encuentra en las mismas unidades (escala) de los datos originales, dado que es simplemente la raíz cuadrada de la varianza (Ecuación (9.8)), lo que la hace más fácil de interpretar y comprender. \\[\\begin{equation} s = \\sqrt{s^2} = \\sqrt{\\frac{\\sum_{i=1}^{N}{\\left(x_i - \\bar{x}\\right)^2}}{N-1}}\\\\ \\sigma = \\sqrt{\\sigma^2} = \\sqrt{\\frac{\\sum_{i=1}^{N}{\\left(x_i - \\mu\\right)}}{N}} \\tag{9.8} \\end{equation}\\] Siguiendo con los datos del ejemplo de la varianza se tiene que \\(s = \\sqrt{s^2} = \\sqrt{11.6} = 3.4 \\ unidades\\). En R se tiene la función sd para calcular esta medida directamente. sd(vec) ## [1] 3.405877 Visualmente (Figura 9.8) se puede mostrar como al incrementar la desviación estándar la curva de densidad de los datos se aplana más. Figura 9.8: Curvas de densidad con diferentes desviaciones estándar, donde a mayor desviación estándar más aplanada la curva y a menor desviación estándar más empinada la curva Como se va a ver más adelante hay una relación entre la desviación estándar y la media que se ve reflejada en la distribución normal (Figura 9.9). Típicamente se asocia que el 68% de los datos se encuentran a \\(1\\ s\\) de la media, el 95% de los datos se encuentran a \\(2\\ s\\) de la media, y el 99% de los datos se encuentran a \\(3\\ s\\) de la media. Figura 9.9: Relación entre desviación estándar y media en la distribución normal. Tomado de: http://algebra2.thinkport.org/module3/images/xyz-page2-graph.jpg 9.3.2.4 Rango intercuartil (\\(IQR\\)) Mide la dispersión central de los datos, ya que se toma únicamente el 50% central de los datos, al ser la diferencia entre el tercer cuartil (\\(Q_3\\)) y primer cuartil (\\(Q_1\\)), ver Ecuación (9.9). Se considera más robusta que la desviación estándar al no tomar en cuenta valores extremos. De hecho, valores extremos o atípicos suelen identificarse cuando se desvían más de 3 veces el \\(IQR\\) con respecto a la mediana. \\[\\begin{equation} IQR = Q_3 - Q_1 \\tag{9.9} \\end{equation}\\] En R se tiene el comando IQR para calcular esta medida, como se muestra a continuación. set.seed(10) vec = rchisq(60,3) IQR(vec) ## [1] 2.533682 9.3.2.5 Mediana de la desviación absoluta (\\(mad\\)) Se calcula usando la Ecuación (9.10) y en general se considera más robusta que la desviación estándar y el rango intercuartil cuando se presentan datos extremos o atípicos y cuando la distribución es asimétrica. Se le aplica un factor de conversión de 1.4826 para cumplir con supuestos de normalidad. \\[\\begin{equation} mad = Me\\left(\\left|x_i - Me(x)\\right|\\right) * 1.4826 \\tag{9.10} \\end{equation}\\] Usando los datos generados para \\(IQR\\) se puede calcular esta medida usando mad. mad(vec) ## [1] 1.769578 9.3.2.6 Coeficiente de variación (\\(cv\\)) Esta es una medida estandarizada (Ecuación (9.11)), lo que nos va a permitir comparar la dispersión entre dos poblaciones distintas e incluso, comparar la variación producto de dos variables diferentes (que pueden provenir de una misma población). Si comparamos la dispersión en varios conjuntos de observaciones tendrá menor dispersión aquella que tenga menor coeficiente de variación. \\[\\begin{equation} cv = \\frac{s}{\\bar{x}}*100 \\tag{9.11} \\end{equation}\\] Un ejemplo se muestra a continuación. Para un grupo de datos \\(\\bar{x}=20, s = 4\\), entonces \\(cv = 4/20 = 0.2 = 20\\%\\). Para un segundo grupo \\(\\bar{x} = 48, s = 6\\), entonces \\(cv = 6/48 = 0.125 = 12.5\\%\\). Se concluye que el primer grupo tiene mayor variabilidad relativa con respecto a su media, lo que no se podría concluir de solo fijarse en la desviación estándar. En R el paquete DescTools (Signorell, 2020) tiene la función CoefVar, y si la aplicamos a los datos generados para \\(IQR\\) tenemos: CoefVar(vec) ## [1] 0.7334606 9.3.3 Medidas de posición Estas medidas corresponden con números que distribuyen los datos ordenados de la muestra en grupos de aproximadamente del mismo tamaño, con el propósito de resaltar su ubicación relativa. Estos números se denominan cuantiles en forma genérica. 9.3.3.1 Cuartiles Los cuartiles son los tres valores de la variable que dividen a un conjunto de datos ordenados en cuatro partes iguales (Figura 9.10). Primer Cuartil (\\(Q1\\)): A la izquierda de \\(Q1\\) están incluidos 25% de los datos (aproximadamente), y a la derecha de \\(Q1\\) están el 75% de los datos (aproximadamente). Segundo Cuartil (\\(Q2\\)): Igual que la mediana divide al grupo de datos en dos partes, cada una con el 50% de los datos (aproximadamente). Tercer Cuartil (\\(Q3\\)): A la izquierda de \\(Q3\\) están incluidos 75% de los datos (aproximadamente), y a la derecha de \\(Q3\\) están el 25% de los datos (aproximadamente). Figura 9.10: Representación de los cuartiles. Tomado de: http://dieumsnh.qfb.umich.mx/estadistica/medidasd%20de%20posicion.htm 9.3.3.2 Deciles Los deciles son los nueve valores de la variable que dividen a un conjunto de datos ordenados en diez partes iguales (Figura 9.11). Primer Decil (D1): A la izquierda de D1 están incluidos 10% de los datos (aproximadamente), y a la derecha de D1 están el 90% de los datos (aproximadamente). Segundo Decil (D2): A la izquierda de D1 están incluidos 20% de los datos (aproximadamente), y a la derecha de D1 están el 80% de los datos (aproximadamente) D5 coincide con la mediana. Figura 9.11: Representación de los deciles. Tomado de: http://dieumsnh.qfb.umich.mx/estadistica/medidasd%20de%20posicion.htm En R los cuantiles se pueden obtener con la función quantile y definiendo el argumento probs, donde corresponde con un vector de valores entre 0 y 1, para los cuantiles deseados. quantile(vec, probs = c(.25,.5,.75)) # para cuartiles ## 25% 50% 75% ## 1.212222 2.156949 3.745904 quantile(vec, probs = seq(.1,.9,.1)) # para deciles ## 10% 20% 30% 40% 50% 60% 70% 80% ## 0.6815646 0.8654207 1.3201193 1.8411737 2.1569488 2.4933732 3.1549380 4.0521953 ## 90% ## 5.4816144 9.3.4 Medidas de forma Estas medidas se usan para describir numéricamente la forma aproximada de la distribución de los datos. 9.3.4.1 Asimetría (skewness) Se dice que una distribución es asimétrica cuando la media, mediana y moda no coinciden y la distribución muestra una forma diferente a la “campana”, con una cola más alargada que la otra. Se pueden identificar dos tipos de asimetría: positiva (hacia la derecha) o negativa (hacia la izquierda), ver Figuras 9.12 y 9.13. Figura 9.12: Asimetría con el nombre de la dirección: hacia la izquierda o derecha. Tomado de: http://2.bp.blogspot.com/_bXZg80tWNts/S4SBFgzljbI/AAAAAAAAAd0/72BnnqmoA7g/s320/asimetria.gif Figura 9.13: Asimetría con el nombre del signo: positiva o negativa. Tomado de: http://pro.arcgis.com/en/pro-app/tool-reference/spatial-statistics/ Si la asimetría es positiva se denomina a la derecha (media a la derecha de la mediana y moda) y si es negativa se denomina a la izquierda (media a la izquierda de la mediana y moda). Se pueden considerar como asimetrías importantes y que pueden afectar los datos aquellas que anden cerca de 1 y definittivamente las superiores a 1. Se puede eliminar o reducir significativamente la asimetría usando transformaciones sobre los datos (Figura 9.14). La transformación logarítmica se puede usar cuando la distribución es asimétrica a la derecha (positiva), y la transformación exponencial se puede usar cuando la distribución es asimétrica a la izquierda (negativa). Figura 9.14: Transformaciones que se pueden aplicar sobre los datos para reducir la asimetría. Tomado de: http://pro.arcgis.com/en/pro-app/tool-reference/spatial-statistics/ 9.3.4.2 Curtosis (kurtosis) Caracteriza el apuntalamiento (puntiagudez) de la distribución, si la distribución tiene un pico distintivo o es relativamente plana, y la concentración de valores alrededor de la media. Los nombres que puede tomar se presentan en la Figura 9.15 y ejemplos de datos con diferentes curtosis se presentan en la Figura 9.16. Figura 9.15: Nombres de la curtosis que se le asigna a la distribución de los datos según el valor estimado de la curtosis. Leptocúrtica cuando \\(k&gt;0\\), mesocúrtica cuando \\(k \\approx 0\\), y platicúrtica cuando \\(k&lt;0\\). Tomado de: http://www.spssfree.com/curso-de-spss/curso/5-19.gif. Figura 9.16: Ejemplo de alta curtosis (izquierda) y baja curtosis (derecha) (Trauth, 2015). En R násico no hay una función para calcular la asimetría ni la curtosis, pero el paquete DescTools tiene la función Skew para asimetría y Kurt para curtosis. Usando los datos anteriores tenemos: Skew(vec) ## [1] 1.06636 Kurt(vec) ## [1] 0.5057107 Con los resultados anteriores se tiene una asimetría positiva (hacia la derecha) bastante importante, y una curtosis positiva indicando que los datos presentan un apuntalamiento importante en vez de que sean más dispersos. 9.4 Resumen general En R hay varias funciones que presentan resúmenes generales presentando varias medidas (revisar Descripciones generales (globales)), aquí se presenta la función descr del paquete summarytools (Comtois, 2019), que se usa para datos cuantitativos, si se tuvieran datos cualitativos se puede utilizar freq o la tabla de frecuencias como se presentó anteriormente (Tablas de frecuencias). descr(vec) ## Descriptive Statistics ## vec ## N: 60 ## ## vec ## ----------------- -------- ## Mean 2.62 ## Std.Dev 1.92 ## Min 0.31 ## Q1 1.19 ## Median 2.16 ## Q3 3.75 ## Max 8.56 ## MAD 1.77 ## IQR 2.53 ## CV 0.73 ## Skewness 1.07 ## SE.Skewness 0.31 ## Kurtosis 0.51 ## N.Valid 60.00 ## Pct.Valid 100.00 Usando esta función (descr) podemos comparar las diferentes medidas entre un vector de datos sin valores extremos y otro con 1 valor extremo, para ver cómo afecta o no este dato las diferentes medidas. original = c(22,10,10,16,15,15,24,19,15,19,18,16,18,12,17,17,11,18) outlier = c(22,10,10,16,15,15,24,19,15,19,18,16,18,12,17,17,11,180) DF = tibble(original, outlier) descr(DF) ## Descriptive Statistics ## DF ## N: 18 ## ## original outlier ## ----------------- ---------- --------- ## Mean 16.22 25.22 ## Std.Dev 3.81 38.81 ## Min 10.00 10.00 ## Q1 15.00 15.00 ## Median 16.50 16.50 ## Q3 18.00 19.00 ## Max 24.00 180.00 ## MAD 2.22 2.97 ## IQR 3.00 3.75 ## CV 0.24 1.54 ## Skewness 0.02 3.50 ## SE.Skewness 0.54 0.54 ## Kurtosis -0.64 11.06 ## N.Valid 18.00 18.00 ## Pct.Valid 100.00 100.00 Viendo el resumen con las diferentes medidas y comparándolas, se puede observar como las medidas de media, desviación estándar, coeficiente de variación, asimetría y curtosis se ven muy afectadas por un único valor extremo, mientras que los cuantiles (incluyendo la mediana) y el mad no se ven afectadas del todo o muy poco. Referencias "],
["estadística-descriptiva-bivariable.html", "Capítulo 10 Estadística Descriptiva Bivariable 10.1 Covarianza 10.2 Correlación 10.3 Regresión", " Capítulo 10 Estadística Descriptiva Bivariable En el capítulo anterior (Estadística Descriptiva Univariable) se enfocó en analizar una variable por separado, sin considerar otra(s) variable(s) que pudiera(n) estar relacionada(s). A veces ese puede ser el enfoque de un análisis o estudio, pero en la mayoría de los casos, muy probablemente, se cuenta con más de una variable y esa(s) variable(s) puede(n) ser importante(s), ya sea para efectos de simple correlación o para efectos de predicción. Esta relación entre dos variables es el enfoque de este capítulo. De manera general se pueden mencionar tres formas de analizar una variable con respecto a otra: Covarianza (lineal), Correlación (lineal), y Regresión (lineal, no lineal). 10.1 Covarianza El objetivo de la covarianza (Ecuación (10.1)) es determinar si hay o no asociación entre 2 variables continuas, y si la hay cómo se comporta una con respecto a la otra, siempre que la relación entre las variables sea lineal. Es el homologo a la varianza pero para dos variables. Ésta puede ser positiva cuando una aumenta conforme la otra aumenta, o negativa cuando una aumenta conforme la otra disminuye. \\[\\begin{equation} s_{xy} = \\frac{\\sum_{i=1}^{N}(x_i - \\bar{x})(y_i - \\bar{y})}{N-1} \\tag{10.1} \\end{equation}\\] donde \\(\\bar{x}\\) es la media de la variable \\(x\\) y \\(\\bar{y}\\) es la media de la variable \\(y\\). Similar a la varianza de una variable, el valor de la covarianza va a depender de la escala de las variables, por lo que NO es ideal para comparar la magnitud de la relación entre las variables. Esta idea se puede demostrar en la Figura 10.1, donde se muestra que aunque los datos tengan tienen una correlación perfecta, la covarianza va a cambiar de acuerdo a la cantidad y escala de los datos. Figura 10.1: Visualización de la covarianza para diferentes datos donde se tiene una correlación perfecta pero la varianza cambia de acuerdo a la escala y cantidad de los datos. En R la función para la covarianza es cov. Si se le pasan dos vectores el resultado es un único valor, pero si se le pasa una matriz o tabla con diferentes variables numéricas el resultado es una matriz de varianza-covarianza. set.seed(101) vec1 = rnorm(n = 30, mean = 40, sd = 5) vec2 = rnorm(n = 30, mean = 20, sd = 3) cov(vec1,vec2) ## [1] 0.2220198 cov(tibble(vec1,vec2)) ## vec1 vec2 ## vec1 17.4519551 0.2220198 ## vec2 0.2220198 9.4703668 cov(rock) ## area peri shape perm ## area 7203044.71232 3160367.49330 -40.820823047 -466063.55213 ## peri 3160367.49330 2049653.68934 -51.775231267 -463032.47715 ## shape -40.82082 -51.77523 0.006971657 20.35164 ## perm -466063.55213 -463032.47715 20.351635275 191684.79915 Del resultado de la matriz de covarianza se observa cómo la escala de las variables afecta el valor de la varianza-covarianza. La diagonal de la matriz es la varianza de la variable respectiva, y las entradas fuera de la diagonal son las covarianzas entre las diferentes variables. 10.2 Correlación El objetivo de la correlación de Pearson (Ecuación (10.2)) es determinar la magnitud de la asociación entre dos variables cuantitativas continuas que tengan una relación lineal. En el caso de que la relación entre las variables no sea lineal se pueden utilizar los coeficientes de correlación de Spearman o Kendall, los cuales son homólogos no-paramétricos que se cubrirán en el capítulo de Estadística No Paramétrica. \\[\\begin{equation} r = \\frac{s_{xy}}{s_{x}s_{y}} \\tag{10.2} \\end{equation}\\] donde \\(s_{xy}\\) es la covarianza entre las variables, \\(s_{x}\\) es la desviación estándar de la variable \\(x\\), y \\(s_{y}\\) es la desviación estándar de la variable \\(y\\). El coeficiente de correlación corresponde con una medida estandarizada ya que tiene la propiedad de que va a estar entre -1 y 1, sin importar la escala y rango de las variables originales (Figura 10.2). Como todas las medidas que dependen de la media, el coeficiente de correlación de Pearson se va a ver afectado por valores extremos (atípicos) y en este caso por la linealidad o no de la relación (Figura 10.3). Figura 10.2: Visualización de coeficiente de correlación de Pearson, con los datos de la figura enterior. Figura 10.3: Ejemplos de la correlación de Pearson y cómo se ve afectado en casos de presencia de valores atípicos (d) y de no linealidad (e, f), estos últimos 3 siendo casos donde no es válido o apropiado usar este coeficiente de correlación (Trauth, 2015). Algo para notar en las Figuras 10.2 y 10.3 es que la correlación se presenta por medio de gráficos de dispersión sin línea de mejor ajuste, ya que si se agrega una línea mejor ajuste se asume regresión y dependencia de una variable con respecto a otra. En R la función para calcular el coeficiente de correlación es cor, donde por defecto estima la correlación de Pearson. de manera similar a la covarianza, si se le pasan dos vectores el resultado es un único valor, pero si se le pasa una matriz o tabla el resultado es una matriz de correlaciones. cor(vec1,vec2) ## [1] 0.01726976 cor(tibble(vec1,vec2)) ## vec1 vec2 ## vec1 1.00000000 0.01726976 ## vec2 0.01726976 1.00000000 cor(rock) ## area peri shape perm ## area 1.0000000 0.8225064 -0.1821611 -0.3966370 ## peri 0.8225064 1.0000000 -0.4331255 -0.7387158 ## shape -0.1821611 -0.4331255 1.0000000 0.5567208 ## perm -0.3966370 -0.7387158 0.5567208 1.0000000 En los resultados se puede ahora sí estimar la magnitud de las relaciones, donde valores cercanos a 1 y -1 indican una asociación mayor y valores cercanos a 0 indican poca o nula asociación. Más delante en el capítulo de Pruebas Estadísticas se podrá determinar si la correlación es nula o no. 10.3 Regresión A diferencia de la correlación donde se busca únicamente establecer la presencia y magnitud de las asociación entre variables, sin importar el orden, la regresión pretende establecer la dependencia de una variable con respecto a otra(s), con el fin de predecir dicha variable y/o entender su relación, ya sea porque es difícil de medir o porque se asume y/o conoce la dependencia de otra variables. El hecho de que las variables estén correlacionadas y se establezca un modelo de regresión, no significa que ambas variables no dependen de una tercera o más variables, por lo que hay que tener cuidado y NO interpretar los resultados como causa y efecto, si ese no fue el diseño de la investigación. De manera general la regresión es el ajuste de un modelo matemático a los datos observados, Ecuación (10.3). \\[\\begin{equation} y = f \\left( x; \\beta \\right) + \\epsilon \\tag{10.3} \\end{equation}\\] donde \\(f \\left( x; \\beta \\right)\\) es el modelo de ajuste definido por el analista, \\(\\beta\\) son los parámetros desconocidos a estimar, y \\(\\epsilon\\) es el error del ajuste. 10.3.1 Nomenclatura En el ámbito de modelos de regresión se manejan diferentes nombres para las partes del modelo. Variable dependiente o respuesta: Es la variable que se pretende predecir, lo que comúnmente se conoce como \\(y\\). Variable independiente o predictor: El o las variables que se van a utilizar para predecir la variable respuesta, lo que comúnmente se conoce como \\(x\\). Coeficiente: El valor estimado del efecto de la variable independiente sobre la dependiente, \\(\\beta\\) en la ecuación del modelo estimado. 10.3.2 Supuestos De manera general los modelos de regresión deben cumplir ciertos supuestos para poder considerarlos como válidos. Para eso se pueden usar lo que se denominan gráficos diagnóstico. Entre los supuestos están: Linealidad: No se refiere la linealidad de los datos originales sino a la relación entre los valores residuales y los valores ajustados (Figura 10.4), donde lo ideal es que no se observen fuertes desviaciones ni tendencias entre estos valores. Figura 10.4: Supuesto de linealidad para un modelo de regresión. Lo ideal es que no se observen fuertes desviaciones ni tendencias. Normalidad: No se refiere la normalidad de los datos originales sino a la normalidad de los residuales, donde lo ideal es que estos residuales sigan una distribución normal, ésto se puede representar por medio del gráfico QQ (Figura 10.5). Figura 10.5: Supuesto de normalidad para un modelo de regresión. Lo ideal es que la mayoría de los puntos caigan cerca de la linea 1:1, y no hayan fuertes desviaciones. Homosquedasticidad (varianza constante): La idea es que los residuales y por ende el ajuste mantenga una varianza o error constante para todo el rango de valores, donde lo lo ideal es que no hayan tendencias ni formas de abanico (Figura 10.6). Figura 10.6: Supuesto de varianza constante para un modelo de regresión. Lo ideal es que no hayan fuertes desviaciones ni tendencias. 10.3.3 Tipos Lineal simple: Es la más básica, cuando se trabaja únicamente con dos variables cuantitativas continuas (Figura 10.7), y el ajuste es una línea. Figura 10.7: Ejemplo de regresión lineal simple. Lineal múltiple: Es cuando se trabaja con 3 o más variables, donde pueden ser de diferentes tipos (cualitativa o cuantitativa) (Figura 10.8), y el ajuste es un plano. Figura 10.8: Ejemplo de regresión lineal multiple. Tomado de: https://dlegorreta.files.wordpress.com/2015/09/regression_lineal.png. No lineal: Es cuando la relación entre las variables sigue una forma más compleja a la lineal (Figura 10.9), la cual puede ser polinomial, exponencial, potencia, logarítmica, o cualquier otro modelo o ecuación. Figura 10.9: Ejemplo de regresión no lineal. Logística: Es cuando la variable dependiente (respuesta) es cualitativa y tiene únicamente dos clases o niveles (Figura 10.10). En este caso el resultado se puede dar como la clase predecida, o las probabilidades de pertenencia a cada clase, donde generalmente se asigna la clase predecida a la clase con más de un 50% de probabilidad. Por esto el eje vertical (y) se representa como probabilidades. Figura 10.10: Ejemplo de regresión logística. 10.3.3.1 Lineal Simple Como se mencionó anteriormente es el tipo de regresión más básica y sencilla ya que lidia únicamente con dos variables cuantitativas continuas. Esta regresión presenta el modelo que se muestra en la Ecuación (10.4), y la forma típica de realizar el ajuste del modelo a los datos es por medio del método de mínimos cuadrados (OLS - ordinary least squares, en inglés), donde se busca minimizar el error (los residuos) en la dirección vertical (Figura 10.11). \\[\\begin{equation} \\hat{y} = \\hat{b}_0 + \\hat{b}_1 x + \\epsilon \\tag{10.4} \\end{equation}\\] donde \\(\\hat{y}\\) son los valores predecidos, \\(\\hat{b}_0\\) es el intercepto, \\(\\hat{b}_1\\) es la pendiente, \\(x\\) es la variable predictora, y \\(\\epsilon\\) es el error de ajuste. En este tipo de regresión lo más importante es la pendiente (\\(\\hat{b}_1\\)) que representa esa relación entre las variables de cómo cambia \\(y\\) con respecto a \\(x\\), donde el valor de la pendiente indica cuanto cambia (incrementa, disminuye) \\(y\\) en promedio por cada unidad de incremento de \\(x\\). El intercepto (\\(\\hat{b}_0\\)) por lo general no es de importancia ya que es un parámetro de ajuste y en la mayoría de las ocasiones carece de sentido práctico. Figura 10.11: Ajuste de modelo lineal simple mostrando los errores como lineas verticales que unen los valores predecidos con los observados. Errores positivos aparecen en color rojo, y errores negativos aparecen en color azul. Cuando la relación entre las dos variables es lineal y se tiene un modelo lineal simple se puede estimar la correlación a partir de la pendiente y viceversa, como se muestra en la Ecuación (10.5): \\[\\begin{equation} r_{xy} = \\hat{b}_1 \\frac{s_x}{s_y}\\\\ \\hat{b}_1 = r_{xy} \\frac{s_y}{s_x} \\tag{10.5} \\end{equation}\\] Más adelante se va a introducir el concepto de estandarización, que es un tipo de transformación que se puede aplicar a una variable o a un modelo. En la regresión lineal simple el coeficiente de correlación, entre las variables \\(x\\) y \\(y\\), es igual a la pendiente (\\(\\hat{b}_1\\)) estandarizada. Si se realiza una regresión lineal simple sobre variables estandarizadas la pendiente va a ser igual al coeficiente de correlación entre la variables. En R para ajustar modelos lineales se usa a función lm, donde los argumentos son primero una formula del tipo y~x (\\(y\\) en función de \\(x\\)), y data la tabla donde se encuentran los datos. Se muestra como ejemplo al ajuste del modelo que se presenta en la Figura 10.7, que es base a un set de datos que trae R por defecto. fit_lin = lm(Temp ~ Wind, airquality) fit_lin %&gt;% tidy() ## # A tibble: 2 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 90.1 2.05 43.9 6.69e-88 ## 2 Wind -1.23 0.194 -6.33 2.64e- 9 Se muestra el ajuste de la temperatura en función de la velocidad del viento, donde el modelo resultante tiene la forma \\(\\hat{Temp} = 90.13 - 1.23 Wind\\). Este resultado se puede interpretar de la siguiente manera: por cada unidad que incrementa la velocidad del viento en millas por hora (mph), la temperatura decrece en 1.23 grados Fahrenheit. Otra interpretación podría ser que por cada 10 mph que incrementa la velocidad del viento, la temperatura decrece 12.3 grados Fahrenheit. Al multiplicar las unidades de \\(x\\) por un factor la pendiente se va a ver afectada por ese mismo factor, en el ejemplo anterior siendo el factor 10. Por el momento en la tabla de resultados que se muestra únicamente es de interés el coeficiente (term) y su valor (estimate), más adelante se explicará el resto de las columnas. La función tidy del paquete broom (Robinson &amp; Hayes, 2020) y del metapaquete tidymodels (Kuhn &amp; Wickham, 2020) es una función que ordena el resultado del ajuste en una tabla para mayor facilidad de interpretación y manipulación. 10.3.4 Medidas de ajuste y error Una vez ajustado un modelo es importante saber la calidad del ajuste, ya que se pueden generar varios modelos y se quisiera saber cuál modelo se ajusta mejor o representa mejor los datos. Para este fin se pueden usar varias métricas. 10.3.4.1 RMSE El Root Mean Square Error (RMSE en inglés) o error cuadrático medio (Ecuación (10.6)) mide qué tan diferentes (alejados) son los residuos de la línea de mejor ajuste. Tiene la propiedad de que se encuentra en la misma escala de la variable respuesta, por lo que va a depender de la misma. En general a menor RMSE mejor ajuste, pero esta métrica es más útil para comparar modelos. \\[\\begin{equation} RMSE = \\sqrt{\\frac{1}{N} \\sum_{i=1}^{N} \\left(y_i - \\hat{y}\\right)^2} \\tag{10.6} \\end{equation}\\] 10.3.4.2 Coeficiente de determinación (\\(R^2\\)) El coeficiente de determinación (\\(R^2\\)) es una métrica de ajuste estandarizada, ya que varia entre 0 y 1, donde mientras más cercano a 1 mejor el ajuste. Esta métrica se puede interpretar como el porcentaje de variación en la variable respuesta que puede ser explicado por la variable predictora. Para el caso de la regresión lineal simple (únicamente) se puede relacionar el coeficiente de determinación con el coeficiente de correlación de la siguiente manera: \\(R^2 = r^2\\), o lo que es lo mismo \\(r = \\sqrt{R^2}\\). En R hay diferentes funciones para obtener diferentes métricas de ajuste. La función glance del paquete broom extrae del modelo varias medidas de ajuste, entre ellas el \\(R^2\\). La función RMSE del paquete DescTools extrae el valor de esta métrica. fit_lin %&gt;% glance() ## # A tibble: 1 x 11 ## r.squared adj.r.squared sigma statistic p.value df logLik AIC BIC ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.210 0.205 8.44 40.1 2.64e-9 2 -542. 1091. 1100. ## # … with 2 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt; RMSE(fit_lin) ## [1] 8.386689 Con este valor de \\(R^2\\) se puede estimar y corroborar el coeficiente de correlación. Tener en cuenta el signo de la pendiente, en este caso negativo, ya que el \\(R^2\\) siempre es positivo y la raíz siempre va a ser positiva, por lo que hay que asignarle el signo de la pendiente. sqrt(fit_lin %&gt;% glance() %&gt;% pull(r.squared)) * -1 ## [1] -0.4579879 with(airquality, cor(Temp,Wind)) ## [1] -0.4579879 Referencias "],
["probabilidad.html", "Capítulo 11 Probabilidad", " Capítulo 11 Probabilidad "],
["distribuciones-de-probabilidad.html", "Capítulo 12 Distribuciones de Probabilidad", " Capítulo 12 Distribuciones de Probabilidad "],
["introducción-a-estadística-inferencial.html", "Capítulo 13 Introducción a Estadística Inferencial", " Capítulo 13 Introducción a Estadística Inferencial "],
["estimación.html", "Capítulo 14 Estimación", " Capítulo 14 Estimación "],
["pruebas-estadísticas.html", "Capítulo 15 Pruebas Estadísticas", " Capítulo 15 Pruebas Estadísticas "],
["estadística-no-paramétrica.html", "Capítulo 16 Estadística No Paramétrica", " Capítulo 16 Estadística No Paramétrica "],
["estadística-direccional.html", "Capítulo 17 Estadística Direccional", " Capítulo 17 Estadística Direccional "],
["secuencias-de-datos.html", "Capítulo 18 Secuencias de Datos", " Capítulo 18 Secuencias de Datos "],
["geoestadística.html", "Capítulo 19 Geoestadística", " Capítulo 19 Geoestadística "],
["referencias.html", "Referencias", " Referencias "]
]
