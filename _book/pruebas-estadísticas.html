<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="es" xml:lang="es">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 15 Pruebas Estadísticas | Geología Numérica: Ciencia de Datos para Geociencias</title>
  <meta name="description" content="Este documento compila el funcionamiento básico del software estadístico y de programación R, así como rutinas y/o comandos específicos para resolver problemas de análisis de datos en geociencias." />
  <meta name="generator" content="bookdown 0.11 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 15 Pruebas Estadísticas | Geología Numérica: Ciencia de Datos para Geociencias" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Este documento compila el funcionamiento básico del software estadístico y de programación R, así como rutinas y/o comandos específicos para resolver problemas de análisis de datos en geociencias." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 15 Pruebas Estadísticas | Geología Numérica: Ciencia de Datos para Geociencias" />
  
  <meta name="twitter:description" content="Este documento compila el funcionamiento básico del software estadístico y de programación R, así como rutinas y/o comandos específicos para resolver problemas de análisis de datos en geociencias." />
  

<meta name="author" content="Maximiliano Garnier Villarreal" />


<meta name="date" content="2020-07-03" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="estimación-e-hipótesis.html">
<link rel="next" href="estadística-no-paramétrica.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.5.1/htmlwidgets.js"></script>
<link href="libs/dygraphs-1.1.1/dygraph.css" rel="stylesheet" />
<script src="libs/dygraphs-1.1.1/dygraph-combined.js"></script>
<script src="libs/dygraphs-1.1.1/shapes.js"></script>
<script src="libs/moment-2.8.4/moment.js"></script>
<script src="libs/moment-timezone-0.2.5/moment-timezone-with-data.js"></script>
<script src="libs/moment-fquarter-1.0.0/moment-fquarter.min.js"></script>
<script src="libs/dygraphs-binding-1.1.1.6/dygraphs.js"></script>
<script src="libs/plotly-binding-4.9.2/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-1.52.2/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-1.52.2/plotly-latest.min.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.11/datatables.js"></script>
<link href="libs/dt-core-1.10.19/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.19/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.19/js/jquery.dataTables.min.js"></script>
<link href="libs/nouislider-7.0.10/jquery.nouislider.min.css" rel="stylesheet" />
<script src="libs/nouislider-7.0.10/jquery.nouislider.min.js"></script>
<link href="libs/selectize-0.12.0/selectize.bootstrap3.css" rel="stylesheet" />
<script src="libs/selectize-0.12.0/selectize.min.js"></script>
<script src="libs/proj4js-2.3.15/proj4.js"></script>
<link href="libs/highcharts-7.0.1/css/motion.css" rel="stylesheet" />
<link href="libs/highcharts-7.0.1/css/htmlwdgtgrid.css" rel="stylesheet" />
<script src="libs/highcharts-7.0.1/highcharts.js"></script>
<script src="libs/highcharts-7.0.1/highcharts-3d.js"></script>
<script src="libs/highcharts-7.0.1/highcharts-more.js"></script>
<script src="libs/highcharts-7.0.1/modules/stock.js"></script>
<script src="libs/highcharts-7.0.1/modules/map.js"></script>
<script src="libs/highcharts-7.0.1/modules/annotations.js"></script>
<script src="libs/highcharts-7.0.1/modules/boost.js"></script>
<script src="libs/highcharts-7.0.1/modules/data.js"></script>
<script src="libs/highcharts-7.0.1/modules/drag-panes.js"></script>
<script src="libs/highcharts-7.0.1/modules/drilldown.js"></script>
<script src="libs/highcharts-7.0.1/modules/item-series.js"></script>
<script src="libs/highcharts-7.0.1/modules/offline-exporting.js"></script>
<script src="libs/highcharts-7.0.1/modules/overlapping-datalabels.js"></script>
<script src="libs/highcharts-7.0.1/modules/exporting.js"></script>
<script src="libs/highcharts-7.0.1/modules/export-data.js"></script>
<script src="libs/highcharts-7.0.1/modules/funnel.js"></script>
<script src="libs/highcharts-7.0.1/modules/heatmap.js"></script>
<script src="libs/highcharts-7.0.1/modules/treemap.js"></script>
<script src="libs/highcharts-7.0.1/modules/sankey.js"></script>
<script src="libs/highcharts-7.0.1/modules/solid-gauge.js"></script>
<script src="libs/highcharts-7.0.1/modules/streamgraph.js"></script>
<script src="libs/highcharts-7.0.1/modules/sunburst.js"></script>
<script src="libs/highcharts-7.0.1/modules/vector.js"></script>
<script src="libs/highcharts-7.0.1/modules/wordcloud.js"></script>
<script src="libs/highcharts-7.0.1/modules/xrange.js"></script>
<script src="libs/highcharts-7.0.1/modules/tilemap.js"></script>
<script src="libs/highcharts-7.0.1/modules/venn.js"></script>
<script src="libs/highcharts-7.0.1/modules/gantt.js"></script>
<script src="libs/highcharts-7.0.1/modules/timeline.js"></script>
<script src="libs/highcharts-7.0.1/modules/parallel-coordinates.js"></script>
<script src="libs/highcharts-7.0.1/plugins/grouped-categories.js"></script>
<script src="libs/highcharts-7.0.1/plugins/motion.js"></script>
<script src="libs/highcharts-7.0.1/plugins/multicolor_series.js"></script>
<script src="libs/highcharts-7.0.1/custom/reset.js"></script>
<script src="libs/highcharts-7.0.1/custom/symbols-extra.js"></script>
<script src="libs/highcharts-7.0.1/custom/text-symbols.js"></script>
<script src="libs/highchart-binding-0.7.0/highchart.js"></script>
<script src="libs/highcharts-regression.js-7.0.1/highcharts-regression.js"></script>
<link href="libs/leaflet-1.3.1/leaflet.css" rel="stylesheet" />
<script src="libs/leaflet-1.3.1/leaflet.js"></script>
<link href="libs/leafletfix-1.0.0/leafletfix.css" rel="stylesheet" />
<script src="libs/Proj4Leaflet-1.0.1/proj4-compressed.js"></script>
<script src="libs/Proj4Leaflet-1.0.1/proj4leaflet.js"></script>
<link href="libs/rstudio_leaflet-1.3.1/rstudio_leaflet.css" rel="stylesheet" />
<script src="libs/leaflet-binding-2.0.2/leaflet.js"></script>
<script src="libs/leaflet-providers-1.1.17/leaflet-providers.js"></script>
<script src="libs/leaflet-providers-plugin-2.0.2/leaflet-providers-plugin.js"></script>
<link href="libs/HomeButton-0.0.1/home-button.css" rel="stylesheet" />
<script src="libs/HomeButton-0.0.1/home-button.js"></script>
<script src="libs/HomeButton-0.0.1/easy-button-src.min.js"></script>
<script src="libs/clipboard-0.0.1/setClipboardText.js"></script>
<link href="libs/PopupTable-0.0.1/popup.css" rel="stylesheet" />
<script src="libs/pacifico-1/data_stars_pacificocdf13b.txt"></script>
<script src="libs/joda-0.0.1/joda.js"></script>
<script src="libs/joda-0.0.1/addImageQuery-bindings.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Geologia Numerica</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prefacio</a></li>
<li class="part"><span><b>R</b></span></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introducción</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#instalación-de-r-y-rstudio"><i class="fa fa-check"></i><b>1.1</b> Instalación de R y RStudio</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#paquetes"><i class="fa fa-check"></i><b>1.2</b> Paquetes</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#ayuda-en-r"><i class="fa fa-check"></i><b>1.3</b> Ayuda en R</a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#rmarkdown"><i class="fa fa-check"></i><b>1.4</b> RMarkdown</a><ul>
<li class="chapter" data-level="1.4.1" data-path="intro.html"><a href="intro.html#tipos-de-resultados"><i class="fa fa-check"></i><b>1.4.1</b> Tipos de resultados</a></li>
<li class="chapter" data-level="1.4.2" data-path="intro.html"><a href="intro.html#formulas"><i class="fa fa-check"></i><b>1.4.2</b> Formulas</a></li>
<li class="chapter" data-level="1.4.3" data-path="intro.html"><a href="intro.html#importando-datos"><i class="fa fa-check"></i><b>1.4.3</b> Importando datos</a></li>
<li class="chapter" data-level="1.4.4" data-path="intro.html"><a href="intro.html#cálculos-en-linea"><i class="fa fa-check"></i><b>1.4.4</b> Cálculos en linea</a></li>
<li class="chapter" data-level="1.4.5" data-path="intro.html"><a href="intro.html#importando-figuras"><i class="fa fa-check"></i><b>1.4.5</b> Importando figuras</a></li>
<li class="chapter" data-level="1.4.6" data-path="intro.html"><a href="intro.html#salvando-y-compartiendo"><i class="fa fa-check"></i><b>1.4.6</b> Salvando y compartiendo</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="intro.html"><a href="intro.html#recursos"><i class="fa fa-check"></i><b>1.5</b> Recursos</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="basico.html"><a href="basico.html"><i class="fa fa-check"></i><b>2</b> Funcionamiento básico de R</a><ul>
<li class="chapter" data-level="2.1" data-path="basico.html"><a href="basico.html#introducción"><i class="fa fa-check"></i><b>2.1</b> Introducción</a></li>
<li class="chapter" data-level="2.2" data-path="basico.html"><a href="basico.html#operaciones-básicas"><i class="fa fa-check"></i><b>2.2</b> Operaciones básicas</a></li>
<li class="chapter" data-level="2.3" data-path="basico.html"><a href="basico.html#crear-objetos"><i class="fa fa-check"></i><b>2.3</b> Crear objetos</a></li>
<li class="chapter" data-level="2.4" data-path="basico.html"><a href="basico.html#vectores"><i class="fa fa-check"></i><b>2.4</b> Vectores</a><ul>
<li class="chapter" data-level="2.4.1" data-path="basico.html"><a href="basico.html#numéricos"><i class="fa fa-check"></i><b>2.4.1</b> Numéricos</a></li>
<li class="chapter" data-level="2.4.2" data-path="basico.html"><a href="basico.html#texto-string-character"><i class="fa fa-check"></i><b>2.4.2</b> Texto (string, character)</a></li>
<li class="chapter" data-level="2.4.3" data-path="basico.html"><a href="basico.html#categóricos-factores"><i class="fa fa-check"></i><b>2.4.3</b> Categóricos (factores)</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="basico.html"><a href="basico.html#matrices"><i class="fa fa-check"></i><b>2.5</b> Matrices</a></li>
<li class="chapter" data-level="2.6" data-path="basico.html"><a href="basico.html#dataframes-listas-y-tibbles"><i class="fa fa-check"></i><b>2.6</b> DataFrames, listas y tibbles</a></li>
<li class="chapter" data-level="2.7" data-path="basico.html"><a href="basico.html#verificando-objetos"><i class="fa fa-check"></i><b>2.7</b> Verificando objetos</a></li>
<li class="chapter" data-level="2.8" data-path="basico.html"><a href="basico.html#guardando-el-espacio-de-trabajo"><i class="fa fa-check"></i><b>2.8</b> Guardando el espacio de trabajo</a></li>
<li class="chapter" data-level="2.9" data-path="basico.html"><a href="basico.html#importandocargando-datos"><i class="fa fa-check"></i><b>2.9</b> Importando/cargando datos</a></li>
<li class="chapter" data-level="2.10" data-path="basico.html"><a href="basico.html#exportando-datos"><i class="fa fa-check"></i><b>2.10</b> Exportando datos</a></li>
<li class="chapter" data-level="2.11" data-path="basico.html"><a href="basico.html#inspeccionando-los-datos"><i class="fa fa-check"></i><b>2.11</b> Inspeccionando los datos</a></li>
<li class="chapter" data-level="2.12" data-path="basico.html"><a href="basico.html#descripciones-generales-globales"><i class="fa fa-check"></i><b>2.12</b> Descripciones generales (globales)</a></li>
<li class="chapter" data-level="2.13" data-path="basico.html"><a href="basico.html#recursos-1"><i class="fa fa-check"></i><b>2.13</b> Recursos</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="avanzado.html"><a href="avanzado.html"><i class="fa fa-check"></i><b>3</b> Funcionamiento avanzado de R</a><ul>
<li class="chapter" data-level="3.1" data-path="avanzado.html"><a href="avanzado.html#introducción-1"><i class="fa fa-check"></i><b>3.1</b> Introducción</a></li>
<li class="chapter" data-level="3.2" data-path="avanzado.html"><a href="avanzado.html#operadores-lógicos"><i class="fa fa-check"></i><b>3.2</b> Operadores lógicos</a></li>
<li class="chapter" data-level="3.3" data-path="avanzado.html"><a href="avanzado.html#operador-de-secuencia-pipe-operator"><i class="fa fa-check"></i><b>3.3</b> Operador de secuencia (Pipe operator)</a></li>
<li class="chapter" data-level="3.4" data-path="avanzado.html"><a href="avanzado.html#resumen-de-variables"><i class="fa fa-check"></i><b>3.4</b> Resumen de variables</a></li>
<li class="chapter" data-level="3.5" data-path="avanzado.html"><a href="avanzado.html#selección-y-renombre-de-variables"><i class="fa fa-check"></i><b>3.5</b> Selección y renombre de variables</a><ul>
<li class="chapter" data-level="3.5.1" data-path="avanzado.html"><a href="avanzado.html#select-helpers"><i class="fa fa-check"></i><b>3.5.1</b> <code>select</code> helpers</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="avanzado.html"><a href="avanzado.html#filtrado-de-observaciones"><i class="fa fa-check"></i><b>3.6</b> Filtrado de observaciones</a></li>
<li class="chapter" data-level="3.7" data-path="avanzado.html"><a href="avanzado.html#orden-de-acuerdo-a-variables"><i class="fa fa-check"></i><b>3.7</b> Orden de acuerdo a variables</a></li>
<li class="chapter" data-level="3.8" data-path="avanzado.html"><a href="avanzado.html#creación-de-variables"><i class="fa fa-check"></i><b>3.8</b> Creación de variables</a></li>
<li class="chapter" data-level="3.9" data-path="avanzado.html"><a href="avanzado.html#conteo-de-variables-cualitativas"><i class="fa fa-check"></i><b>3.9</b> Conteo de variables cualitativas</a></li>
<li class="chapter" data-level="3.10" data-path="avanzado.html"><a href="avanzado.html#tabla-interactiva"><i class="fa fa-check"></i><b>3.10</b> Tabla interactiva</a></li>
<li class="chapter" data-level="3.11" data-path="avanzado.html"><a href="avanzado.html#datos-relacionales"><i class="fa fa-check"></i><b>3.11</b> Datos relacionales</a><ul>
<li class="chapter" data-level="3.11.1" data-path="avanzado.html"><a href="avanzado.html#uniones-de-transformación"><i class="fa fa-check"></i><b>3.11.1</b> Uniones de transformación</a></li>
<li class="chapter" data-level="3.11.2" data-path="avanzado.html"><a href="avanzado.html#uniones-de-filtro"><i class="fa fa-check"></i><b>3.11.2</b> Uniones de filtro</a></li>
</ul></li>
<li class="chapter" data-level="3.12" data-path="avanzado.html"><a href="avanzado.html#datos-ordenados-tidy-data"><i class="fa fa-check"></i><b>3.12</b> Datos ordenados (Tidy data)</a><ul>
<li class="chapter" data-level="3.12.1" data-path="avanzado.html"><a href="avanzado.html#formatos-largo-y-ancho"><i class="fa fa-check"></i><b>3.12.1</b> Formatos largo y ancho</a></li>
<li class="chapter" data-level="3.12.2" data-path="avanzado.html"><a href="avanzado.html#separar-y-unir"><i class="fa fa-check"></i><b>3.12.2</b> Separar y unir</a></li>
</ul></li>
<li class="chapter" data-level="3.13" data-path="avanzado.html"><a href="avanzado.html#nest"><i class="fa fa-check"></i><b>3.13</b> Datos anidados (Nesting)</a></li>
<li class="chapter" data-level="3.14" data-path="avanzado.html"><a href="avanzado.html#recursos-2"><i class="fa fa-check"></i><b>3.14</b> Recursos</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="gráficos-1.html"><a href="gráficos-1.html"><i class="fa fa-check"></i><b>4</b> Gráficos</a><ul>
<li class="chapter" data-level="4.1" data-path="gráficos-1.html"><a href="gráficos-1.html#introducción-2"><i class="fa fa-check"></i><b>4.1</b> Introducción</a></li>
<li class="chapter" data-level="4.2" data-path="gráficos-1.html"><a href="gráficos-1.html#estáticos"><i class="fa fa-check"></i><b>4.2</b> Estáticos</a><ul>
<li class="chapter" data-level="4.2.1" data-path="gráficos-1.html"><a href="gráficos-1.html#histograma"><i class="fa fa-check"></i><b>4.2.1</b> Histograma</a></li>
<li class="chapter" data-level="4.2.2" data-path="gráficos-1.html"><a href="gráficos-1.html#barras"><i class="fa fa-check"></i><b>4.2.2</b> Barras</a></li>
<li class="chapter" data-level="4.2.3" data-path="gráficos-1.html"><a href="gráficos-1.html#boxplot"><i class="fa fa-check"></i><b>4.2.3</b> Boxplot</a></li>
<li class="chapter" data-level="4.2.4" data-path="gráficos-1.html"><a href="gráficos-1.html#dispersión"><i class="fa fa-check"></i><b>4.2.4</b> Dispersión</a></li>
<li class="chapter" data-level="4.2.5" data-path="gráficos-1.html"><a href="gráficos-1.html#líneas"><i class="fa fa-check"></i><b>4.2.5</b> líneas</a></li>
<li class="chapter" data-level="4.2.6" data-path="gráficos-1.html"><a href="gráficos-1.html#gráficos-estadísticos"><i class="fa fa-check"></i><b>4.2.6</b> Gráficos estadísticos</a></li>
<li class="chapter" data-level="4.2.7" data-path="gráficos-1.html"><a href="gráficos-1.html#transformación-de-ejes"><i class="fa fa-check"></i><b>4.2.7</b> Transformación de ejes</a></li>
<li class="chapter" data-level="4.2.8" data-path="gráficos-1.html"><a href="gráficos-1.html#limites-de-ejes-zoom"><i class="fa fa-check"></i><b>4.2.8</b> Limites de ejes (Zoom)</a></li>
<li class="chapter" data-level="4.2.9" data-path="gráficos-1.html"><a href="gráficos-1.html#salvando-gráficos"><i class="fa fa-check"></i><b>4.2.9</b> Salvando gráficos</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="gráficos-1.html"><a href="gráficos-1.html#interactivos"><i class="fa fa-check"></i><b>4.3</b> Interactivos</a><ul>
<li class="chapter" data-level="4.3.1" data-path="gráficos-1.html"><a href="gráficos-1.html#histograma-1"><i class="fa fa-check"></i><b>4.3.1</b> Histograma</a></li>
<li class="chapter" data-level="4.3.2" data-path="gráficos-1.html"><a href="gráficos-1.html#barras-1"><i class="fa fa-check"></i><b>4.3.2</b> Barras</a></li>
<li class="chapter" data-level="4.3.3" data-path="gráficos-1.html"><a href="gráficos-1.html#boxplot-1"><i class="fa fa-check"></i><b>4.3.3</b> Boxplot</a></li>
<li class="chapter" data-level="4.3.4" data-path="gráficos-1.html"><a href="gráficos-1.html#dispersión-1"><i class="fa fa-check"></i><b>4.3.4</b> Dispersión</a></li>
<li class="chapter" data-level="4.3.5" data-path="gráficos-1.html"><a href="gráficos-1.html#líneas-1"><i class="fa fa-check"></i><b>4.3.5</b> líneas</a></li>
<li class="chapter" data-level="4.3.6" data-path="gráficos-1.html"><a href="gráficos-1.html#transformación-de-ejes-1"><i class="fa fa-check"></i><b>4.3.6</b> Transformación de ejes</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="gráficos-1.html"><a href="gráficos-1.html#recursos-3"><i class="fa fa-check"></i><b>4.4</b> Recursos</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="iteración.html"><a href="iteración.html"><i class="fa fa-check"></i><b>5</b> Iteración</a><ul>
<li class="chapter" data-level="5.1" data-path="iteración.html"><a href="iteración.html#introducción-3"><i class="fa fa-check"></i><b>5.1</b> Introducción</a></li>
<li class="chapter" data-level="5.2" data-path="iteración.html"><a href="iteración.html#iterando-sobre-un-objeto"><i class="fa fa-check"></i><b>5.2</b> Iterando sobre un objeto</a></li>
<li class="chapter" data-level="5.3" data-path="iteración.html"><a href="iteración.html#iterando-sobre-dos-objetos"><i class="fa fa-check"></i><b>5.3</b> Iterando sobre dos objetos</a></li>
<li class="chapter" data-level="5.4" data-path="iteración.html"><a href="iteración.html#leyendo-archivos-y-combinándolos"><i class="fa fa-check"></i><b>5.4</b> Leyendo archivos y combinándolos</a></li>
<li class="chapter" data-level="5.5" data-path="iteración.html"><a href="iteración.html#datos-anidados-caso-1"><i class="fa fa-check"></i><b>5.5</b> Datos anidados, caso 1</a><ul>
<li class="chapter" data-level="5.5.1" data-path="iteración.html"><a href="iteración.html#efectos-secundarios"><i class="fa fa-check"></i><b>5.5.1</b> Efectos secundarios</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="iteración.html"><a href="iteración.html#datos-anidados-caso-2"><i class="fa fa-check"></i><b>5.6</b> Datos anidados, caso 2</a></li>
<li class="chapter" data-level="5.7" data-path="iteración.html"><a href="iteración.html#recursos-4"><i class="fa fa-check"></i><b>5.7</b> Recursos</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="datos-espaciales.html"><a href="datos-espaciales.html"><i class="fa fa-check"></i><b>6</b> Datos espaciales</a><ul>
<li class="chapter" data-level="6.1" data-path="datos-espaciales.html"><a href="datos-espaciales.html#introducción-4"><i class="fa fa-check"></i><b>6.1</b> Introducción</a></li>
<li class="chapter" data-level="6.2" data-path="datos-espaciales.html"><a href="datos-espaciales.html#paquetes-para-datos-espaciales"><i class="fa fa-check"></i><b>6.2</b> Paquetes para datos espaciales</a></li>
<li class="chapter" data-level="6.3" data-path="datos-espaciales.html"><a href="datos-espaciales.html#sistemas-de-referencias-de-coordenadas-crs"><i class="fa fa-check"></i><b>6.3</b> Sistemas de Referencias de Coordenadas (CRS)</a></li>
<li class="chapter" data-level="6.4" data-path="datos-espaciales.html"><a href="datos-espaciales.html#importar-datos"><i class="fa fa-check"></i><b>6.4</b> Importar datos</a><ul>
<li class="chapter" data-level="6.4.1" data-path="datos-espaciales.html"><a href="datos-espaciales.html#desde-archivos-de-texto"><i class="fa fa-check"></i><b>6.4.1</b> Desde archivos de texto</a></li>
<li class="chapter" data-level="6.4.2" data-path="datos-espaciales.html"><a href="datos-espaciales.html#desde-archivos-espaciales"><i class="fa fa-check"></i><b>6.4.2</b> Desde archivos espaciales</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="datos-espaciales.html"><a href="datos-espaciales.html#exportar-datos"><i class="fa fa-check"></i><b>6.5</b> Exportar datos</a><ul>
<li class="chapter" data-level="6.5.1" data-path="datos-espaciales.html"><a href="datos-espaciales.html#vectoriales"><i class="fa fa-check"></i><b>6.5.1</b> Vectoriales</a></li>
<li class="chapter" data-level="6.5.2" data-path="datos-espaciales.html"><a href="datos-espaciales.html#raster-1"><i class="fa fa-check"></i><b>6.5.2</b> Raster</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="datos-espaciales.html"><a href="datos-espaciales.html#mapas"><i class="fa fa-check"></i><b>6.6</b> Mapas</a><ul>
<li class="chapter" data-level="6.6.1" data-path="datos-espaciales.html"><a href="datos-espaciales.html#estáticos-1"><i class="fa fa-check"></i><b>6.6.1</b> Estáticos</a></li>
<li class="chapter" data-level="6.6.2" data-path="datos-espaciales.html"><a href="datos-espaciales.html#dinámicos"><i class="fa fa-check"></i><b>6.6.2</b> Dinámicos</a></li>
<li class="chapter" data-level="6.6.3" data-path="datos-espaciales.html"><a href="datos-espaciales.html#modelos-de-sombras"><i class="fa fa-check"></i><b>6.6.3</b> Modelos de sombras</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="datos-espaciales.html"><a href="datos-espaciales.html#recursos-5"><i class="fa fa-check"></i><b>6.7</b> Recursos</a></li>
</ul></li>
<li class="part"><span><b>Análisis de datos</b></span></li>
<li class="chapter" data-level="7" data-path="álgebra-lineal.html"><a href="álgebra-lineal.html"><i class="fa fa-check"></i><b>7</b> Álgebra lineal</a><ul>
<li class="chapter" data-level="7.1" data-path="álgebra-lineal.html"><a href="álgebra-lineal.html#introducción-5"><i class="fa fa-check"></i><b>7.1</b> Introducción</a></li>
<li class="chapter" data-level="7.2" data-path="álgebra-lineal.html"><a href="álgebra-lineal.html#tensores"><i class="fa fa-check"></i><b>7.2</b> Tensores</a><ul>
<li class="chapter" data-level="7.2.1" data-path="álgebra-lineal.html"><a href="álgebra-lineal.html#vectores-1"><i class="fa fa-check"></i><b>7.2.1</b> Vectores</a></li>
<li class="chapter" data-level="7.2.2" data-path="álgebra-lineal.html"><a href="álgebra-lineal.html#matrices-1"><i class="fa fa-check"></i><b>7.2.2</b> Matrices</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="álgebra-lineal.html"><a href="álgebra-lineal.html#eigenvectors-y-eigenvalues"><i class="fa fa-check"></i><b>7.3</b> Eigenvectors y Eigenvalues</a><ul>
<li class="chapter" data-level="7.3.1" data-path="álgebra-lineal.html"><a href="álgebra-lineal.html#definición"><i class="fa fa-check"></i><b>7.3.1</b> Definición</a></li>
<li class="chapter" data-level="7.3.2" data-path="álgebra-lineal.html"><a href="álgebra-lineal.html#cálculo"><i class="fa fa-check"></i><b>7.3.2</b> Cálculo</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="introducción-a-estadística.html"><a href="introducción-a-estadística.html"><i class="fa fa-check"></i><b>8</b> Introducción a estadística</a><ul>
<li class="chapter" data-level="8.1" data-path="introducción-a-estadística.html"><a href="introducción-a-estadística.html#introducción-6"><i class="fa fa-check"></i><b>8.1</b> Introducción</a></li>
<li class="chapter" data-level="8.2" data-path="introducción-a-estadística.html"><a href="introducción-a-estadística.html#tipos"><i class="fa fa-check"></i><b>8.2</b> Tipos</a></li>
<li class="chapter" data-level="8.3" data-path="introducción-a-estadística.html"><a href="introducción-a-estadística.html#modelos"><i class="fa fa-check"></i><b>8.3</b> Modelos</a></li>
<li class="chapter" data-level="8.4" data-path="introducción-a-estadística.html"><a href="introducción-a-estadística.html#nomenclatura"><i class="fa fa-check"></i><b>8.4</b> Nomenclatura</a></li>
<li class="chapter" data-level="8.5" data-path="introducción-a-estadística.html"><a href="introducción-a-estadística.html#variables"><i class="fa fa-check"></i><b>8.5</b> Variables</a><ul>
<li class="chapter" data-level="8.5.1" data-path="introducción-a-estadística.html"><a href="introducción-a-estadística.html#cualitativa"><i class="fa fa-check"></i><b>8.5.1</b> Cualitativa</a></li>
<li class="chapter" data-level="8.5.2" data-path="introducción-a-estadística.html"><a href="introducción-a-estadística.html#cuantitativa"><i class="fa fa-check"></i><b>8.5.2</b> Cuantitativa</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="introducción-a-estadística.html"><a href="introducción-a-estadística.html#métodos-de-análisis"><i class="fa fa-check"></i><b>8.6</b> Métodos de análisis</a></li>
<li class="chapter" data-level="8.7" data-path="introducción-a-estadística.html"><a href="introducción-a-estadística.html#muestreo"><i class="fa fa-check"></i><b>8.7</b> Muestreo</a><ul>
<li class="chapter" data-level="8.7.1" data-path="introducción-a-estadística.html"><a href="introducción-a-estadística.html#tipos-1"><i class="fa fa-check"></i><b>8.7.1</b> Tipos</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="introducción-a-estadística.html"><a href="introducción-a-estadística.html#incertidumbre"><i class="fa fa-check"></i><b>8.8</b> Incertidumbre</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="estadística-descriptiva-univariable.html"><a href="estadística-descriptiva-univariable.html"><i class="fa fa-check"></i><b>9</b> Estadística Descriptiva Univariable</a><ul>
<li class="chapter" data-level="9.1" data-path="estadística-descriptiva-univariable.html"><a href="estadística-descriptiva-univariable.html#introducción-7"><i class="fa fa-check"></i><b>9.1</b> Introducción</a></li>
<li class="chapter" data-level="9.2" data-path="estadística-descriptiva-univariable.html"><a href="estadística-descriptiva-univariable.html#tablas-de-frecuencias"><i class="fa fa-check"></i><b>9.2</b> Tablas de frecuencias</a></li>
<li class="chapter" data-level="9.3" data-path="estadística-descriptiva-univariable.html"><a href="estadística-descriptiva-univariable.html#gráficas"><i class="fa fa-check"></i><b>9.3</b> Gráficas</a></li>
<li class="chapter" data-level="9.4" data-path="estadística-descriptiva-univariable.html"><a href="estadística-descriptiva-univariable.html#resúmenes-numéricos"><i class="fa fa-check"></i><b>9.4</b> Resúmenes numéricos</a><ul>
<li class="chapter" data-level="9.4.1" data-path="estadística-descriptiva-univariable.html"><a href="estadística-descriptiva-univariable.html#medidas-de-tendencia-central"><i class="fa fa-check"></i><b>9.4.1</b> Medidas de tendencia central</a></li>
<li class="chapter" data-level="9.4.2" data-path="estadística-descriptiva-univariable.html"><a href="estadística-descriptiva-univariable.html#medidas-de-dispersión"><i class="fa fa-check"></i><b>9.4.2</b> Medidas de dispersión</a></li>
<li class="chapter" data-level="9.4.3" data-path="estadística-descriptiva-univariable.html"><a href="estadística-descriptiva-univariable.html#medidas-de-posición"><i class="fa fa-check"></i><b>9.4.3</b> Medidas de posición</a></li>
<li class="chapter" data-level="9.4.4" data-path="estadística-descriptiva-univariable.html"><a href="estadística-descriptiva-univariable.html#medidas-de-forma"><i class="fa fa-check"></i><b>9.4.4</b> Medidas de forma</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="estadística-descriptiva-univariable.html"><a href="estadística-descriptiva-univariable.html#resumen-general"><i class="fa fa-check"></i><b>9.5</b> Resumen general</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="estadística-descriptiva-bivariable.html"><a href="estadística-descriptiva-bivariable.html"><i class="fa fa-check"></i><b>10</b> Estadística Descriptiva Bivariable</a><ul>
<li class="chapter" data-level="10.1" data-path="estadística-descriptiva-bivariable.html"><a href="estadística-descriptiva-bivariable.html#introducción-8"><i class="fa fa-check"></i><b>10.1</b> Introducción</a></li>
<li class="chapter" data-level="10.2" data-path="estadística-descriptiva-bivariable.html"><a href="estadística-descriptiva-bivariable.html#covarianza"><i class="fa fa-check"></i><b>10.2</b> Covarianza</a></li>
<li class="chapter" data-level="10.3" data-path="estadística-descriptiva-bivariable.html"><a href="estadística-descriptiva-bivariable.html#bivar-cor"><i class="fa fa-check"></i><b>10.3</b> Correlación</a></li>
<li class="chapter" data-level="10.4" data-path="estadística-descriptiva-bivariable.html"><a href="estadística-descriptiva-bivariable.html#bivar-reg"><i class="fa fa-check"></i><b>10.4</b> Regresión</a><ul>
<li class="chapter" data-level="10.4.1" data-path="estadística-descriptiva-bivariable.html"><a href="estadística-descriptiva-bivariable.html#nomenclatura-1"><i class="fa fa-check"></i><b>10.4.1</b> Nomenclatura</a></li>
<li class="chapter" data-level="10.4.2" data-path="estadística-descriptiva-bivariable.html"><a href="estadística-descriptiva-bivariable.html#supuestos"><i class="fa fa-check"></i><b>10.4.2</b> Supuestos</a></li>
<li class="chapter" data-level="10.4.3" data-path="estadística-descriptiva-bivariable.html"><a href="estadística-descriptiva-bivariable.html#tipos-2"><i class="fa fa-check"></i><b>10.4.3</b> Tipos</a></li>
<li class="chapter" data-level="10.4.4" data-path="estadística-descriptiva-bivariable.html"><a href="estadística-descriptiva-bivariable.html#medidas-de-ajuste-y-error"><i class="fa fa-check"></i><b>10.4.4</b> Medidas de ajuste y error</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="probabilidad.html"><a href="probabilidad.html"><i class="fa fa-check"></i><b>11</b> Probabilidad</a><ul>
<li class="chapter" data-level="11.1" data-path="probabilidad.html"><a href="probabilidad.html#introducción-9"><i class="fa fa-check"></i><b>11.1</b> Introducción</a></li>
<li class="chapter" data-level="11.2" data-path="probabilidad.html"><a href="probabilidad.html#axiomas-y-nomenclatura"><i class="fa fa-check"></i><b>11.2</b> Axiomas y Nomenclatura</a></li>
<li class="chapter" data-level="11.3" data-path="probabilidad.html"><a href="probabilidad.html#reglas-de-probabilidad"><i class="fa fa-check"></i><b>11.3</b> Reglas de probabilidad</a><ul>
<li class="chapter" data-level="11.3.1" data-path="probabilidad.html"><a href="probabilidad.html#regla-de-la-suma"><i class="fa fa-check"></i><b>11.3.1</b> Regla de la suma</a></li>
<li class="chapter" data-level="11.3.2" data-path="probabilidad.html"><a href="probabilidad.html#regla-de-la-multiplicación"><i class="fa fa-check"></i><b>11.3.2</b> Regla de la multiplicación</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="probabilidad.html"><a href="probabilidad.html#variables-aleatorias"><i class="fa fa-check"></i><b>11.4</b> Variables aleatorias</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="distribuciones-de-probabilidad.html"><a href="distribuciones-de-probabilidad.html"><i class="fa fa-check"></i><b>12</b> Distribuciones de Probabilidad</a><ul>
<li class="chapter" data-level="12.1" data-path="distribuciones-de-probabilidad.html"><a href="distribuciones-de-probabilidad.html#introducción-10"><i class="fa fa-check"></i><b>12.1</b> Introducción</a></li>
<li class="chapter" data-level="12.2" data-path="distribuciones-de-probabilidad.html"><a href="distribuciones-de-probabilidad.html#distribución-binomial"><i class="fa fa-check"></i><b>12.2</b> Distribución Binomial</a></li>
<li class="chapter" data-level="12.3" data-path="distribuciones-de-probabilidad.html"><a href="distribuciones-de-probabilidad.html#distribución-de-poisson"><i class="fa fa-check"></i><b>12.3</b> Distribución de Poisson</a></li>
<li class="chapter" data-level="12.4" data-path="distribuciones-de-probabilidad.html"><a href="distribuciones-de-probabilidad.html#distribución-normal-o-gaussiana"><i class="fa fa-check"></i><b>12.4</b> Distribución Normal o Gaussiana</a><ul>
<li class="chapter" data-level="12.4.1" data-path="distribuciones-de-probabilidad.html"><a href="distribuciones-de-probabilidad.html#distribución-normal-estándar-z"><i class="fa fa-check"></i><b>12.4.1</b> Distribución Normal Estándar (Z)</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="distribuciones-de-probabilidad.html"><a href="distribuciones-de-probabilidad.html#distribuciones-de-probabilidad-en-r"><i class="fa fa-check"></i><b>12.5</b> Distribuciones de probabilidad en <strong>R</strong></a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="introducción-a-estadística-inferencial.html"><a href="introducción-a-estadística-inferencial.html"><i class="fa fa-check"></i><b>13</b> Introducción a Estadística Inferencial</a><ul>
<li class="chapter" data-level="13.1" data-path="introducción-a-estadística-inferencial.html"><a href="introducción-a-estadística-inferencial.html#introducción-11"><i class="fa fa-check"></i><b>13.1</b> Introducción</a></li>
<li class="chapter" data-level="13.2" data-path="introducción-a-estadística-inferencial.html"><a href="introducción-a-estadística-inferencial.html#distribuciones-muestrales"><i class="fa fa-check"></i><b>13.2</b> Distribuciones muestrales</a><ul>
<li class="chapter" data-level="13.2.1" data-path="introducción-a-estadística-inferencial.html"><a href="introducción-a-estadística-inferencial.html#infer-x"><i class="fa fa-check"></i><b>13.2.1</b> Media <span class="math inline">\((\bar{x})\)</span></a></li>
<li class="chapter" data-level="13.2.2" data-path="introducción-a-estadística-inferencial.html"><a href="introducción-a-estadística-inferencial.html#infer-x2"><i class="fa fa-check"></i><b>13.2.2</b> Diferencia de medias <span class="math inline">\((\bar{x}_1-\bar{x}_2)\)</span></a></li>
<li class="chapter" data-level="13.2.3" data-path="introducción-a-estadística-inferencial.html"><a href="introducción-a-estadística-inferencial.html#infer-chi"><i class="fa fa-check"></i><b>13.2.3</b> Varianza <span class="math inline">\((s^2)\)</span></a></li>
<li class="chapter" data-level="13.2.4" data-path="introducción-a-estadística-inferencial.html"><a href="introducción-a-estadística-inferencial.html#infer-f"><i class="fa fa-check"></i><b>13.2.4</b> Dos varianzas <span class="math inline">\(\left( \frac{s_1^2}{s_2^2} \right)\)</span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="estimación-e-hipótesis.html"><a href="estimación-e-hipótesis.html"><i class="fa fa-check"></i><b>14</b> Estimación e Hipótesis</a><ul>
<li class="chapter" data-level="14.1" data-path="estimación-e-hipótesis.html"><a href="estimación-e-hipótesis.html#introducción-12"><i class="fa fa-check"></i><b>14.1</b> Introducción</a></li>
<li class="chapter" data-level="14.2" data-path="estimación-e-hipótesis.html"><a href="estimación-e-hipótesis.html#estim"><i class="fa fa-check"></i><b>14.2</b> Estimación</a><ul>
<li class="chapter" data-level="14.2.1" data-path="estimación-e-hipótesis.html"><a href="estimación-e-hipótesis.html#media-1"><i class="fa fa-check"></i><b>14.2.1</b> Media</a></li>
<li class="chapter" data-level="14.2.2" data-path="estimación-e-hipótesis.html"><a href="estimación-e-hipótesis.html#estim-diff-medias"><i class="fa fa-check"></i><b>14.2.2</b> Diferencia de medias</a></li>
<li class="chapter" data-level="14.2.3" data-path="estimación-e-hipótesis.html"><a href="estimación-e-hipótesis.html#estim-ic-chi"><i class="fa fa-check"></i><b>14.2.3</b> Varianza</a></li>
<li class="chapter" data-level="14.2.4" data-path="estimación-e-hipótesis.html"><a href="estimación-e-hipótesis.html#estim-ic-f"><i class="fa fa-check"></i><b>14.2.4</b> Dos varianzas</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="estimación-e-hipótesis.html"><a href="estimación-e-hipótesis.html#hip"><i class="fa fa-check"></i><b>14.3</b> Hipótesis</a><ul>
<li class="chapter" data-level="14.3.1" data-path="estimación-e-hipótesis.html"><a href="estimación-e-hipótesis.html#nula-h_0-y-alterna-h_1"><i class="fa fa-check"></i><b>14.3.1</b> Nula (<span class="math inline">\(H_0\)</span>) y Alterna (<span class="math inline">\(H_1\)</span>)</a></li>
<li class="chapter" data-level="14.3.2" data-path="estimación-e-hipótesis.html"><a href="estimación-e-hipótesis.html#resultados-y-errores"><i class="fa fa-check"></i><b>14.3.2</b> Resultados y Errores</a></li>
<li class="chapter" data-level="14.3.3" data-path="estimación-e-hipótesis.html"><a href="estimación-e-hipótesis.html#estadístico-de-prueba-y-crítico"><i class="fa fa-check"></i><b>14.3.3</b> Estadístico de prueba y crítico</a></li>
<li class="chapter" data-level="14.3.4" data-path="estimación-e-hipótesis.html"><a href="estimación-e-hipótesis.html#contrastes-y-valor-p"><i class="fa fa-check"></i><b>14.3.4</b> Contrastes y valor-<em>p</em></a></li>
<li class="chapter" data-level="14.3.5" data-path="estimación-e-hipótesis.html"><a href="estimación-e-hipótesis.html#decisión"><i class="fa fa-check"></i><b>14.3.5</b> Decisión</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="pruebas-estadísticas.html"><a href="pruebas-estadísticas.html"><i class="fa fa-check"></i><b>15</b> Pruebas Estadísticas</a><ul>
<li class="chapter" data-level="15.1" data-path="pruebas-estadísticas.html"><a href="pruebas-estadísticas.html#introducción-13"><i class="fa fa-check"></i><b>15.1</b> Introducción</a></li>
<li class="chapter" data-level="15.2" data-path="pruebas-estadísticas.html"><a href="pruebas-estadísticas.html#pruebas-param"><i class="fa fa-check"></i><b>15.2</b> Pruebas paramétricas</a><ul>
<li class="chapter" data-level="15.2.1" data-path="pruebas-estadísticas.html"><a href="pruebas-estadísticas.html#supuestos-pasos"><i class="fa fa-check"></i><b>15.2.1</b> Supuestos y Pasos</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="pruebas-estadísticas.html"><a href="pruebas-estadísticas.html#ES-p"><i class="fa fa-check"></i><b>15.3</b> Tamaño del Efecto</a></li>
<li class="chapter" data-level="15.4" data-path="pruebas-estadísticas.html"><a href="pruebas-estadísticas.html#prueba-z1"><i class="fa fa-check"></i><b>15.4</b> <span class="math inline">\(z\)</span> de 1 muestra</a></li>
<li class="chapter" data-level="15.5" data-path="pruebas-estadísticas.html"><a href="pruebas-estadísticas.html#prueba-t1"><i class="fa fa-check"></i><b>15.5</b> <span class="math inline">\(t\)</span> de 1 muestra</a></li>
<li class="chapter" data-level="15.6" data-path="pruebas-estadísticas.html"><a href="pruebas-estadísticas.html#prueba-t2-ind"><i class="fa fa-check"></i><b>15.6</b> <span class="math inline">\(t\)</span> de 2 muestras independientes</a></li>
<li class="chapter" data-level="15.7" data-path="pruebas-estadísticas.html"><a href="pruebas-estadísticas.html#prueba-t2-dep"><i class="fa fa-check"></i><b>15.7</b> <span class="math inline">\(t\)</span> de 2 muestras dependientes</a></li>
<li class="chapter" data-level="15.8" data-path="pruebas-estadísticas.html"><a href="pruebas-estadísticas.html#prueba-aov"><i class="fa fa-check"></i><b>15.8</b> ANOVA de 1-factor entre-grupos</a></li>
<li class="chapter" data-level="15.9" data-path="pruebas-estadísticas.html"><a href="pruebas-estadísticas.html#prueba-t-cor"><i class="fa fa-check"></i><b>15.9</b> <span class="math inline">\(t\)</span> de correlación</a></li>
<li class="chapter" data-level="15.10" data-path="pruebas-estadísticas.html"><a href="pruebas-estadísticas.html#prueba-chi"><i class="fa fa-check"></i><b>15.10</b> <span class="math inline">\(\chi^2\)</span> para 1 varianza</a></li>
<li class="chapter" data-level="15.11" data-path="pruebas-estadísticas.html"><a href="pruebas-estadísticas.html#prueba-f"><i class="fa fa-check"></i><b>15.11</b> <span class="math inline">\(F\)</span> para 2 varianzas</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html"><i class="fa fa-check"></i><b>16</b> Estadística No Paramétrica</a><ul>
<li class="chapter" data-level="16.1" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html#introducción-14"><i class="fa fa-check"></i><b>16.1</b> Introducción</a></li>
<li class="chapter" data-level="16.2" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html#pruebas-noparam"><i class="fa fa-check"></i><b>16.2</b> Pruebas no-paramétricas</a></li>
<li class="chapter" data-level="16.3" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html#ES-np"><i class="fa fa-check"></i><b>16.3</b> Tamaño del efecto</a></li>
<li class="chapter" data-level="16.4" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html#prueba-chi-gof"><i class="fa fa-check"></i><b>16.4</b> Bondad de ajuste</a></li>
<li class="chapter" data-level="16.5" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html#prueba-chi-hom"><i class="fa fa-check"></i><b>16.5</b> Homogeneidad</a></li>
<li class="chapter" data-level="16.6" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html#prueba-chi-asoc"><i class="fa fa-check"></i><b>16.6</b> Independencia / asociación</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="estadística-direccional.html"><a href="estadística-direccional.html"><i class="fa fa-check"></i><b>17</b> Estadística Direccional</a></li>
<li class="chapter" data-level="18" data-path="secuencias-de-datos.html"><a href="secuencias-de-datos.html"><i class="fa fa-check"></i><b>18</b> Secuencias de Datos</a></li>
<li class="chapter" data-level="19" data-path="geoestadística.html"><a href="geoestadística.html"><i class="fa fa-check"></i><b>19</b> Geoestadística</a></li>
<li class="chapter" data-level="" data-path="referencias.html"><a href="referencias.html"><i class="fa fa-check"></i>Referencias</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Creado con bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Geología Numérica: Ciencia de Datos para Geociencias</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="pruebas-estadísticas" class="section level1">
<h1><span class="header-section-number">Capítulo 15</span> Pruebas Estadísticas</h1>
<div id="introducción-13" class="section level2">
<h2><span class="header-section-number">15.1</span> Introducción</h2>
<p>En la sección <a href="estimación-e-hipótesis.html#hip">14.3</a> del capítulo anterior se introdujeron las bases teóricas de lo que son las pruebas de hipótesis, las partes o elementos que la componen, y cómo tomar una decisión una vez llevada a cabo la prueba. Este capítulo se centra en la parte práctica de cómo realizar una prueba estadística paramétrica (los pasos generales). Además se introduce el concepto de tamaño del efecto (effect size - ES - en inglés), y de cómo puede éste agregar información después de realizada la prueba, así como la importancia práctica que representa.</p>
</div>
<div id="pruebas-param" class="section level2">
<h2><span class="header-section-number">15.2</span> Pruebas paramétricas</h2>
<p>De manera general se van a cubrir las pruebas estadísticas homólogas con las estimaciones que se presentaron en el capítulo anterior en la sección <a href="estimación-e-hipótesis.html#estim">Estimación</a> (<a href="estimación-e-hipótesis.html#estim">14.2</a>), donde la práctica en general es usar un contraste bilateral a menos que sea muy justificado un contraste unilateral. Las pruebas se resumen a continuación y serán detalladas más adelante:</p>
<ul>
<li>Prueba <span class="math inline">\(z\)</span> de 1 muestra (<a href="pruebas-estadísticas.html#prueba-z1">15.4</a>)
<ul>
<li><span class="math inline">\(H_0: \mu = \mu_0\)</span></li>
</ul></li>
<li>Prueba <span class="math inline">\(t\)</span> de 1 muestra (<a href="pruebas-estadísticas.html#prueba-t1">15.5</a>)
<ul>
<li><span class="math inline">\(H_0: \mu = \mu_0\)</span></li>
</ul></li>
<li>Prueba <span class="math inline">\(t\)</span> de 2 muestras independientes (<a href="pruebas-estadísticas.html#prueba-t2-ind">15.6</a>)
<ul>
<li><span class="math inline">\(H_0: \mu_1 = \mu_2\)</span></li>
</ul></li>
<li>Prueba <span class="math inline">\(t\)</span> de 2 muestras dependientes (<a href="pruebas-estadísticas.html#prueba-t2-dep">15.7</a>)
<ul>
<li><span class="math inline">\(H_0: \mu_D = 0\)</span></li>
</ul></li>
<li>Prueba <span class="math inline">\(F\)</span> para 2 o más muestras (<a href="pruebas-estadísticas.html#prueba-aov">15.8</a>)
<ul>
<li><span class="math inline">\(H_0: \mu_1 = \mu_2 = \mu_3 = \cdots = \mu_k\)</span></li>
</ul></li>
<li>Prueba <span class="math inline">\(t\)</span> de correlación (<a href="pruebas-estadísticas.html#prueba-t-cor">15.9</a>)
<ul>
<li><span class="math inline">\(H_0: r = 0\)</span></li>
</ul></li>
<li>Prueba <span class="math inline">\(\chi^2\)</span> para 1 varianza (<a href="pruebas-estadísticas.html#prueba-chi">15.10</a>)
<ul>
<li><span class="math inline">\(H_0: \sigma^2 = \sigma^2_0\)</span></li>
</ul></li>
<li>Prueba <span class="math inline">\(F\)</span> para 2 varianzas (<a href="pruebas-estadísticas.html#prueba-f">15.11</a>)
<ul>
<li><span class="math inline">\(H_0: \sigma^2_1 = \sigma^2_2 \to \frac{\sigma^2_1}{\sigma^2_2} = 1\)</span></li>
</ul></li>
</ul>
<div id="supuestos-pasos" class="section level3">
<h3><span class="header-section-number">15.2.1</span> Supuestos y Pasos</h3>
<p>Las pruebas presentadas en este capítulo se conocen como pruebas paramétricas, que a diferencia de las pruebas no-parámetricas que se presentan en el próximo capítulo, hacen supuestos sobre los datos que se van a analizar, siendo el mayor supuesto de que los datos siguen una distribución aproximadamente normal (o se tiene una muestra grande, <span class="math inline">\(n &gt; 30\)</span>), y que las muestras son aleatoreas independientes (excepto en el caso de datos apareados) <span class="citation">(Nolan &amp; Heinzen, <a href="#ref-nolan2014">2014</a>; Triola, <a href="#ref-triola2004">2004</a>)</span>; en algunos casos pueden haber otros supuestos (parámetros conocidos, varianzas iguales, etc.) pero en general éstos son los más importantes.</p>
<p>Para evaluar la “normalidad” de los datos se pueden generar gráficos como el de caja, histogramas, y QQ (Figura <a href="pruebas-estadísticas.html#fig:normalidad">15.1</a>). El gráfico de caja muestra la mediana y los cuartiles, mientras la mediana no se encuentre muy cerca de alguno de los extremos de la caja se puede considerar normalmente distribuida; en caso de haber valores atípicos (extremos) éstos aparecerían como puntos en los extremos. El gráfico QQ hace una comparación de los valores originales con los cuantiles teóricos, la idea es que si los puntos caen cerca de la línea se puede considerar normalmente distribuida; puede que en las colas haya cierta desviación pero eso es normal siempre y cuando no sea muy extrema. El histograma se puede comparar con una curva normal y ver asimetrías, similar al de caja, mientras las asimetría sea nula o mínima se puede considerar normalmente distribuida. Hay pruebas específicas para evaluar la normalidad (Shapiro-Wilk), pero éstas tienden a ser muy sensibles a desviaciones por lo que en general es más recomendado hacer una evaluación visual</p>
<div class="figure" style="text-align: center"><span id="fig:normalidad"></span>
<img src="geolonum_files/figure-html/normalidad-1.png" alt="Gráficos que se pueden usar para evaluar si los datos siguen una distribución aproximandamente normal. **A** Gráfico de caja. **B** Gráfico QQ. **C** Histograma." width="90%" />
<p class="caption">
Figura 15.1: Gráficos que se pueden usar para evaluar si los datos siguen una distribución aproximandamente normal. <strong>A</strong> Gráfico de caja. <strong>B</strong> Gráfico QQ. <strong>C</strong> Histograma.
</p>
</div>
<p><span class="citation">Nolan &amp; Heinzen (<a href="#ref-nolan2014">2014</a>)</span> establecen una serie de pasos que se pueden aplicar de manera general a las pruebas estadísticas:</p>
<ol style="list-style-type: decimal">
<li>Identificar la población, distribución, y la prueba apropiada:
<ul>
<li>En función del parámetro de interés (<span class="math inline">\(\mu, \sigma^2\)</span>)</li>
</ul></li>
<li>Establecer las hipótesis nula y alterna:
<ul>
<li>En función de la prueba escogida en el punto anterior (<span class="math inline">\(z,t,\chi^2,F\)</span>)</li>
</ul></li>
<li>Determinar parámetros de la distribución a comparar (<span class="math inline">\(H_0\)</span>):
<ul>
<li>En función del parámetro de interés y datos disponibles</li>
</ul></li>
<li>Determinar valores críticos
<ul>
<li>En función de la distribución y el nivel de significancia (<span class="math inline">\(\alpha\)</span>)</li>
</ul></li>
<li>Calcular el estadístico de prueba
<ul>
<li>En función de la prueba escogida y datos disponibles</li>
<li>Aquí se puede agregar calcular los intervalos de confianza respectivos</li>
</ul></li>
<li>Tomar una decisión
<ul>
<li>En función de valores críticos y estadístico de prueba, valor-<em>p</em>, o intervalos de confianza</li>
</ul></li>
</ol>
<p>Si se rechaza <span class="math inline">\(H_0\)</span> se dice que hay un resultado <strong><em>estadísticamente significativo</em></strong>. Esta aseveración se refiere a que hay poca probabilidad de que los datos observados provengan de una población representada por <span class="math inline">\(H_0\)</span>. El hecho de que se rechace <span class="math inline">\(H_0\)</span> y se obtenga un resultado <strong><em>estadísticamente significativo</em></strong> no quiere decir que éste sea importante desde el punto de vista práctico <span class="citation">(Nolan &amp; Heinzen, <a href="#ref-nolan2014">2014</a>)</span>. Esto último es lo que va a indicar el tamaño del efecto.</p>
</div>
</div>
<div id="ES-p" class="section level2">
<h2><span class="header-section-number">15.3</span> Tamaño del Efecto</h2>
<p>Cuando una prueba da un resultado estadísticamente significativo, quiere decir que se determinó que hay una diferencia o relación. Como se mencionó en el capítulo anterior, este resultado se va a ver afectado directamente por el tamaño de la muestra, por lo que en el caso de muestras grandes casí siempre se va a encontrar un resultado estadísticamente significativo, aun cuando la diferencia o relación real sea pequeña. El tamaño del efecto (ES) es lo que indica la magnitud real de esa diferencia o relación, no se ve afectada por el tamaño de la muestra, e indica la importancia práctica de un efecto, y debe ser el objetivo a la hora de realizar análisis estadísticos <span class="citation">(Cohen, <a href="#ref-cohen1988">1988</a>; Cumming, <a href="#ref-cumming2012">2012</a>; Cumming &amp; Calin-Jageman, <a href="#ref-cumming2017">2017</a>; Nolan &amp; Heinzen, <a href="#ref-nolan2014">2014</a>)</span>.</p>
<p>El tamaño del efecto puede presentarse en las unidades originales o de forma estandarizada (más usadas) y se reconocen dos familias: diferencia entre medias (familia <span class="math inline">\(d\)</span> y sus variantes), asociación/relación entre variables (familia <span class="math inline">\(r\)</span> y similares como <span class="math inline">\(R^2, \eta^2, V\)</span>), y dentro de lo posible es recomendable incluir intervalos de confianza <span class="citation">(Cohen, <a href="#ref-cohen1988">1988</a>; Cumming, <a href="#ref-cumming2012">2012</a>; Cumming &amp; Calin-Jageman, <a href="#ref-cumming2017">2017</a>; Lakens, <a href="#ref-lakens2013fp">2013</a>; Nakagawa &amp; Cuthill, <a href="#ref-nakagawa2007br">2007</a>)</span>. Para los tamaños de efecto es complicado calcular de forma manual los intervalos de confianza, en la mayoría de los casos se usa la distribución <span class="math inline">\(t\)</span> no-central, por lo que se recomienda utilizar métodos computacionales <span class="citation">(Cumming, <a href="#ref-cumming2012">2012</a>; Cumming &amp; Calin-Jageman, <a href="#ref-cumming2017">2017</a>)</span>.</p>
<p>A parte de presentar los resultados de pruebas estadísticas, sea que se rechace o no la hipótesis nula, es necesario incluir el tamaño del efecto para brindar una mejor idea del resultado encontrado, así como para posibles usos en futuros estudios (meta-analisis, cálculos de tamaños de muestra, potencia, etc.), y generar una base de resultados resportados en un área específica del saber para determinar qué se puede considerar como un efecto pequeño, mediano o grande <span class="citation">(American Psycological Association [APA] <a href="#ref-americanpsychologicalassociation2010">2010</a>; Cumming, <a href="#ref-cumming2012">2012</a>; Cumming &amp; Calin-Jageman, <a href="#ref-cumming2017">2017</a>; Nakagawa &amp; Cuthill, <a href="#ref-nakagawa2007br">2007</a>; Thompson, <a href="#ref-thompson2007ps">2007</a>; Tomczak &amp; Tomczak, <a href="#ref-tomczak2014tss">2014</a>)</span>.</p>
<p>La diferencia entre medias estandarizada se conoce como Cohen <span class="math inline">\(d\)</span> <span class="citation">(Cohen, <a href="#ref-cohen1988">1988</a>)</span>, de manera general se presenta en la Ecuación <a href="pruebas-estadísticas.html#eq:cohen-d-pop">(15.1)</a>, y se puede visualizar en la Figura <a href="pruebas-estadísticas.html#fig:cohen-d">15.2</a>. Se interpreta de manera similar a <span class="math inline">\(Z\)</span>, donde la diferencia entre medias está dada en función de una desviación estándar. La desviación estándar (denominador) es la que va a cambiar dependiendo de la prueba y condiciones de la misma (Tabla <a href="pruebas-estadísticas.html#tab:ES-p">15.1</a>).</p>
<p><span class="math display" id="eq:cohen-d-pop">\[\begin{equation}
  d = \frac{\bar{x}_1-\bar{x}_2}{\sigma}
  \tag{15.1}
\end{equation}\]</span></p>
<div class="figure" style="text-align: center"><span id="fig:cohen-d"></span>
<img src="geolonum_files/figure-html/cohen-d-1.png" alt="Representación del Cohen $d$." width="70%" />
<p class="caption">
Figura 15.2: Representación del Cohen <span class="math inline">\(d\)</span>.
</p>
</div>
<p>Hay dos factores que controlan el tamaño de <span class="math inline">\(d\)</span>, primero al incrementar la diferencia entre medias (manteniendo la dispersión constante) mayor será <span class="math inline">\(d\)</span>, segundo al disminuir la dispersión (manteniendo la diferencia de medias constante) mayor será <span class="math inline">\(d\)</span>. Estos dos factores van a influenciar el traslape entre las curvas, donde a mayor <span class="math inline">\(d\)</span> menor el traslape y mayor la diferencia entre las curvas y las muestras. Al igual que <span class="math inline">\(Z\)</span> puede tomar valores de <span class="math inline">\(-∞\)</span> a <span class="math inline">\(∞\)</span>.</p>
<p>Dada la naturaleza estadística del Cohen <span class="math inline">\(d\)</span> y la dificultad de su interpretación para personas con poco conocimiento estadístico, se han generado otras métricas comparables que pueden ser más fáciles de entender en términos generales. <span class="citation">Grissom &amp; Kim (<a href="#ref-grissom2005">2005</a>)</span>, <span class="citation">McGraw &amp; Wong (<a href="#ref-mcgraw1992pb">1992</a>)</span>, y <span class="citation">Ruscio (<a href="#ref-ruscio2008pm">2008</a>)</span> desarrollaron el concepto de probabilidad de superioridad (PS) o lenguage común del tamaño del efecto (CL) el cuál se puede calcular de acuerdo a la Ecuación <a href="pruebas-estadísticas.html#eq:PS">(15.2)</a>. Este concepto se interpreta como la probabilidad de que un elemento del grupo con media superior (elegido al azar) tenga un valor superior al de un elemento del grupo con media inferior, y al ser una probabilidad se encuentra entre 0 y 100%, conforme mayor sea <span class="math inline">\(d\)</span> mayor será PS. <span class="citation">Reiser &amp; Faraggi (<a href="#ref-reiser1999jrss">1999</a>)</span> modificaron de <span class="citation">Cohen (<a href="#ref-cohen1988">1988</a>)</span> el traslape (OVL) entre las curvas (grupos), dado por la Ecuación <a href="pruebas-estadísticas.html#eq:traslape">(15.3)</a>, donde a mayor <span class="math inline">\(d\)</span> menor el traslape y más diferenciados los grupos. <span class="citation">Cohen (<a href="#ref-cohen1988">1988</a>)</span> definió el concepto de <span class="math inline">\(U_3\)</span>, denominado la medida de no-traslape, presentado en Ecuación <a href="pruebas-estadísticas.html#eq:U3">(15.4)</a>, y se puede interpretar como el porcentaje del grupo con media superior que va a estar por encima de la media del grupo con media inferior. Para todos estos casos <span class="math inline">\(\Phi\)</span> corresponde con la función de densidad acumulada de la distribución normal estándar <span class="math inline">\(Z\)</span>. <em>Cabe resaltar que éstos conceptos y cálculos se basan en grupos de mismo tamaño y misma desviación estándar</em>.Un muy buen recurso para visualizar todos estos conceptos lo brinda <span class="citation">Magnusson (<a href="#ref-magnusson2020">2020</a>)</span> en <a href="https://rpsychologist.com/d3/cohend/">Interpreting Cohen’s d</a>.</p>
<p><span class="math display" id="eq:PS">\[\begin{equation}
  PS = CL = \Phi \left( \frac{|d|}{\sqrt{2}} \right)
  \tag{15.2}
\end{equation}\]</span></p>
<p><span class="math display" id="eq:traslape">\[\begin{equation}
  OVL = 2 \Phi \left( \frac{-|d|}{2} \right)
  \tag{15.3}
\end{equation}\]</span></p>
<p><span class="math display" id="eq:U3">\[\begin{equation}
  U_3 = \Phi \left( |d| \right)
  \tag{15.4}
\end{equation}\]</span></p>
<p>Aquí se presenta cómo calcular estos conceptos en <strong>R</strong>, donde el único dato necesario es el <span class="math inline">\(d\)</span>.</p>
<pre class="sourceCode r"><code class="sourceCode r">d =<span class="st"> </span><span class="dv">2</span>
<span class="kw">pnorm</span>(<span class="kw">abs</span>(d)<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">2</span>))<span class="op">*</span><span class="dv">100</span> <span class="co"># PS, CL</span></code></pre>
<pre><code>## [1] 92.13504</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="dv">2</span><span class="op">*</span><span class="kw">pnorm</span>(<span class="op">-</span><span class="kw">abs</span>(d)<span class="op">/</span><span class="dv">2</span>)<span class="op">*</span><span class="dv">100</span> <span class="co"># traslape</span></code></pre>
<pre><code>## [1] 31.73105</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pnorm</span>(<span class="kw">abs</span>(d))<span class="op">*</span><span class="dv">100</span> <span class="co"># U3</span></code></pre>
<pre><code>## [1] 97.72499</code></pre>
<p>Muchos autores han trabajado en este tema, proponiendo mejoras a los tamaños de efecto inicialmente planteados y resumiendo los diferentes tamaños de efecto para las diferentes pruebas y condiciones <span class="citation">(Cohen, <a href="#ref-cohen1988">1988</a>; Cumming, <a href="#ref-cumming2012">2012</a>; Cumming &amp; Calin-Jageman, <a href="#ref-cumming2017">2017</a>; Ellis, <a href="#ref-ellis2010">2010</a>; Fritz et al., <a href="#ref-fritz2012joepg">2012</a>; Grissom &amp; Kim, <a href="#ref-grissom2005">2005</a>; Hedges &amp; Olkin, <a href="#ref-hedges1985">1985</a>; Lakens, <a href="#ref-lakens2013fp">2013</a>; McGrath &amp; Meyer, <a href="#ref-mcgrath2006pm">2006</a>; McGraw &amp; Wong, <a href="#ref-mcgraw1992pb">1992</a>; Nakagawa &amp; Cuthill, <a href="#ref-nakagawa2007br">2007</a>; Thompson, <a href="#ref-thompson2007ps">2007</a>; Tomczak &amp; Tomczak, <a href="#ref-tomczak2014tss">2014</a>; Zou, <a href="#ref-zou2007pm">2007</a>)</span>. Aquí se presenta un resumen de los diferentes tamaños de efecto (Tabla <a href="pruebas-estadísticas.html#tab:ES-p">15.1</a>) y se remite al lector a revisar las referencias aquí mencionadas y las que se incluyen en las mismas, en el caso de querer ahondar en alguno de los casos presentados.</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:ES-p">Tabla 15.1: </span>Tamaños de efecto estandarizados para pruebas paramétricas
</caption>
<thead>
<tr>
<th style="text-align:center;">
Prueba
</th>
<th style="text-align:center;">
Tamaño de efecto
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;width: 15em; ">
Z de 1 muestra
</td>
<td style="text-align:center;width: 25em; ">
<span class="math display" id="eq:d-pop">\[\begin{equation}
              d_{pop} = \frac{\bar{x}-\mu_0}{\sigma}
              \tag{15.5}
              \end{equation}\]</span>
</td>
</tr>
<tr>
<td style="text-align:center;width: 15em; ">
t de 1 muestra
</td>
<td style="text-align:center;width: 25em; ">
<span class="math display" id="eq:d-t1">\[\begin{equation}
              d_s = \frac{\bar{x}-\mu_0}{s}
              \tag{15.6}
              \end{equation}\]</span>
</td>
</tr>
<tr>
<td style="text-align:center;width: 15em; ">
t de 2 muestras independientes
</td>
<td style="text-align:center;width: 25em; ">
<span class="math display" id="eq:d-t2-d">\[\begin{equation}
              d_s = \frac{\bar{x}_1-\bar{x}_2}{\sqrt{\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 - 2}}}
              \tag{15.7}
              \end{equation}\]</span>
</td>
</tr>
<tr>
<td style="text-align:center;width: 15em; ">
t de 2 muestras dependientes usando la desviación de las diferencias
</td>
<td style="text-align:center;width: 25em; ">
<span class="math display" id="eq:d-t2-dep1">\[\begin{equation}
              d_z = \frac{\bar{x}_d}{s_d}
              \tag{15.8}
              \end{equation}\]</span>
</td>
</tr>
<tr>
<td style="text-align:center;width: 15em; ">
t de 2 muestras dependientes tomando en cuenta la correlación
</td>
<td style="text-align:center;width: 25em; ">
<span class="math display" id="eq:d-t2-dep2">\[\begin{equation}
              d_{rm} = \frac{\bar{x}_d}{\sqrt{s_1^2 + s_2^2 - 2 \cdot r \cdot s_1 \cdot s_2}}\sqrt{2(1-r)}
              \tag{15.9}
              \end{equation}\]</span>
</td>
</tr>
<tr>
<td style="text-align:center;width: 15em; ">
t de 2 muestras dependientes usando el promedio de las desviaciones
</td>
<td style="text-align:center;width: 25em; ">
<span class="math display" id="eq:d-t2-dep3">\[\begin{equation}
              d_{av} = \frac{\bar{x}_d}{\sqrt{\frac{s_1^2 + s_2^2}{2}}}
              \tag{15.10}
              \end{equation}\]</span>
</td>
</tr>
<tr>
<td style="text-align:center;width: 15em; ">
t con correción de Hedges
</td>
<td style="text-align:center;width: 25em; ">
<span class="math display" id="eq:d-g">\[\begin{equation}
              g = d \cdot \left( 1 - \frac{3}{4v-1} \right)
              \tag{15.11}
              \end{equation}\]</span>
</td>
</tr>
<tr>
<td style="text-align:center;width: 15em; ">
Correlación punto biserial a partir de <span class="math inline">\(d_s\)</span> para 2 muestras independientes
</td>
<td style="text-align:center;width: 25em; ">
<span class="math display" id="eq:r-pb">\[\begin{equation}
              r_{pb} = \frac{d_s}{\sqrt{d_s^2 + \frac{(n_1 + n_2)^2}{n_1  n_2}}}
              \tag{15.12}
              \end{equation}\]</span>
</td>
</tr>
<tr>
<td style="text-align:center;width: 15em; ">
Correlación
</td>
<td style="text-align:center;width: 25em; ">
<span class="math display" id="eq:r">\[\begin{equation}
              r
              \tag{15.13}
              \end{equation}\]</span>
</td>
</tr>
<tr>
<td style="text-align:center;width: 15em; ">
Regresión
</td>
<td style="text-align:center;width: 25em; ">
<span class="math display" id="eq:r2">\[\begin{equation}
              R^2
              \tag{15.14}
              \end{equation}\]</span>
</td>
</tr>
<tr>
<td style="text-align:center;width: 15em; ">
ANOVA
</td>
<td style="text-align:center;width: 25em; ">
<span class="math display" id="eq:eta2-1">\[\begin{equation}
              \eta^2 = \frac{SC_{efecto}}{SC_{total}}
              \tag{15.15}
              \end{equation}\]</span>
</td>
</tr>
<tr>
<td style="text-align:center;width: 15em; ">
ANOVA
</td>
<td style="text-align:center;width: 25em; ">
<span class="math display" id="eq:eta2-2">\[\begin{equation}
              \eta_p^2 = \frac{SC_{efecto}}{SC_{efecto}+SC_{error}}
              \tag{15.16}
              \end{equation}\]</span>
</td>
</tr>
</tbody>
<tfoot>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<span style="font-style: italic;">Notas:</span>
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(\mu_0\)</span> = media poblacional
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(\sigma\)</span> = desviación estándar poblacional
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(\bar{x}_k\)</span> = media muestral de <span class="math inline">\(k\)</span>
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(s_k\)</span> = desviación estándar muestral de <span class="math inline">\(k\)</span>
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(s_k^2\)</span> = varianza muestral de <span class="math inline">\(k\)</span>
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(n_k\)</span> = tamaño de muestra de <span class="math inline">\(k\)</span>
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(v\)</span> = grados de libertad
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(\bar{x}_d\)</span> = media de la diferencia entre muestras
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(s_d\)</span> = desviación estándar de la diferencia entre muestras
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(r\)</span> = coeficiente de correlación de Pearson
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(r_{pb}\)</span> = coeficiente de correlación punto biserial
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(SC\)</span> = suma de cuadrados en ANOVA
</td>
</tr>
</tfoot>
</table>
<p>La Tabla <a href="pruebas-estadísticas.html#tab:ES-p">15.1</a> presenta ambas familias de tamaños de efecto, donde <span class="math inline">\(r\)</span> y <span class="math inline">\(R^2\)</span> se interpretan como en las secciones <a href="estadística-descriptiva-bivariable.html#bivar-cor">10.3</a> y <a href="estadística-descriptiva-bivariable.html#bivar-reg-r2">10.4.4.2</a>, respectivamente. <span class="math inline">\(\eta^2\)</span> se interpreta igual a <span class="math inline">\(R^2\)</span>, como el porcentaje de variación en la variable respuesta explicado por la variable predictora <span class="citation">(Cohen, <a href="#ref-cohen1988">1988</a>; Lakens, <a href="#ref-lakens2013fp">2013</a>; Tomczak &amp; Tomczak, <a href="#ref-tomczak2014tss">2014</a>)</span>.</p>
<p>Una pregunta que puede surgir es qué magnitud de los diferentes tamaños de efecto se puede considerar pequeña, mediana, o grande. <span class="citation">Cohen (<a href="#ref-cohen1988">1988</a>)</span> sugirió unos valores que se pueden usar como guías (Tabla <a href="pruebas-estadísticas.html#tab:ES-p-clas">15.2</a>), los cuales han surgido y fueron determinados como tales en las ciencias sociales. El mismo autor advierte sobre utilizar estos valores como definitivos y estrictos, y menciona que se debe aplicar criterio de experto en el área específica para determinar que califica como pequeño, mediano, o grande.</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:ES-p-clas">Tabla 15.2: </span>Clases comunmente usadas para diferentes tamaños de efecto
</caption>
<thead>
<tr>
<th style="border-bottom:hidden" colspan="2">
</th>
<th style="border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="3">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Clases del tamaño del efecto
</div>
</th>
</tr>
<tr>
<th style="text-align:center;">
Prueba
</th>
<th style="text-align:center;">
Tamaño de efecto
</th>
<th style="text-align:center;">
Pequeño
</th>
<th style="text-align:center;">
Mediano
</th>
<th style="text-align:center;">
Grande
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
Comparación de medias
</td>
<td style="text-align:center;">
<span class="math inline">\(d\)</span>, <span class="math inline">\(g\)</span>
</td>
<td style="text-align:center;">
0.20
</td>
<td style="text-align:center;">
0.50
</td>
<td style="text-align:center;">
0.80
</td>
</tr>
<tr>
<td style="text-align:center;vertical-align: top !important;" rowspan="3">
Correlación
</td>
<td style="text-align:center;">
<span class="math inline">\(r\)</span>
</td>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
0.30
</td>
<td style="text-align:center;">
0.50
</td>
</tr>
<tr>
<td style="text-align:center;">
<span class="math inline">\(R^2\)</span>
</td>
<td style="text-align:center;">
0.01
</td>
<td style="text-align:center;">
0.09
</td>
<td style="text-align:center;">
0.25
</td>
</tr>
<tr>
<td style="text-align:center;">
<span class="math inline">\(r_{pb}\)</span>
</td>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
0.24
</td>
<td style="text-align:center;">
0.37
</td>
</tr>
<tr>
<td style="text-align:center;">
Regresión
</td>
<td style="text-align:center;">
<span class="math inline">\(R^2\)</span>
</td>
<td style="text-align:center;">
0.02
</td>
<td style="text-align:center;">
0.13
</td>
<td style="text-align:center;">
0.26
</td>
</tr>
<tr>
<td style="text-align:center;">
ANOVA
</td>
<td style="text-align:center;">
<span class="math inline">\(\eta^2\)</span>
</td>
<td style="text-align:center;">
0.01
</td>
<td style="text-align:center;">
0.06
</td>
<td style="text-align:center;">
0.14
</td>
</tr>
</tbody>
<tfoot>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<span style="font-style: italic;">Nota:</span> <sup></sup> Conforme <span class="citation">Cohen (<a href="#ref-cohen1988">1988</a>)</span>
</td>
</tr>
</tfoot>
</table>
</div>
<div id="prueba-z1" class="section level2">
<h2><span class="header-section-number">15.4</span> <span class="math inline">\(z\)</span> de 1 muestra</h2>
<p>El uso de la prueba <span class="math inline">\(z\)</span> de 1 muestra se realiza con el ejemplo de la sección <a href="estimación-e-hipótesis.html#estim-ic-z">14.2.1.1</a> <span class="citation">(Walpole et al., <a href="#ref-walpole2012">2012</a>)</span>, donde se tenía una media muestral de <span class="math inline">\(2.6 \ g/ml\)</span> para una muestra de tamaño 36 y se asumía una deviación poblacional de <span class="math inline">\(0.3 \ g/ml\)</span>. Es posible que esta muestra provenga de una población con media 2.8 (<span class="math inline">\(\mu_0=2.8\)</span>)? Asuma <span class="math inline">\(\alpha = 0.05\)</span>.</p>
<p>Usando los pasos mencionados anteriormente (<a href="pruebas-estadísticas.html#supuestos-pasos">15.2.1</a>) se tiene:</p>
<ol style="list-style-type: decimal">
<li>Identificar la población, distribución, y la prueba apropiada:
<ul>
<li>Población: concentración de zinc en un río</li>
<li>Distribución: de medias</li>
<li>Prueba: <span class="math inline">\(Z\)</span> de 1 muestra porque se tiene 1 muestra, se quiere comparar con un valor hipotético, y se tiene <span class="math inline">\(\sigma\)</span></li>
</ul></li>
<li>Establecer las hipótesis nula y alterna:
<ul>
<li><span class="math inline">\(H_0: \mu = \mu_0 \to\)</span> La concentración de zinc en el río es <em>igual</em> a un valor hipotético o conocido (2.8)</li>
<li><span class="math inline">\(H_1: \mu \neq \mu_0 \to\)</span> La concentración de zinc en el río es <em>diferente</em> a un valor hipotético o conocido (2.8)</li>
</ul></li>
<li>Determinar parámetros de la distribución a comparar (<span class="math inline">\(H_0\)</span>):
<ul>
<li><span class="math inline">\(\mu_0 = 2.8\)</span></li>
<li><span class="math inline">\(\sigma_\bar{x} = \frac{\sigma}{\sqrt{n}} = \frac{0.3}{\sqrt{36}} = 0.05\)</span></li>
</ul></li>
<li>Determinar valores críticos
<ul>
<li><span class="math inline">\(\alpha = 0.05\)</span></li>
<li><span class="math inline">\(z_{\alpha/2} = z_{0.05/2} = |1.96|\)</span></li>
</ul></li>
<li>Calcular el estadístico de prueba
<ul>
<li><span class="math inline">\(Z = \frac{\bar{x} - \mu}{\sigma_\bar{x}} = \frac{2.6 - 2.8}{0.05} = -4\)</span></li>
<li><span class="math inline">\(2.6 \pm 0.1 \to 95\% \ IC \ [2.50,2.70]\)</span></li>
</ul></li>
<li>Tomar una decisión
<ul>
<li>El estadístico de prueba es mayor al crítico, <span class="math inline">\(z &gt; z_{\alpha/2}\)</span></li>
<li>El valor-<em>p</em> es menor a <span class="math inline">\(\alpha = 0.05\)</span>, <span class="math inline">\(p &lt; .001\)</span></li>
<li>El valor hipotético del parámetro cae fuera del intervalo de confianza, <span class="math inline">\(IC \ [2.50,2.70]\)</span></li>
<li><em>Decisión</em>: Se rechaza <span class="math inline">\(H_0\)</span></li>
</ul></li>
</ol>
<p>En <strong>R</strong> el paquete <em>DescTools</em> tiene la función <code>ZTest</code> para realizar esta prueba, pero necesita un vector de datos, por lo que se genera un vector aleatorio, y se demuestra a continuación.</p>
<pre class="sourceCode r"><code class="sourceCode r">x =<span class="st"> </span><span class="fl">2.6</span>
n =<span class="st"> </span><span class="dv">36</span>
sig =<span class="st"> </span><span class="fl">0.3</span>
mu0 =<span class="st"> </span><span class="fl">2.8</span>
a =<span class="st"> </span><span class="fl">0.05</span>

<span class="kw">set.seed</span>(<span class="dv">123</span>)
vec =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n =</span> n, <span class="dt">mean =</span> x, <span class="dt">sd =</span> sig)

z1.res =<span class="st"> </span><span class="kw">ZTest</span>(vec, 
               <span class="dt">mu =</span> mu0, <span class="co"># valor del parámetro a comparar</span>
               <span class="dt">sd_pop =</span> sig, <span class="co"># deviación poblacional</span>
               <span class="dt">conf.level =</span> <span class="dv">1</span><span class="op">-</span>a) <span class="co"># nivel de confianza</span>
z1.res</code></pre>
<pre><code>## 
##  One Sample z-test
## 
## data:  vec
## z = -3.6664, Std. Dev. Population = 0.3, p-value = 0.000246
## alternative hypothesis: true mean is not equal to 2.8
## 95 percent confidence interval:
##  2.518683 2.714680
## sample estimates:
## mean of x 
##  2.616681</code></pre>
<p>El tamaño del efecto se puede calcular de acuerdo a la Ecuación <a href="pruebas-estadísticas.html#eq:d-pop">(15.5)</a> de la siguiente manera:</p>
<p><span class="math display">\[\begin{equation}
  d_{pop} = \frac{\bar{x}-\mu_0}{\sigma}\\
  d_{pop} = \frac{2.6-2.8}{0.3} = -0.67
\end{equation}\]</span></p>
<p>En <strong>R</strong> se puede calcular de forma básica y el intervalo de confianza con la función <code>d.ci</code> del paquete <em>psych</em> <span class="citation">(Revelle, <a href="#ref-R-psych">2020</a>)</span>, donde es necesario indicar <span class="math inline">\(d\)</span> y <span class="math inline">\(n\)</span>.</p>
<pre class="sourceCode r"><code class="sourceCode r">dpop =<span class="st"> </span>(x <span class="op">-</span><span class="st"> </span>mu0) <span class="op">/</span><span class="st"> </span>sig

dpop.ci =<span class="st"> </span><span class="kw">d.ci</span>(dpop,<span class="dt">n1=</span>n) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(<span class="dv">2</span>)
dpop.ci</code></pre>
<pre><code>##      lower effect upper
## [1,] -1.02  -0.67  -0.3</code></pre>
<p>Usando las medidas PS, OVL, y <span class="math inline">\(U_3\)</span> (Figura <a href="pruebas-estadísticas.html#fig:z1-u3">15.3</a>).</p>
<pre><code>## # A tibble: 1 x 3
##      PS   OVL    U3
##   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1  68.1  73.9  74.8</code></pre>
<div class="figure" style="text-align: center"><span id="fig:z1-u3"></span>
<img src="geolonum_files/figure-html/z1-u3-1.png" alt="$U_3$ para el ejemplo de la prueba $z$ de 1 muestra. **A** Corresponde con los datos en escala original. **B** Corresponde con el tamaño del efecto $d$." width="70%" />
<p class="caption">
Figura 15.3: <span class="math inline">\(U_3\)</span> para el ejemplo de la prueba <span class="math inline">\(z\)</span> de 1 muestra. <strong>A</strong> Corresponde con los datos en escala original. <strong>B</strong> Corresponde con el tamaño del efecto <span class="math inline">\(d\)</span>.
</p>
</div>
<blockquote>
<p>Conclusión: La concentración de zinc (<span class="math inline">\(M = 2.62\)</span>, 95% IC <span class="math inline">\([2.52\)</span>, <span class="math inline">\(2.71]\)</span>) es signficativamente diferente a la media de 2.8 g/ml, <span class="math inline">\(z(36) = -3.67\)</span>, <span class="math inline">\(p &lt; .001\)</span>, <span class="math inline">\(d = -0.67 \ [-1.02, -0.3]\)</span>. El efecto se puede considerar mediano, pero con un rango de pequeño hasta muy grande. Hay una probabilidad de 68.1% (PS) que un elemento de la población hipotética tenga una concentración mayor a un elemento de la muestra; las dos curvas se traslapan en un 73.9% (OVL); el 74.8% (<span class="math inline">\(U_3\)</span>) de la población hipotética se encuentra por encima de la media de la muestra.</p>
</blockquote>
</div>
<div id="prueba-t1" class="section level2">
<h2><span class="header-section-number">15.5</span> <span class="math inline">\(t\)</span> de 1 muestra</h2>
<p>El uso de la prueba <span class="math inline">\(t\)</span> de 1 muestra se realiza con el ejemplo de la sección <a href="estimación-e-hipótesis.html#estim-ic-t">14.2.1.2</a> <span class="citation">(Swan &amp; Sandilands, <a href="#ref-swan1995">1995</a>)</span>, donde se tenía el contenido de cuarzo en secciones delgadas de una roca ígnea. Es posible que esta muestra provenga de una población con media 20% (<span class="math inline">\(\mu_0=20\)</span>)? Asuma <span class="math inline">\(\alpha = 0.05\)</span>.</p>
<ol style="list-style-type: decimal">
<li>Identificar la población, distribución, y la prueba apropiada:
<ul>
<li>Población: contenido de cuarzo en la roca ígnea</li>
<li>Distribución: de medias</li>
<li>Prueba: <span class="math inline">\(t\)</span> de 1 muestra porque se tiene 1 muestra, se quiere comparar con un valor hipotético, y no se tiene <span class="math inline">\(\sigma\)</span></li>
</ul></li>
<li>Establecer las hipótesis nula y alterna:
<ul>
<li><span class="math inline">\(H_0: \mu = \mu_0 \to\)</span> El contenido de cuarzo en la roca ígnea es <em>igual</em> a un valor hipotético o conocido (20)</li>
<li><span class="math inline">\(H_1: \mu \neq \mu_0 \to\)</span> El contenido de cuarzo en la roca ígnea es <em>diferente</em> a un valor hipotético o conocido (20)</li>
</ul></li>
<li>Determinar parámetros de la distribución a comparar (<span class="math inline">\(H_0\)</span>):
<ul>
<li><span class="math inline">\(\mu_0 = 20\)</span></li>
<li><span class="math inline">\(s_\bar{x} = \frac{s}{\sqrt{n}} = \frac{3.083}{\sqrt{8}} = 1.09\)</span></li>
</ul></li>
<li>Determinar valores críticos
<ul>
<li><span class="math inline">\(\alpha = 0.05\)</span></li>
<li><span class="math inline">\(t_{\alpha/2,v} = t_{0.05/2,7} = |2.365|\)</span></li>
</ul></li>
<li>Calcular el estadístico de prueba
<ul>
<li><span class="math inline">\(t = \frac{\bar{x} - \mu}{s_\bar{x}} = \frac{21.5 - 20}{1.09} = 1.37\)</span></li>
<li><span class="math inline">\(21.512 \pm 2.578 \to 95\% \ IC \ [18.93, 24.09]\)</span></li>
</ul></li>
<li>Tomar una decisión
<ul>
<li>El estadístico de prueba es menor al crítico, <span class="math inline">\(t &lt; t_{\alpha/2,v}\)</span></li>
<li>El valor-<em>p</em> es mayor a <span class="math inline">\(\alpha = 0.05\)</span>, <span class="math inline">\(p = 0.2079\)</span></li>
<li>El valor hipotético del parámetro cae dentro del intervalo de confianza, <span class="math inline">\(IC \ [18.93, 24.09]\)</span></li>
<li><em>Decisión</em>: No se rechaza <span class="math inline">\(H_0\)</span></li>
</ul></li>
</ol>
<p><strong>R</strong> trae la función <code>t.test</code> que puede realizar las diferentes pruebas <span class="math inline">\(t\)</span>. Para el caso de 1 muestra se brinda el vector de datos, la media poblacional con la cual comparar (<code>mu</code>), y el nivel de confianza.</p>
<pre class="sourceCode r"><code class="sourceCode r">mu0 =<span class="st"> </span><span class="dv">20</span>
a =<span class="st"> </span><span class="fl">0.05</span>

cuarzo =<span class="st"> </span><span class="kw">c</span>(<span class="fl">23.5</span>, <span class="fl">16.6</span>, <span class="fl">25.4</span>, <span class="fl">19.1</span>, <span class="fl">19.3</span>, <span class="fl">22.4</span>, <span class="fl">20.9</span>, <span class="fl">24.9</span>)

t1.res =<span class="st"> </span><span class="kw">t.test</span>(cuarzo, 
                <span class="dt">mu =</span> mu0, 
                <span class="dt">conf.level =</span> <span class="dv">1</span><span class="op">-</span>a)
t1.res</code></pre>
<pre><code>## 
##  One Sample t-test
## 
## data:  cuarzo
## t = 1.3875, df = 7, p-value = 0.2079
## alternative hypothesis: true mean is not equal to 20
## 95 percent confidence interval:
##  18.93477 24.09023
## sample estimates:
## mean of x 
##   21.5125</code></pre>
<p>El tamaño del efecto se puede calcular de acuerdo a la Ecuación <a href="pruebas-estadísticas.html#eq:d-t1">(15.6)</a> de la siguiente manera:</p>
<p><span class="math display">\[\begin{equation}
  d_s = \frac{\bar{x}-\mu_0}{s}\\
  d_s = \frac{21.5-20}{3.083} = 0.49
\end{equation}\]</span></p>
<p>En <strong>R</strong> se puede calcular con la función <code>d.single.t</code> del paquete <em>MOTE</em> <span class="citation">(Buchanan et al., <a href="#ref-R-MOTE">2019</a>)</span>, donde es necesario indicar la media muestral, media poblacional a comparar, desviación estándar muestral, tamaño de la muestra, y nivel de significancia.</p>
<pre class="sourceCode r"><code class="sourceCode r">d.t1.res =<span class="st"> </span><span class="kw">d.single.t</span>(<span class="dt">m =</span> <span class="kw">mean</span>(cuarzo), 
                      <span class="dt">u =</span> mu0, 
                      <span class="dt">sd =</span> <span class="kw">sd</span>(cuarzo), 
                      <span class="dt">n =</span> <span class="kw">length</span>(cuarzo), 
                      <span class="dt">a =</span> a)
d.t1.res[<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">unlist</span>()</code></pre>
<pre><code>##          d       dlow      dhigh 
##  0.4905400 -0.2619016  1.2128190</code></pre>
<p>Usando las medidas PS, OVL, y <span class="math inline">\(U_3\)</span> (Figura <a href="pruebas-estadísticas.html#fig:t1-u3">15.4</a>).</p>
<pre><code>## # A tibble: 1 x 3
##      PS   OVL    U3
##   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1  63.6  80.6  68.8</code></pre>
<div class="figure" style="text-align: center"><span id="fig:t1-u3"></span>
<img src="geolonum_files/figure-html/t1-u3-1.png" alt="$U_3$ para el ejemplo de la prueba $t$ de 1 muestra. **A** Corresponde con los datos en escala original. **B** Corresponde con el tamaño del efecto $d$." width="70%" />
<p class="caption">
Figura 15.4: <span class="math inline">\(U_3\)</span> para el ejemplo de la prueba <span class="math inline">\(t\)</span> de 1 muestra. <strong>A</strong> Corresponde con los datos en escala original. <strong>B</strong> Corresponde con el tamaño del efecto <span class="math inline">\(d\)</span>.
</p>
</div>
<blockquote>
<p>Conclusión: El contenido de cuarzo de la roca ígnea (<span class="math inline">\(M = 21.51\)</span>, 95% IC <span class="math inline">\([18.93\)</span>, <span class="math inline">\(24.09]\)</span>) no es signficativamente diferente a la media de 20% , <span class="math inline">\(t(7) = 1.39\)</span>, <span class="math inline">\(p = .208\)</span>, <span class="math inline">\(d\)</span> = 0.49 <span class="math inline">\([-0.26, 1.21]\)</span>. El efecto se puede considerar mediano, pero con un rango de pequeño, en dirección opuesta, hasta muy grande. Hay una probabilidad de 63.6% (PS) que un elemento de la muestra tenga un contenido de cuarzo mayor a un elemento de la población hipotética; las dos curvas se traslapan en un 80.6% (OVL); el 68.8% (<span class="math inline">\(U_3\)</span>) de la muestra se encuentra por encima de la media de la población hipotética.</p>
</blockquote>
</div>
<div id="prueba-t2-ind" class="section level2">
<h2><span class="header-section-number">15.6</span> <span class="math inline">\(t\)</span> de 2 muestras independientes</h2>
<p>Para este caso es cuando, en teoría, se debiera cumplir no solo la normalidad de las muestras, sino también la igualdad de varianzas. Si se quiere relajar el supuesto de igualdad de varianzas se usa el estadístico Welch o Welch-Satterthwaite (<a href="estimación-e-hipótesis.html#estim-ic-t2-ind">14.2.2.2.1</a> - varianzas diferentes). En general la diferecia entre asumir igualdad de varianzas o no va a ser pequeña, siempre y cuando éstas no sean muy diferentes y los tamaños de muestra no sean muy disparejos, y es recomendado indicar qué método se usó <span class="citation">(Cumming &amp; Calin-Jageman, <a href="#ref-cumming2017">2017</a>)</span>.</p>
<p>El uso de la prueba <span class="math inline">\(t\)</span> de 2 muestras independientes se realiza con el ejemplo de la sección <a href="estimación-e-hipótesis.html#estim-ic-t2-ind">14.2.2.2.1</a> <span class="citation">(Swan &amp; Sandilands, <a href="#ref-swan1995">1995</a>)</span>, el de varianzas iguales, donde se tenían braquiópodos en dos capas (A, B) y se les midió la longitud (cm). Es posible que estas muestras provenga de una misma población (<span class="math inline">\(\mu_1=\mu_2\)</span>)? Asuma <span class="math inline">\(\alpha = 0.05\)</span>.</p>
<ol style="list-style-type: decimal">
<li>Identificar la población, distribución, y la prueba apropiada:
<ul>
<li>Población: braquiópodos en capas A y B</li>
<li>Distribución: diferencia de medias</li>
<li>Prueba: <span class="math inline">\(t\)</span> de 2 muestras independientes porque se tienen 2 muestras, y las dos provienen de sitios diferentes (independientes uno del otro)</li>
</ul></li>
<li>Establecer las hipótesis nula y alterna:
<ul>
<li><span class="math inline">\(H_0: \mu_1 = \mu_2 \to\)</span> La longitud e los braquiópodos en la capa A es <em>igual</em> a la longitud e los braquiópodos en la capa B</li>
<li><span class="math inline">\(H_1: \mu \neq \mu_0 \to\)</span> La longitud e los braquiópodos en la capa A es <em>diferente</em> la longitud e los braquiópodos en la capa B</li>
</ul></li>
<li>Determinar parámetros de la distribución a comparar (<span class="math inline">\(H_0\)</span>):
<ul>
<li><span class="math inline">\(\mu_1 - \mu_2 = 0\)</span></li>
<li><span class="math inline">\(s_p = \sqrt{\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 - 2}} = \sqrt{\frac{(8-1)0.042 + (10-1)0.029}{8 + 10 - 2}} = 0.1865\)</span></li>
<li><span class="math inline">\(s_{\bar{x}_1-\bar{x}_2} = s_p \sqrt{\frac{1}{n_1} + \frac{1}{n_2}} = 0.1865 \sqrt{\frac{1}{8} + \frac{1}{10}} = 0.0885\)</span></li>
</ul></li>
<li>Determinar valores críticos
<ul>
<li><span class="math inline">\(\alpha = 0.05\)</span></li>
<li><span class="math inline">\(t_{\alpha/2,v} = t_{0.05/2,16} = |2.12|\)</span></li>
</ul></li>
<li>Calcular el estadístico de prueba
<ul>
<li><span class="math inline">\(t = \frac{(\bar{x}_1-\bar{x}_2) - (\mu_1-\mu_2)}{s_{\bar{x}_1-\bar{x}_2}} = \frac{(3.125-2.96) - 0}{0.0885} = 1.86\)</span></li>
<li><span class="math inline">\(0.165 \pm 0.1876 \to 95\% \ IC \ [-0.023,0.353]\)</span></li>
</ul></li>
<li>Tomar una decisión
<ul>
<li>El estadístico de prueba es menor al crítico, <span class="math inline">\(t &lt; t_{\alpha/2,v}\)</span></li>
<li>El valor-<em>p</em> es mayor a <span class="math inline">\(\alpha = 0.05\)</span>, <span class="math inline">\(p = 0.081\)</span></li>
<li>El valor de <span class="math inline">\(0\)</span> cae dentro del intervalo de confianza, <span class="math inline">\(IC \ [-0.023,0.353]\)</span></li>
<li><em>Decisión</em>: No se rechaza <span class="math inline">\(H_0\)</span></li>
</ul></li>
</ol>
<p><strong>R</strong> trae la función <code>t.test</code> que puede realizar las diferentes pruebas <span class="math inline">\(t\)</span>. Para el caso de 2 muestras independientes se brindan los vectores de datos, el indicador lógico de si las varianzas se deben considerar iguales, y el nivel de confianza.</p>
<pre class="sourceCode r"><code class="sourceCode r">a =<span class="st"> </span><span class="fl">0.05</span>

A =<span class="st"> </span><span class="kw">c</span>(<span class="fl">3.2</span>, <span class="fl">3.1</span>, <span class="fl">3.1</span>, <span class="fl">3.3</span>, <span class="fl">2.9</span>, <span class="fl">2.9</span>, <span class="fl">3.5</span>, <span class="fl">3.0</span>)
B =<span class="st"> </span><span class="kw">c</span>(<span class="fl">3.1</span>, <span class="fl">3.1</span>, <span class="fl">2.8</span>, <span class="fl">3.1</span>, <span class="fl">3.0</span>, <span class="fl">2.6</span>, <span class="fl">3.0</span>, <span class="fl">3.0</span>, <span class="fl">3.1</span>, <span class="fl">2.8</span>)

t2.ind.res =<span class="st"> </span><span class="kw">t.test</span>(<span class="dt">x =</span> A,
                    <span class="dt">y =</span> B,
                    <span class="dt">var.equal =</span> T, 
                    <span class="dt">conf.level =</span> <span class="dv">1</span><span class="op">-</span>a)
t2.ind.res</code></pre>
<pre><code>## 
##  Two Sample t-test
## 
## data:  A and B
## t = 1.861, df = 16, p-value = 0.08122
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.02295489  0.35295489
## sample estimates:
## mean of x mean of y 
##     3.125     2.960</code></pre>
<p>Como se mencionó en la sección <a href="estimación-e-hipótesis.html#estim-ic-t2-ind">14.2.2.2.1</a>, las pruebas de hipótesis se pueden aproximar por medio de la estimación, más específicamente, los intervalos de confianza (Figura <a href="pruebas-estadísticas.html#fig:t2-ind-ci">15.5</a>), siguiendo las guías de <span class="citation">Cumming &amp; Finch (<a href="#ref-cumming2005ap">2005</a>)</span>, <span class="citation">Cumming (<a href="#ref-cumming2012">2012</a>)</span>, y <span class="citation">Cumming &amp; Calin-Jageman (<a href="#ref-cumming2017">2017</a>)</span>. El intervalo de confianza para el parámetro de interés se puede comparar con <span class="math inline">\(H_0\)</span>, y se puede obtener la misma conclusión a realizar la prueba estadística.</p>
<div class="figure" style="text-align: center"><span id="fig:t2-ind-ci"></span>
<img src="geolonum_files/figure-html/t2-ind-ci-1.png" alt="Intervalos de confianza para la prueba t de 2 muestras independientes. El valor de 0 cae dentro del intervalo de confianza para la diferencia, por lo que se pueden considerar iguales o que no hay diferencia entre las capas." width="70%" />
<p class="caption">
Figura 15.5: Intervalos de confianza para la prueba t de 2 muestras independientes. El valor de 0 cae dentro del intervalo de confianza para la diferencia, por lo que se pueden considerar iguales o que no hay diferencia entre las capas.
</p>
</div>
<p>El tamaño del efecto se puede calcular de acuerdo a las Ecuaciones <a href="pruebas-estadísticas.html#eq:d-t2-d">(15.7)</a> y <a href="pruebas-estadísticas.html#eq:d-g">(15.11)</a>, donde de manera general se usa la desviación agrupada (pooled standard deviation ,<span class="math inline">\(s_p\)</span>) como el estandarizador, sin importar si se asumen varianzas iguales o no para la prueba, pero es buena práctica reportar qué se uso como estandarizador <span class="citation">(Cumming &amp; Calin-Jageman, <a href="#ref-cumming2017">2017</a>)</span>.</p>
<p><span class="math display">\[\begin{equation}
  d_s = \frac{\bar{x}_1-\bar{x}_2}{\sqrt{\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 - 2}}}\\
  d_s = \frac{3.125-2.96}{\sqrt{\frac{(8-1)0.042 + (10-1)0.029}{8 + 10 - 2}}} = 0.88
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
  g_s = d_s \cdot \left( 1 - \frac{3}{4v-1} \right)\\
  g_s = 0.88 \cdot \left( 1 - \frac{3}{4(16)-1} \right) = 0.84
\end{equation}\]</span></p>
<p>La correción de Hedges (<span class="math inline">\(g_s\)</span>) se usa ya que <span class="math inline">\(d_s\)</span> se considera un estimador sesgado (biased) especialmenta para muestras pequeñas, conforme mayor sea el tamaño de muestra más similares <span class="math inline">\(d_s\)</span> y <span class="math inline">\(g_s\)</span> <span class="citation">(Cumming, <a href="#ref-cumming2012">2012</a>; Cumming &amp; Calin-Jageman, <a href="#ref-cumming2017">2017</a>; Fritz et al., <a href="#ref-fritz2012joepg">2012</a>; McGrath &amp; Meyer, <a href="#ref-mcgrath2006pm">2006</a>)</span>.</p>
<p>En <strong>R</strong> se puede calcular <span class="math inline">\(d_s\)</span> con la función <code>d.ind.t</code> y <span class="math inline">\(g_s\)</span> con la función <code>g.ind.t</code> del paquete <em>MOTE</em>, donde es necesario indicar la media muestral de ambas muetras, desviación estándar muestral de ambas muestras, tamaño ambas muestras, y nivel de significancia. Adicionalmente existen las funciones <code>cohens_d</code> y <code>hedges_g</code> de <em>effectsize</em> <span class="citation">(Ben-Shachar et al., <a href="#ref-R-effectsize">2020</a>)</span>, y <code>cohen.d</code> de <em>effsize</em> <span class="citation">(Torchiano, <a href="#ref-R-effsize">2018</a>)</span>.</p>
<p>Usando <em>MOTE</em></p>
<pre class="sourceCode r"><code class="sourceCode r">d.t2.ind.res =<span class="st"> </span><span class="kw">d.ind.t</span>(<span class="dt">m1 =</span> <span class="kw">mean</span>(A), <span class="dt">m2 =</span> <span class="kw">mean</span>(B), 
                       <span class="dt">sd1 =</span> <span class="kw">sd</span>(A), <span class="dt">sd2 =</span> <span class="kw">sd</span>(B), 
                       <span class="dt">n1 =</span> <span class="kw">length</span>(A), <span class="dt">n2 =</span> <span class="kw">length</span>(B),
                       <span class="dt">a =</span> a)
d.t2.ind.res[<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">unlist</span>()</code></pre>
<pre><code>##          d       dlow      dhigh 
##  0.8827506 -0.1075693  1.8483100</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">g.t2.ind.res =<span class="st"> </span><span class="kw">g.ind.t</span>(<span class="dt">m1 =</span> <span class="kw">mean</span>(A), <span class="dt">m2 =</span> <span class="kw">mean</span>(B), 
                       <span class="dt">sd1 =</span> <span class="kw">sd</span>(A), <span class="dt">sd2 =</span> <span class="kw">sd</span>(B), 
                       <span class="dt">n1 =</span> <span class="kw">length</span>(A), <span class="dt">n2 =</span> <span class="kw">length</span>(B),
                       <span class="dt">a =</span> a)
g.t2.ind.res[<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">unlist</span>()</code></pre>
<pre><code>##          d       dlow      dhigh 
##  0.8407149 -0.1024469  1.7602953</code></pre>
<p>Usando <em>effectsize</em></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cohens_d</span>(A,B,
         <span class="dt">ci =</span> <span class="dv">1</span><span class="op">-</span>a)</code></pre>
<pre><code>## # A tibble: 1 x 4
##   Cohens_d    CI CI_low CI_high
##      &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;
## 1    0.883  0.95 -0.108    1.85</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">hedges_g</span>(A,B,
         <span class="dt">ci =</span> <span class="dv">1</span><span class="op">-</span>a)</code></pre>
<pre><code>## # A tibble: 1 x 4
##   Hedges_g    CI CI_low CI_high
##      &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;
## 1    0.841  0.95 -0.102    1.76</code></pre>
<p>Usando <em>effsize</em></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cohen.d</span>(A,B,
        <span class="dt">conf.level =</span> <span class="dv">1</span><span class="op">-</span>a,
        <span class="dt">noncentral=</span>T)</code></pre>
<pre><code>## 
## Cohen&#39;s d
## 
## d estimate: 0.8827506 (large)
## 95 percent confidence interval:
##      lower      upper 
## -0.1075693  1.8483100</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cohen.d</span>(A,B,
        <span class="dt">conf.level =</span> <span class="dv">1</span><span class="op">-</span>a,
        <span class="dt">hedges.correction =</span> T,
        <span class="dt">noncentral=</span>T)</code></pre>
<pre><code>## 
## Hedges&#39;s g
## 
## g estimate: 0.8407149 (large)
## 95 percent confidence interval:
##      lower      upper 
## -0.1075693  1.8483100</code></pre>
<p>Usando las medidas PS, OVL, y <span class="math inline">\(U_3\)</span> (Figura <a href="pruebas-estadísticas.html#fig:t2-ind-u3">15.6</a>).</p>
<pre><code>## # A tibble: 1 x 3
##      PS   OVL    U3
##   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1  73.4  65.9  81.1</code></pre>
<div class="figure" style="text-align: center"><span id="fig:t2-ind-u3"></span>
<img src="geolonum_files/figure-html/t2-ind-u3-1.png" alt="$U_3$ para el ejemplo de la prueba $t$ de 2 muestras independientes. **A** Corresponde con los datos en escala original. **B** Corresponde con el tamaño del efecto $d$." width="70%" />
<p class="caption">
Figura 15.6: <span class="math inline">\(U_3\)</span> para el ejemplo de la prueba <span class="math inline">\(t\)</span> de 2 muestras independientes. <strong>A</strong> Corresponde con los datos en escala original. <strong>B</strong> Corresponde con el tamaño del efecto <span class="math inline">\(d\)</span>.
</p>
</div>
<blockquote>
<p>Conclusión: La longitud de los braquiópodos en la capa A no es signficativamente diferente de la longitud de los braquiópodos en la capa B (<span class="math inline">\(\Delta M = 0.165\)</span>, 95% IC <span class="math inline">\([-0.023\)</span>, <span class="math inline">\(0.353]\)</span>), <span class="math inline">\(t(16) = 1.86\)</span>, <span class="math inline">\(p = .081\)</span>, <span class="math inline">\(d_s\)</span> = 0.88 <span class="math inline">\([-0.11, 1.85]\)</span>. El efecto se puede considerar grande, pero con un rango de muy pequeño, en dirección opuesta, hasta muy grande. Hay una probabilidad de 73.4% (PS) que un elemento de la muestra A tenga una longitud mayor que un elemento de la muestra B; las dos curvas se traslapan en un 65.9% (OVL); el 81.8% (<span class="math inline">\(U_3\)</span>) de la muestra A se encuentra por encima de la media de la muestra B.</p>
</blockquote>
</div>
<div id="prueba-t2-dep" class="section level2">
<h2><span class="header-section-number">15.7</span> <span class="math inline">\(t\)</span> de 2 muestras dependientes</h2>
<p>Estas muestras que miden la misma observación (objeto, sujeto) más de una vez también se conocen como <em>muestras pareadas</em> o <em>mediciones repetidas</em> (repeated measures - en inglés).</p>
<p>El uso de la prueba <span class="math inline">\(t\)</span> de 2 muestras dependientes se realiza con el ejemplo de la sección <a href="estimación-e-hipótesis.html#estim-ic-t2-dep">14.2.2.2.2</a> <span class="citation">(McKillup &amp; Darby Dyar, <a href="#ref-mckillup2010">2010</a>)</span>, donde se tenía el contenido de <span class="math inline">\(FeO\)</span> en porcentaje de peso para 10 granitos que fueron preparados a diferentes tamaños de grano: <span class="math inline">\(&lt; 25 \ \mu m\)</span> y <span class="math inline">\(&lt; 125 \ \mu m\)</span>. Hay un efecto en el tratamiento, en este caso, cambio del tamaño de grano (<span class="math inline">\(\mu_D=0\)</span>)? Asuma <span class="math inline">\(\alpha = 0.05\)</span>.</p>
<ol style="list-style-type: decimal">
<li>Identificar la población, distribución, y la prueba apropiada:
<ul>
<li>Población: contenido de <span class="math inline">\(FeO\)</span> a diferentes tamaños de grano: <span class="math inline">\(&lt; 25 \ \mu m\)</span> y <span class="math inline">\(&lt; 125 \ \mu m\)</span></li>
<li>Distribución: media de las diferencia</li>
<li>Prueba: <span class="math inline">\(t\)</span> de 2 muestras dependientes porque se tienen los mismos elementos antes y después de un tratamiento (cambio de tamaño de grano)</li>
</ul></li>
<li>Establecer las hipótesis nula y alterna:
<ul>
<li><span class="math inline">\(H_0: \mu_D = 0 \to\)</span> El contenido de <span class="math inline">\(FeO\)</span> es <em>igual</em> a los diferentes tamaños de grano</li>
<li><span class="math inline">\(H_1: \mu_D \neq 0 \to\)</span> El contenido de <span class="math inline">\(FeO\)</span> es <em>diferente</em> a los diferentes tamaños de grano</li>
</ul></li>
<li>Determinar parámetros de la distribución a comparar (<span class="math inline">\(H_0\)</span>):
<ul>
<li><span class="math inline">\(\mu_D = 0\)</span></li>
<li><span class="math inline">\(s_{\bar{x}_d} = \frac{s_d}{\sqrt{n}} = \frac{0.1247}{\sqrt{10}} = 0.0394\)</span></li>
</ul></li>
<li>Determinar valores críticos
<ul>
<li><span class="math inline">\(\alpha = 0.05\)</span></li>
<li><span class="math inline">\(t_{\alpha/2,v} = t_{0.05/2,9} = |2.262|\)</span></li>
</ul></li>
<li>Calcular el estadístico de prueba
<ul>
<li><span class="math inline">\(t = \frac{\bar{x}_d}{s_{\bar{x}_d}} = \frac{0.1}{0.0394} = 2.538\)</span></li>
<li><span class="math inline">\(0.1 \pm 0.0981 \to 95\% \ IC \ [0.0108,0.189]\)</span></li>
</ul></li>
<li>Tomar una decisión
<ul>
<li>El estadístico de prueba es mayor al crítico, <span class="math inline">\(t &gt; t_{\alpha/2,v}\)</span></li>
<li>El valor-<em>p</em> es menor a <span class="math inline">\(\alpha = 0.05\)</span>, <span class="math inline">\(p = 0.032\)</span></li>
<li>El valor de <span class="math inline">\(0\)</span> no cae dentro del intervalo de confianza, <span class="math inline">\(IC \ [0.0108,0.189]\)</span></li>
<li><em>Decisión</em>: Se rechaza <span class="math inline">\(H_0\)</span></li>
</ul></li>
</ol>
<p><strong>R</strong> trae la función <code>t.test</code> que puede realizar las diferentes pruebas <span class="math inline">\(t\)</span>. Para el caso de 2 muestras dependientes se brindan los vectores de datos, el indicador lógico de si es una prueba dependiente (<code>paired</code>), y el nivel de confianza.</p>
<pre class="sourceCode r"><code class="sourceCode r">a =<span class="st"> </span><span class="fl">0.05</span>

m1 =<span class="st"> </span><span class="kw">c</span>(<span class="fl">13.5</span>,<span class="fl">14.6</span>,<span class="fl">12.7</span>,<span class="fl">15.5</span>,<span class="fl">11.1</span>,<span class="fl">16.4</span>,<span class="fl">13.2</span>,<span class="fl">19.3</span>,<span class="fl">16.7</span>,<span class="fl">18.4</span>)
m2 =<span class="st"> </span><span class="kw">c</span>(<span class="fl">13.6</span>,<span class="fl">14.6</span>,<span class="fl">12.6</span>,<span class="fl">15.7</span>,<span class="fl">11.1</span>,<span class="fl">16.6</span>,<span class="fl">13.2</span>,<span class="fl">19.5</span>,<span class="fl">16.8</span>,<span class="fl">18.7</span>)
n =<span class="st"> </span><span class="kw">length</span>(m2)
r =<span class="st"> </span><span class="kw">cor</span>(m1,m2)

t2.dep.res =<span class="st"> </span><span class="kw">t.test</span>(<span class="dt">x =</span> m2,
                    <span class="dt">y =</span> m1,
                    <span class="dt">paired =</span> T,
                    <span class="dt">conf.level =</span> <span class="dv">1</span><span class="op">-</span>a)
t2.dep.res</code></pre>
<pre><code>## 
##  Paired t-test
## 
## data:  m2 and m1
## t = 2.5355, df = 9, p-value = 0.03195
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  0.01077932 0.18922068
## sample estimates:
## mean of the differences 
##                     0.1</code></pre>
<p>Como se mencionó en la sección <a href="estimación-e-hipótesis.html#estim-ic-t2-dep">14.2.2.2.2</a>, y a diferencia de muestras independientes, las pruebas de hipótesis para muestras dependientes no se pueden aproximar por medio de los intervalos de confianza (Figura <a href="pruebas-estadísticas.html#fig:t2-dep-ci">15.7</a>), siguiendo las guías de <span class="citation">Cumming &amp; Finch (<a href="#ref-cumming2005ap">2005</a>)</span>, <span class="citation">Cumming (<a href="#ref-cumming2012">2012</a>)</span>, y <span class="citation">Cumming &amp; Calin-Jageman (<a href="#ref-cumming2017">2017</a>)</span>. En este caso solo se puede utilizar el intervalo de confianza para la diferencia, que va a estar en función de los márgenes de error de las muestras y la correlación entre las mismas (<span class="math inline">\(MoE_d^2 = MoE_1^2 + MoE_2^2 - 2rMoE_1MoE_2\)</span>), donde a mayor correlación menor el márgen de error para la diferencia y mayor precisión <span class="citation">(Cumming &amp; Finch, <a href="#ref-cumming2005ap">2005</a>)</span>.</p>
<div class="figure" style="text-align: center"><span id="fig:t2-dep-ci"></span>
<img src="geolonum_files/figure-html/t2-dep-ci-1.png" alt="Intervalos de confianza para la prueba t de 2 muestras independientes. El valor de 0 cae fuera del intervalo de confianza para la diferencia, por lo que no se pueden considerar iguales o que hay diferencia entre la concentración de $FeO$ para los tamaños." width="70%" />
<p class="caption">
Figura 15.7: Intervalos de confianza para la prueba t de 2 muestras independientes. El valor de 0 cae fuera del intervalo de confianza para la diferencia, por lo que no se pueden considerar iguales o que hay diferencia entre la concentración de <span class="math inline">\(FeO\)</span> para los tamaños.
</p>
</div>
<p>El tamaño del efecto se puede calcular de acuerdo a las Ecuaciones <a href="pruebas-estadísticas.html#eq:d-t2-dep1">(15.8)</a>, <a href="pruebas-estadísticas.html#eq:d-t2-dep2">(15.9)</a> y <a href="pruebas-estadísticas.html#eq:d-t2-dep3">(15.10)</a>, donde la diferencia es qué se usa como estandarizador. De nuevo es buena práctica reportar qué se usó como estandarizador para claridad en lo que se reporta <span class="citation">(Cumming &amp; Calin-Jageman, <a href="#ref-cumming2017">2017</a>)</span>. Si la correlación entre las muestras es <span class="math inline">\(r \sim |0.5|\)</span> no hay mucha diferencia entre los tamaños de efecto, pero conforme la correlación se acerque a <span class="math inline">\(0\)</span> o <span class="math inline">\(1\)</span> mayor será la diferencia entre <span class="math inline">\(d_z\)</span> con respecto a <span class="math inline">\(d_{rm}\)</span> y <span class="math inline">\(d_{av}\)</span> <span class="citation">(Lakens, <a href="#ref-lakens2013fp">2013</a>)</span>. Debido al punto anterior, y la típica relación entre muestras, <span class="citation">Cumming (<a href="#ref-cumming2012">2012</a>)</span>, <span class="citation">Cumming &amp; Calin-Jageman (<a href="#ref-cumming2017">2017</a>)</span>, y <span class="citation">Lakens (<a href="#ref-lakens2013fp">2013</a>)</span> sugieren utilizar <span class="math inline">\(d_{av}\)</span> como el tamaño del efecto.</p>
<p><span class="math display">\[\begin{equation}
  d_z = \frac{\bar{x}_d}{s_d}\\
  d_z = \frac{0.1}{0.1247} = 0.80
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
  d_{rm} = \frac{\bar{x}_d}{\sqrt{s_1^2 + s_2^2 - 2 \cdot r \cdot s_1 \cdot s_2}}\sqrt{2(1-r)}\\
  d_{rm} = \frac{0.1}{\sqrt{7.33 + 6.79 - 2 \cdot 0.9996 \cdot 2.7 \cdot 2.6}}\sqrt{2(1-0.9996)} = 0.001\\
  \text{usando todos los decimales da } d_{rm} = 0.022)
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
  d_{av} = \frac{\bar{x}_d}{\sqrt{\frac{s_1^2 + s_2^2}{2}}}\\
  d_{av} = \frac{0.1}{\sqrt{\frac{7.33 + 6.79}{2}}} = 0.038
\end{equation}\]</span></p>
<p>En <strong>R</strong> se puede calcular <span class="math inline">\(d_z\)</span> con la función <code>d.dep.t.diff</code>, <span class="math inline">\(d_{rm}\)</span> con la función <code>d.dep.t.rm</code>, y <span class="math inline">\(d_{av}\)</span> con la función <code>d.dep.t.avg</code>, todas del paquete <em>MOTE</em>. Adicionalmente existen las funciones <code>cohens_d</code> de <em>effectsize</em>, y <code>cohen.d</code> de <em>effsize</em>, donde de nuevo se tiene que definir el argumento <code>paired</code>, pero en los dos casos el efecto que calculan es <span class="math inline">\(d_z\)</span>, el cual es el menos recomendado. Además, la función <code>cohensd_rm</code> del paquete <em>itns</em> <span class="citation">(Erceg-Hurn et al., <a href="#ref-R-itns">2017</a>)</span> calcula <span class="math inline">\(d_{av}\)</span>.</p>
<p>Usando <em>MOTE</em></p>
<pre class="sourceCode r"><code class="sourceCode r">a =<span class="st"> </span><span class="fl">0.05</span>
d.t2.dep.res1 =<span class="st"> </span><span class="kw">d.dep.t.diff</span>(<span class="dt">mdiff =</span> <span class="kw">mean</span>(m2<span class="op">-</span>m1),
                             <span class="dt">sddiff =</span> <span class="kw">sd</span>(m2<span class="op">-</span>m1),
                             <span class="dt">n =</span> n,
                             <span class="dt">a =</span> a)
d.t2.dep.res1[<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">unlist</span>()</code></pre>
<pre><code>##          d       dlow      dhigh 
## 0.80178373 0.06638463 1.50482386</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">d.t2.dep.res2 =<span class="st"> </span><span class="kw">d.dep.t.rm</span>(<span class="dt">m1 =</span> <span class="kw">mean</span>(m2),
                           <span class="dt">m2 =</span> <span class="kw">mean</span>(m1),
                           <span class="dt">sd1 =</span> <span class="kw">sd</span>(m2),
                           <span class="dt">sd2 =</span> <span class="kw">sd</span>(m1),
                           <span class="dt">r =</span> r,
                           <span class="dt">n =</span> n,
                           <span class="dt">a =</span> a)
d.t2.dep.res2[<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">unlist</span>()</code></pre>
<pre><code>##           d        dlow       dhigh 
##  0.02164429 -0.59882065  0.64092600</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">d.t2.dep.res3 =<span class="st"> </span><span class="kw">d.dep.t.avg</span>(<span class="dt">m1 =</span> <span class="kw">mean</span>(m2),
                            <span class="dt">m2 =</span> <span class="kw">mean</span>(m1),
                            <span class="dt">sd1 =</span> <span class="kw">sd</span>(m2),
                            <span class="dt">sd2 =</span> <span class="kw">sd</span>(m1),
                            <span class="dt">n =</span> n,
                            <span class="dt">a =</span> a)
d.t2.dep.res3[<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">unlist</span>()</code></pre>
<pre><code>##           d        dlow       dhigh 
##  0.03764125 -0.58341889  0.65664471</code></pre>
<p>La Tabla <a href="pruebas-estadísticas.html#tab:d-dep-comparacion">15.3</a> muestra la comparación entre los diferentes tamaños de efecto para el ejemplo de muestras dependientes. Los resultados muestran como <span class="math inline">\(d_z\)</span> sobreestima (y por mucho) a <span class="math inline">\(d_{rm}\)</span> y <span class="math inline">\(d_{av}\)</span>, donde <span class="math inline">\(d_{rm}\)</span> es el más conservador de todos. <span class="citation">(Lakens, <a href="#ref-lakens2013fp">2013</a>)</span>. El hecho de que <span class="math inline">\(d_z\)</span> sobreestima el tamaño del efecto es devido a la alta correlación entre las muestras <span class="math inline">\(r = 0.9996\)</span>.</p>
<table>
<caption>
<span id="tab:d-dep-comparacion">Tabla 15.3: </span>Comparación de tamaños de efecto para muestras dependientes
</caption>
<thead>
<tr>
<th style="text-align:center;">
ES
</th>
<th style="text-align:center;">
<span class="math inline">\(d\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(IC_{inf}\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(IC_{sup}\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
<span class="math inline">\(d_z\)</span>
</td>
<td style="text-align:center;">
0.802
</td>
<td style="text-align:center;">
0.066
</td>
<td style="text-align:center;">
1.505
</td>
</tr>
<tr>
<td style="text-align:center;">
<span class="math inline">\(d_{rm}\)</span>
</td>
<td style="text-align:center;">
0.022
</td>
<td style="text-align:center;">
-0.599
</td>
<td style="text-align:center;">
0.641
</td>
</tr>
<tr>
<td style="text-align:center;">
<span class="math inline">\(d_{av}\)</span>
</td>
<td style="text-align:center;">
0.038
</td>
<td style="text-align:center;">
-0.583
</td>
<td style="text-align:center;">
0.657
</td>
</tr>
</tbody>
</table>
<p>Un panorama general del efecto de <span class="math inline">\(r\)</span> en el tamaño del efecto para muestras dependientes se muestra en la Tabla <a href="pruebas-estadísticas.html#tab:d-dep-comparacion2">15.4</a>, donde se generaron tres juegos de datos, provenientes de poblaciones con <span class="math inline">\(r=0.1\)</span>, <span class="math inline">\(r=0.5\)</span>, y <span class="math inline">\(r=0.9\)</span>, respectivamente. Se observa como a bajos valores de <span class="math inline">\(r\)</span> <span class="math inline">\(d_z\)</span> subestima el tamaño del efecto (con respecto a <span class="math inline">\(d_{rm}\)</span> y <span class="math inline">\(d_{av}\)</span>), a valores intermedios todos son muy similares, y a altos valores de <span class="math inline">\(r\)</span> <span class="math inline">\(d_z\)</span> sobreestima el tamaño del efecto (con respecto a <span class="math inline">\(d_{rm}\)</span> y <span class="math inline">\(d_{av}\)</span>), lo que muestra la sensibilidad y el efecto de <span class="math inline">\(r\)</span> en el uso de <span class="math inline">\(d_z\)</span>, y por lo que se recomienda usar <span class="math inline">\(d_{rm}\)</span> o <span class="math inline">\(d_{av}\)</span>.</p>
<table>
<caption>
<span id="tab:d-dep-comparacion2">Tabla 15.4: </span>Comparación de los diferentes <span class="math inline">\(d\)</span> para muestras dependientes
</caption>
<thead>
<tr>
<th style="text-align:left;">
<span class="math inline">\(\rho\)</span>
</th>
<th style="text-align:right;">
<span class="math inline">\(r\)</span>
</th>
<th style="text-align:right;">
<span class="math inline">\(d_z\)</span>
</th>
<th style="text-align:right;">
<span class="math inline">\(d_{rm}\)</span>
</th>
<th style="text-align:right;">
<span class="math inline">\(d_{av}\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
0.1
</td>
<td style="text-align:right;">
0.254
</td>
<td style="text-align:right;">
0.511
</td>
<td style="text-align:right;">
0.624
</td>
<td style="text-align:right;">
0.625
</td>
</tr>
<tr>
<td style="text-align:left;">
0.5
</td>
<td style="text-align:right;">
0.492
</td>
<td style="text-align:right;">
0.637
</td>
<td style="text-align:right;">
0.642
</td>
<td style="text-align:right;">
0.646
</td>
</tr>
<tr>
<td style="text-align:left;">
0.9
</td>
<td style="text-align:right;">
0.932
</td>
<td style="text-align:right;">
2.107
</td>
<td style="text-align:right;">
0.778
</td>
<td style="text-align:right;">
0.804
</td>
</tr>
</tbody>
</table>
<p>Usando <em>itns</em></p>
<pre class="sourceCode r"><code class="sourceCode r">d.t2.dep.res4 =<span class="st"> </span><span class="kw">cohensd_rm</span>(m2,m1,
                           <span class="dt">ci =</span> <span class="dv">1</span><span class="op">-</span>a)
d.t2.dep.res4</code></pre>
<pre><code>##        est         ll         ul 
## 0.03763431 0.03630516 0.03671538</code></pre>
<p>Usando <em>effectsize</em></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cohens_d</span>(m2,m1,
         <span class="dt">paired =</span> T,
         <span class="dt">ci =</span> <span class="dv">1</span><span class="op">-</span>a)</code></pre>
<pre><code>## # A tibble: 1 x 4
##   Cohens_d    CI CI_low CI_high
##      &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;
## 1    0.802  0.95 0.0700    1.59</code></pre>
<p>Usando <em>effsize</em></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cohen.d</span>(m2,m1,
        <span class="dt">conf.level =</span> <span class="dv">1</span><span class="op">-</span>a,
        <span class="dt">paired =</span> T,
        <span class="dt">noncentral=</span>T)</code></pre>
<pre><code>## 
## Cohen&#39;s d
## 
## d estimate: 0.8017837 (large)
## 95 percent confidence interval:
##      lower      upper 
## 0.06996669 1.58622949</code></pre>
<p>Usando las medidas PS, OVL, y <span class="math inline">\(U_3\)</span> (Figura <a href="pruebas-estadísticas.html#fig:t2-dep-u3">15.8</a>).</p>
<pre><code>## # A tibble: 1 x 3
##      PS   OVL    U3
##   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1  51.1  98.5  51.5</code></pre>
<div class="figure" style="text-align: center"><span id="fig:t2-dep-u3"></span>
<img src="geolonum_files/figure-html/t2-dep-u3-1.png" alt="$U_3$ para el ejemplo de la prueba $t$ de 2 muestras dependientes. **A** Corresponde con los datos en escala original. **B** Corresponde con el tamaño del efecto $d$." width="70%" />
<p class="caption">
Figura 15.8: <span class="math inline">\(U_3\)</span> para el ejemplo de la prueba <span class="math inline">\(t\)</span> de 2 muestras dependientes. <strong>A</strong> Corresponde con los datos en escala original. <strong>B</strong> Corresponde con el tamaño del efecto <span class="math inline">\(d\)</span>.
</p>
</div>
<blockquote>
<p>Conclusión: La concentración de <span class="math inline">\(FeO\)</span> es signficativamente diferente para los diferentes tamaños (<span class="math inline">\(M_d = 0.100\)</span>, 95% IC <span class="math inline">\([0.011\)</span>, <span class="math inline">\(0.189]\)</span>), <span class="math inline">\(t(9) = 2.54\)</span>, <span class="math inline">\(p = .032\)</span>, <span class="math inline">\(N = 10\)</span>, <span class="math inline">\(r = 0.9996356\)</span>, <span class="math inline">\(d_{av}\)</span> = 0.04 <span class="math inline">\([-0.58, 0.66]\)</span>. El efecto se puede considerar muy pequeño, con un rango de mediano, en dirección opuesta, hasta mediano en la dirección del efecto. Hay una probabilidad de 51.1% (PS) que un elemento de la muestra de <span class="math inline">\(&lt; 125 \ \mu m\)</span> tenga una concentración mayor que un elemento de la muestra de <span class="math inline">\(&lt; 25 \ \mu m\)</span>; las dos curvas se traslapan en un 98.5% (OVL); el 51.5% (<span class="math inline">\(U_3\)</span>) de la muestra de <span class="math inline">\(&lt; 125 \ \mu m\)</span> se encuentra por encima de la media de la muestra de <span class="math inline">\(&lt; 25 \ \mu m\)</span>.</p>
</blockquote>
</div>
<div id="prueba-aov" class="section level2">
<h2><span class="header-section-number">15.8</span> ANOVA de 1-factor entre-grupos</h2>
<p>Hasta el momento solo se han analizado casos donde se tenían 1 o 2 muestras y se desean hacer inferencias sobre la media, pero en muchos casos se pueden llegar a tener 3 o más muestras.</p>
<p>Se podría pensar en realizar diferentes pruebas <span class="math inline">\(t\)</span> de dos muestras, pero esto genera dos problemas: primero, dependiendo de la cantidad de grupos el número de comparaciones sería muy grande, y segundo y más importante al realizar diferentes purbeas <span class="math inline">\(t\)</span> se va a inflar el error tipo-I (<span class="math inline">\(\alpha\)</span>), pudiendo incurrir en conclusiones equivocadas <span class="citation">(Nolan &amp; Heinzen, <a href="#ref-nolan2014">2014</a>)</span>.</p>
<p>La prueba del análisis de varianza (ANOVA - Analysis of Variance, en inglés), es una prueba que permite dilucidar la similitud entre muestras sin incurrir en los problemas antes mencionados, y la cual hace uso de la distribución y prueba <span class="math inline">\(F\)</span> para el análisis. La base teórica y procedimental que se va a exponer aquí se puede encontrar en <span class="citation">(Borradaile, <a href="#ref-borradaile2003">2003</a>; Davis, <a href="#ref-davis2002">2002</a>; McKillup &amp; Darby Dyar, <a href="#ref-mckillup2010">2010</a>; Nolan &amp; Heinzen, <a href="#ref-nolan2014">2014</a>; Swan &amp; Sandilands, <a href="#ref-swan1995">1995</a>; Walpole et al., <a href="#ref-walpole2012">2012</a>)</span></p>
<p>Una suposición de ANOVA es que las varianzas son iguales; esta prueba es relativamente robusta a esta suposición siempre y cuando la razón entre las varianzas mayor y menor no sea superior a 2. ANOVA es una técnica que permite diferentes diseños, pero en esta sección se presenta el caso más sencillo, el cual se conoce como ANOVA de 1 factor entre-grupos (between-groups ANOVA). Este diseño quiere decir que la variable de interés (numérica continua) está en función de una variable categórica (factor o tratamiento) con <span class="math inline">\(2+\)</span> grupos o clases. De hecho la prueba <span class="math inline">\(t\)</span> de 2 muestras independientes es un caso especial de ANOVA con 2 grupos, y se puede comprobar que <span class="math inline">\(F=t^2\)</span>.</p>
<p>De manera general las hipótesis nula y alterna serían:</p>
<ul>
<li><span class="math inline">\(H_0: \mu_1 = \mu_2 = \mu_3 = \cdots = \mu_k\)</span></li>
<li><span class="math inline">\(H_1: \text{Al menos 1 de las media es diferente}\)</span></li>
</ul>
<p>Para poder determinar el efecto de los diferentes grupos (muestras) en la variación de la media de la variable de interés, se puede pensar en que hay dos fuentes de variación: <strong>entre</strong> las muestras (Figura <a href="pruebas-estadísticas.html#fig:anova-entre">15.9</a>) y <strong>dentro</strong> de las muestras (Figura <a href="pruebas-estadísticas.html#fig:anova-dentro">15.10</a>).</p>
<div class="figure" style="text-align: center"><span id="fig:anova-entre"></span>
<img src="images/anova-entre.png" alt="Representación de la variación entre grupos. Conforme más separados estén y más distancia con respecto a la media general, mayor la variación." width="70%" />
<p class="caption">
Figura 15.9: Representación de la variación entre grupos. Conforme más separados estén y más distancia con respecto a la media general, mayor la variación.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:anova-dentro"></span>
<img src="images/anova-dentro.png" alt="Representación de la variación dentro de grupos. Conforme más dispersión haya en las muestras mayor la vriación dentro de lo grupos." width="70%" />
<p class="caption">
Figura 15.10: Representación de la variación dentro de grupos. Conforme más dispersión haya en las muestras mayor la vriación dentro de lo grupos.
</p>
</div>
<p>La variación entre grupos va a cuantificar la diferencia real entre las medias más el error (variación dentro de los grupos), por lo que de manera general se puede estimar este efecto por medio del estadístico <span class="math inline">\(F\)</span> a como se muestra en la Ecuación <a href="pruebas-estadísticas.html#eq:anova-F-gen">(15.17)</a>. Conforme mayor sea la diferencia entre los grupos mayor será el valor de <span class="math inline">\(F\)</span>, mientras que conforme más similares sean los grupos <span class="math inline">\(F \sim 1\)</span>. Para este caso la prueba <span class="math inline">\(F\)</span> va a ser siempre de una cola, donde hay un único valor crítico y la región de rechazo se encuentra a la derecha.</p>
<p><span class="math display" id="eq:anova-F-gen">\[\begin{equation}
  F = \frac{\text{variación entre grupos (diferencia + error)}}{\text{variación dentro de grupos (error)}}
  \tag{15.17}
\end{equation}\]</span></p>
<div class="figure" style="text-align: center"><span id="fig:anova-F"></span>
<img src="geolonum_files/figure-html/anova-F-1.png" alt="Representación de la distribución $F$, donde se muestra la región crítica o de rechazo en color rojo." width="70%" />
<p class="caption">
Figura 15.11: Representación de la distribución <span class="math inline">\(F\)</span>, donde se muestra la región crítica o de rechazo en color rojo.
</p>
</div>
<p>El resultado de ANOVA por lo general se presenta como una tabla, donde manera general lleva la estructura presentada en la Tabla <a href="pruebas-estadísticas.html#tab:anova-tabla">15.5</a>. El tamaño del efecto para ANOVA se puede obtener de los valores de la tabla: <span class="math inline">\(\eta^2=SCG/SCT\)</span>, donde <span class="math inline">\(SCT\)</span> es la suma de cuadrados total (<span class="math inline">\(SCT=SCG+SCE\)</span>) y corresponde con el porcentaje de variación en la variable respuesta explicado por el efecto de los grupos.</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:anova-tabla">Tabla 15.5: </span>Tabla de ANOVA
</caption>
<thead>
<tr>
<th style="text-align:center;">
Fuente de variación
</th>
<th style="text-align:center;">
Suma de cuadrados
</th>
<th style="text-align:center;">
Grados de liberta
</th>
<th style="text-align:center;">
Cuadrados medios
</th>
<th style="text-align:center;">
F
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
Entre grupos
</td>
<td style="text-align:center;">
<span class="math inline">\(SCG = \sum(\bar{x}_g-\bar{x}_T)^2 \cdot n_g\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(k-1\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(s_1^2 = \frac{\sum(\bar{x}_g-\bar{x}_T)^2 \cdot n_g}{k-1}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\frac{s_1^2}{s^2}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
Dentro de grupos (error)
</td>
<td style="text-align:center;">
<span class="math inline">\(SCE = \sum\sum(x_{ig}-\bar{x}_g)^2\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(N-k\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(s^2 = \frac{\sum\sum(x_{ig}-\bar{x}_g)^2}{N-k}\)</span>
</td>
<td style="text-align:center;">
</td>
</tr>
</tbody>
<tfoot>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<span style="font-style: italic;">Notas:</span>
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(\bar{x}_g\)</span> = media del grupo
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(\bar{x}_T\)</span> = media total (global)
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(x_{ig}\)</span> = valor <span class="math inline">\(i\)</span> del grupo <span class="math inline">\(g\)</span>
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(n_g\)</span> = tamaño del grupo <span class="math inline">\(g\)</span>
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(k\)</span> = número de grupos
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(N\)</span> = total de observaciones
</td>
</tr>
</tfoot>
</table>
<p>Cuando el resultado de la prueba de ANOVA es significativo esto indica que al menos uno de los grupos es diferente, pero no se sabe cuál. Para poder responder hay dos opciones:</p>
<ul>
<li>Si no se tiene idea o no se ha decidido con anterioridad de cuáles grupos se quieren comparar se puedeen realizar análisis posteriores (post-hoc) comparando todos los grupos, donde se ajusta para el error tipo-I. El post-hoc más utilizado es TukeyHSD (Honestly Significant Difference), pero existen otros como Bonferroni, Holm, Scheffe, etc.</li>
<li>Si se han decidido comparaciones (contrastes) <em>a priori</em> éstas son las que se analizan, pero debieron haberse especificado durante la planificación del estudio y antes de recolectar los datos.</li>
</ul>
<p>Para demostrar el ANOVA se usa un ejemplo de <span class="citation">McKillup &amp; Darby Dyar (<a href="#ref-mckillup2010">2010</a>)</span>, donde se tiene el contenido de <span class="math inline">\(MgO\)</span> presente en cuatro turmalinas en tres sitios diferentes: Mount Mica, Sebago Batholith, Black Mountain. Asuma <span class="math inline">\(\alpha=0.05\)</span>.</p>
<ol style="list-style-type: decimal">
<li>Identificar la población, distribución, y la prueba apropiada:
<ul>
<li>Población: contenido de <span class="math inline">\(MgO\)</span> presente en turmalinas en Mount Mica, Sebago Batholith, Black Mountain</li>
<li>Distribución: F</li>
<li>Prueba: <span class="math inline">\(F\)</span></li>
</ul></li>
<li>Establecer las hipótesis nula y alterna:
<ul>
<li><span class="math inline">\(H_0: \mu_1 = \mu_2 = \mu_3 \to\)</span> El contenido de <span class="math inline">\(MgO\)</span> presente en las turmalinas de los tres sitios es el mismo</li>
<li><span class="math inline">\(H_1:\)</span> El contenido de <span class="math inline">\(MgO\)</span> presente en las turmalinas difiere por lo menos en uno de los tres sitios</li>
</ul></li>
<li>Determinar parámetros de la distribución a comparar (<span class="math inline">\(H_0\)</span>):
<ul>
<li><span class="math inline">\(v_1 = k-1 = 3-1=2\)</span></li>
<li><span class="math inline">\(v_2 = N-k = 12-3 = 9\)</span></li>
</ul></li>
<li>Determinar valores críticos
<ul>
<li><span class="math inline">\(\alpha = 0.05\)</span></li>
<li><span class="math inline">\(F_{\alpha,v_1,v_2} = F_{0.05,2,9} = 4.256\)</span></li>
</ul></li>
<li>Calcular el estadístico de prueba
<ul>
<li><span class="math inline">\(F = \frac{36}{3.3} = 10.8\)</span></li>
<li>El procedimiento manual no se detalla aquí por ser más extenso y elaborado de lo normal, pero se recomienda al lector revisar las referencias mencionadas para detallarlo y entenderlo</li>
</ul></li>
<li>Tomar una decisión
<ul>
<li>El estadístico de prueba es mayor al crítico, <span class="math inline">\(F &gt; F_{\alpha,v_1,v_2}\)</span></li>
<li>El valor-<em>p</em> es menor a <span class="math inline">\(\alpha = 0.05\)</span>, <span class="math inline">\(p = 0.004\)</span></li>
<li><em>Decisión</em>: Se rechaza <span class="math inline">\(H_0\)</span> y por lo menos uno de los contenidos de <span class="math inline">\(MgO\)</span> es diferente</li>
</ul></li>
</ol>
<p>En <strong>R</strong> los datos tienen que estar en formato largo, lo que quiere decir una columna con los valores de la variable de interés, y otra columna con el grupo al que pertence la medición. Otro punto importante es que la variable agrupadora es mejor que sea del tipo <em>factor</em>.</p>
<p>Los datos del ejemplo se encuentran en el archivo <em>anova MgO.csv</em></p>
<pre class="sourceCode r"><code class="sourceCode r">a =<span class="st"> </span><span class="fl">0.05</span>
dat.aov =<span class="st"> </span><span class="kw">import</span>(<span class="st">&#39;data/anova MgO.csv&#39;</span>, <span class="dt">setclass =</span> <span class="st">&#39;tibble&#39;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Location =</span> <span class="kw">as.factor</span>(Location) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">           </span><span class="kw">fct_reorder</span>(MgO))
dat.aov</code></pre>
<pre><code>## # A tibble: 12 x 2
##    Location           MgO
##    &lt;fct&gt;            &lt;int&gt;
##  1 Mount Mica           7
##  2 Mount Mica           8
##  3 Mount Mica          10
##  4 Mount Mica          11
##  5 Sebago Batholith     4
##  6 Sebago Batholith     5
##  7 Sebago Batholith     7
##  8 Sebago Batholith     8
##  9 Black Mountain       1
## 10 Black Mountain       2
## 11 Black Mountain       4
## 12 Black Mountain       5</code></pre>
<p>Es recomendable hacer una inspección de los grupos, tanto numerica (Tabla <a href="pruebas-estadísticas.html#tab:mgo-resumen">15.6</a>) como gráfica, para darnos una idea de la media y desviaciones estándar. Aquí se observa que todos los grupos tienen la misma desviación estándar (algo poco comun), por lo que el supuesto de la homogeniedad de varianzas se mantiene.</p>
<pre class="sourceCode r"><code class="sourceCode r">dat.aov <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(Location) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarise_all</span>(<span class="kw">list</span>(<span class="dt">N =</span> <span class="op">~</span><span class="kw">n</span>(),
                     <span class="dt">Avg =</span> <span class="op">~</span><span class="kw">mean</span>(.),
                     <span class="dt">SD =</span> <span class="op">~</span><span class="kw">sd</span>(.)))</code></pre>
<table>
<caption>
<span id="tab:mgo-resumen">Tabla 15.6: </span>Resumen por grupo
</caption>
<thead>
<tr>
<th style="text-align:left;">
Location
</th>
<th style="text-align:right;">
N
</th>
<th style="text-align:right;">
Avg
</th>
<th style="text-align:right;">
SD
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Black Mountain
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
1.826
</td>
</tr>
<tr>
<td style="text-align:left;">
Sebago Batholith
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
6
</td>
<td style="text-align:right;">
1.826
</td>
</tr>
<tr>
<td style="text-align:left;">
Mount Mica
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
1.826
</td>
</tr>
</tbody>
</table>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(dat.aov, <span class="kw">aes</span>(Location, MgO)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">stat_summary</span>(<span class="dt">fun.data =</span> mean_cl_normal, 
               <span class="dt">fun.args =</span> <span class="kw">list</span>(<span class="dt">conf.int =</span> <span class="dv">1</span><span class="op">-</span>a), 
               <span class="dt">geom =</span> <span class="st">&#39;pointrange&#39;</span>, <span class="dt">size =</span> <span class="fl">.75</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x=</span><span class="st">&#39;&#39;</span>)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:mgo-ci"></span>
<img src="geolonum_files/figure-html/mgo-ci-1.png" alt="Medias e intervalos de confianza (95%) para cada grupo." width="70%" />
<p class="caption">
Figura 15.12: Medias e intervalos de confianza (95%) para cada grupo.
</p>
</div>
<p>Para realizar el ANOVA se puede hacer de diferentes maneras, pero de manera general se expresa como un modelo lineal <code>y ~ x</code>, donde <code>y</code> es la variable de interes y <code>x</code> es la variable agrupadora. Se pueden usar diferentes funciones, dentro de ellas <code>aov</code>, <code>lm</code>, donde siempre es necesario especificar la tabla de datos. La tabla resumen se muestra en la Tabla <a href="pruebas-estadísticas.html#tab:mgo-anova">15.7</a>, donde se puede confeccionar a partir de la función <code>anova</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">mgo.aov =<span class="st"> </span><span class="kw">aov</span>(MgO <span class="op">~</span><span class="st"> </span>Location, dat.aov)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(mgo.aov)</code></pre>
<table>
<caption>
<span id="tab:mgo-anova">Tabla 15.7: </span>Tabla de ANOVA para el ejemplo
</caption>
<thead>
<tr>
<th style="text-align:left;">
Variación
</th>
<th style="text-align:right;">
Grados libertad
</th>
<th style="text-align:right;">
Suma Cuadrados
</th>
<th style="text-align:right;">
Cuadrados Medios
</th>
<th style="text-align:right;">
F
</th>
<th style="text-align:right;">
Valor-<em>p</em>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Location
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
72
</td>
<td style="text-align:right;">
36.0000
</td>
<td style="text-align:right;">
10.8
</td>
<td style="text-align:right;">
0.0041
</td>
</tr>
<tr>
<td style="text-align:left;">
Residuals
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
30
</td>
<td style="text-align:right;">
3.3333
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
NA
</td>
</tr>
</tbody>
</table>
<p>El resultado es significativo, indicando que por lo menos uno de los contenidos de <span class="math inline">\(MgO\)</span> difiere del resto.</p>
<p>El tamaño del efecto <span class="math inline">\(\eta^2\)</span>, así como el intervalo de confianza, se puede obtener por medio de las funciones <code>eta.F</code> de <em>MOTE</em> y <code>eta_squared</code> de <em>effectsize</em>. Para <code>eta.F</code> es necesario indicar los grados de liberta, el valor de <span class="math inline">\(F\)</span>, y el nivel de significancia <span class="math inline">\(\alpha\)</span>. Para <code>eta_squared</code> lo que se necesita es el objeto de ANOVA y el nivel se confianza.</p>
<pre class="sourceCode r"><code class="sourceCode r">aov.eta =<span class="st"> </span><span class="kw">eta.F</span>(<span class="dt">dfm =</span> <span class="dv">2</span>, <span class="dt">dfe =</span> <span class="dv">9</span>, <span class="dt">Fvalue =</span> <span class="fl">10.8</span>, <span class="dt">a =</span> a)
aov.eta[<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">unlist</span>()</code></pre>
<pre><code>##       eta    etalow   etahigh 
## 0.7058824 0.1574104 0.8872368</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">eta_squared</span>(mgo.aov,<span class="dt">ci =</span> <span class="dv">1</span><span class="op">-</span>a)</code></pre>
<pre><code>## # A tibble: 1 x 5
##   Parameter Eta_Sq_partial    CI CI_low CI_high
##   &lt;chr&gt;              &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;
## 1 Location           0.706  0.95  0.193   0.859</code></pre>
<p>Como se encontró un resultdo significativo, es necesario indicar dónde se encuentran esas diferencias. Aquí no se definirieron contrastes <em>a priori</em>, por lo que se usa Tukey para ajustar el error tipo-I para todas las comparaciones. Se usa la función <code>TukeyHSD</code> donde los argumentos necesarios son el objeto de ANOVA y el nivel de confianza. Aquí se puede interpretar el valor-<em>p</em> con respecto al nivel de significancia escogido, ya que es un valor-<em>p</em> ajustado, de igual manera se puede interpretar el intervalo de confianza. El resumen de la prueba de Tukey se presenta en la Tabla <a href="pruebas-estadísticas.html#tab:mgo-tukey-resumen">15.8</a> y la Figura <a href="pruebas-estadísticas.html#fig:mgo-tukey-ci">15.13</a>.</p>
<pre class="sourceCode r"><code class="sourceCode r">tukey =<span class="st"> </span><span class="kw">TukeyHSD</span>(mgo.aov, 
                 <span class="dt">conf.level =</span> <span class="dv">1</span><span class="op">-</span>a) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">tidy</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw">select</span>(<span class="op">-</span>term)</code></pre>
<table>
<caption>
<span id="tab:mgo-tukey-resumen">Tabla 15.8: </span>Resumen de la prueba de Tukey
</caption>
<thead>
<tr>
<th style="text-align:left;">
Comparación
</th>
<th style="text-align:right;">
Diferencia
</th>
<th style="text-align:right;">
<span class="math inline">\(IC_{inf}\)</span>
</th>
<th style="text-align:right;">
<span class="math inline">\(IC_{sup}\)</span>
</th>
<th style="text-align:right;">
Valor-<em>p</em> ajustado
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Sebago Batholith-Black Mountain
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
-0.604
</td>
<td style="text-align:right;">
6.604
</td>
<td style="text-align:right;">
0.103
</td>
</tr>
<tr>
<td style="text-align:left;">
Mount Mica-Black Mountain
</td>
<td style="text-align:right;">
6
</td>
<td style="text-align:right;">
2.396
</td>
<td style="text-align:right;">
9.604
</td>
<td style="text-align:right;">
0.003
</td>
</tr>
<tr>
<td style="text-align:left;">
Mount Mica-Sebago Batholith
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
-0.604
</td>
<td style="text-align:right;">
6.604
</td>
<td style="text-align:right;">
0.103
</td>
</tr>
</tbody>
</table>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(tukey, <span class="kw">aes</span>(comparison, estimate, 
                  <span class="dt">ymin =</span> conf.low, <span class="dt">ymax =</span> conf.high)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_pointrange</span>(<span class="dt">size =</span> <span class="dv">1</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="dv">0</span>, <span class="dt">col =</span> <span class="st">&#39;red&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_flip</span>() <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">theme_bw</span>() <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">y =</span> <span class="st">&#39;Diferencia en medias&#39;</span>, <span class="dt">x =</span> <span class="st">&#39;Comparacion&#39;</span>)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:mgo-tukey-ci"></span>
<img src="geolonum_files/figure-html/mgo-tukey-ci-1.png" alt="Intervalos de confianza (95%) para las comparaciones usando la prueba de Tukey." width="70%" />
<p class="caption">
Figura 15.13: Intervalos de confianza (95%) para las comparaciones usando la prueba de Tukey.
</p>
</div>
<blockquote>
<p>Conclusión: El contenido de <span class="math inline">\(MgO\)</span> varía significativamentre entre las localidades, <span class="math inline">\(F\)</span>(2, 9) = 10.80, <span class="math inline">\(p\)</span> = .004. El tamano del efecto es grande, <span class="math inline">\(\eta^2\)</span> = 0.71, 95% IC [0.16, 0.89], pero con un rango muy amplio. Analisis posteriores con Tukey HSD indican que hay una diferencia entre Mount Mica - Black Mountain (<em>p</em> = .003), pero no asi entre Mount Mica - Sebago Batholit (<em>p</em> = .103), ni Sebago Batholith - Black Mountain (<em>p</em> = .103).</p>
</blockquote>
</div>
<div id="prueba-t-cor" class="section level2">
<h2><span class="header-section-number">15.9</span> <span class="math inline">\(t\)</span> de correlación</h2>
<p>En la sección de <a href="estadística-descriptiva-bivariable.html#bivar-cor">Correlación</a> (<a href="estadística-descriptiva-bivariable.html#bivar-cor">10.3</a>) se introdujo el concepto de correlación, más específicamente la correlación de Pearson. Esta es una medida de asosiación entre dos variables (en este caso numéricas) que indica la magnitud y dirección de dicha asociación. La idea de la prueba para la correlación es determinar si la correlación encontrada es significativa o no, o sea, si difiere de cero <span class="citation">(Borradaile, <a href="#ref-borradaile2003">2003</a>; Davis, <a href="#ref-davis2002">2002</a>; Nolan &amp; Heinzen, <a href="#ref-nolan2014">2014</a>; Swan &amp; Sandilands, <a href="#ref-swan1995">1995</a>; Trauth, <a href="#ref-trauth2015">2015</a>)</span>.</p>
<p>El uso de la prueba <span class="math inline">\(t\)</span> de correlación se realiza con un ejemplo de <span class="citation">Davis (<a href="#ref-davis2002">2002</a>)</span>, donde se tiene la longitud de los ejes de cantos en una playa (Tabla <a href="pruebas-estadísticas.html#tab:cantos-playa">15.9</a>). Se quiere determinar si la correlación entre los ejes <span class="math inline">\(a\)</span> y <span class="math inline">\(b\)</span> es significativa, asumiendo <span class="math inline">\(\alpha = 0.1\)</span>.</p>
<table>
<caption>
<span id="tab:cantos-playa">Tabla 15.9: </span>Longitudes de los ejes de cantos en una playa
</caption>
<thead>
<tr>
<th style="text-align:center;">
Canto
</th>
<th style="text-align:center;">
Eje-a
</th>
<th style="text-align:center;">
Eje-b
</th>
<th style="text-align:center;">
Eje-c
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
8
</td>
<td style="text-align:center;">
7
</td>
<td style="text-align:center;">
3
</td>
</tr>
<tr>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
16
</td>
<td style="text-align:center;">
8
</td>
<td style="text-align:center;">
5
</td>
</tr>
<tr>
<td style="text-align:center;">
3
</td>
<td style="text-align:center;">
12
</td>
<td style="text-align:center;">
10
</td>
<td style="text-align:center;">
9
</td>
</tr>
<tr>
<td style="text-align:center;">
4
</td>
<td style="text-align:center;">
13
</td>
<td style="text-align:center;">
12
</td>
<td style="text-align:center;">
5
</td>
</tr>
<tr>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
16
</td>
<td style="text-align:center;">
14
</td>
<td style="text-align:center;">
5
</td>
</tr>
<tr>
<td style="text-align:center;">
6
</td>
<td style="text-align:center;">
14
</td>
<td style="text-align:center;">
9
</td>
<td style="text-align:center;">
8
</td>
</tr>
<tr>
<td style="text-align:center;">
7
</td>
<td style="text-align:center;">
16
</td>
<td style="text-align:center;">
13
</td>
<td style="text-align:center;">
13
</td>
</tr>
<tr>
<td style="text-align:center;">
8
</td>
<td style="text-align:center;">
11
</td>
<td style="text-align:center;">
6
</td>
<td style="text-align:center;">
3
</td>
</tr>
<tr>
<td style="text-align:center;">
9
</td>
<td style="text-align:center;">
15
</td>
<td style="text-align:center;">
9
</td>
<td style="text-align:center;">
9
</td>
</tr>
<tr>
<td style="text-align:center;">
10
</td>
<td style="text-align:center;">
13
</td>
<td style="text-align:center;">
10
</td>
<td style="text-align:center;">
9
</td>
</tr>
</tbody>
<tfoot>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> Fuente: <span class="citation">Davis (<a href="#ref-davis2002">2002</a>)</span>
</td>
</tr>
</tfoot>
</table>
<ol style="list-style-type: decimal">
<li>Identificar la población, distribución, y la prueba apropiada:
<ul>
<li>Población: relación entre ejes <span class="math inline">\(a\)</span> y <span class="math inline">\(b\)</span></li>
<li>Distribución: de correlaciones</li>
<li>Prueba: <span class="math inline">\(t\)</span> de correlación</li>
</ul></li>
<li>Establecer las hipótesis nula y alterna:
<ul>
<li><span class="math inline">\(H_0: \rho = 0 \to\)</span> No hay relación entre los ejes</li>
<li><span class="math inline">\(H_1: \rho \neq 0 \to\)</span> Hay una relación entre los ejes</li>
<li><em>Nota</em>: <span class="math inline">\(\rho\)</span> es el parámetro poblacional para la correlación</li>
</ul></li>
<li>Determinar parámetros de la distribución a comparar (<span class="math inline">\(H_0\)</span>):
<ul>
<li><span class="math inline">\(r_{a,b} = 0.597\)</span></li>
<li><span class="math inline">\(v = N-2 = 10-2 = 8\)</span></li>
<li>Aquí el único parámetro del que depende la prueba son los grados de libertad <span class="math inline">\(v\)</span>, pero se muestra el valor de <span class="math inline">\(r\)</span> encontrado</li>
</ul></li>
<li>Determinar valores críticos
<ul>
<li><span class="math inline">\(\alpha = 0.1\)</span></li>
<li><span class="math inline">\(t_{\alpha/2,v} = t_{0.1/2,8} = |1.860|\)</span></li>
</ul></li>
<li>Calcular el estadístico de prueba
<ul>
<li><span class="math inline">\(t = \frac{r \sqrt{v}}{\sqrt{1-r^2}} = \frac{0.597 \cdot \sqrt{8}}{\sqrt{1-0.597^2}} = 2.10\)</span></li>
<li><span class="math inline">\(90\% \ IC \ [0.066,0.864]\)</span></li>
</ul></li>
<li>Tomar una decisión
<ul>
<li>El estadístico de prueba es mayor al crítico, <span class="math inline">\(t &gt; t_{\alpha/2,v}\)</span></li>
<li>El valor-<em>p</em> es menor a <span class="math inline">\(\alpha = 0.1\)</span>, <span class="math inline">\(p = 0.068\)</span></li>
<li>El valor de <span class="math inline">\(0\)</span> no cae dentro del intervalo de confianza, <span class="math inline">\(IC \ [0.0108,0.189]\)</span></li>
<li><em>Decisión</em>: Se rechaza <span class="math inline">\(H_0\)</span></li>
<li><em>Nota</em>: Tomar en cuenta que si se escogiera <span class="math inline">\(\alpha=0.05\)</span>, no se rechazaría <span class="math inline">\(H_0\)</span></li>
</ul></li>
</ol>
<p>En <strong>R</strong> así como está la función <code>cor</code> para calcular el coeficiente de correlación, se tiene la función <code>cor.test</code> para la prueba específica. Se pueden especificar el típo de correlación (<code>method</code>) y el nivel de significancia. El coeficiente de correlación es ya un tamaño de efecto, por lo que no es necesario realizar ningun cálculo adicional.</p>
<pre class="sourceCode r"><code class="sourceCode r">cantos =<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">Canto =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">10</span>,
                <span class="dt">a =</span> <span class="kw">c</span>(<span class="dv">8</span>,<span class="dv">16</span>,<span class="dv">12</span>,<span class="dv">13</span>,<span class="dv">16</span>,<span class="dv">14</span>,<span class="dv">16</span>,<span class="dv">11</span>,<span class="dv">15</span>,<span class="dv">13</span>),
                <span class="dt">b =</span> <span class="kw">c</span>(<span class="dv">7</span>,<span class="dv">8</span>,<span class="dv">10</span>,<span class="dv">12</span>,<span class="dv">14</span>,<span class="dv">9</span>,<span class="dv">13</span>,<span class="dv">6</span>,<span class="dv">9</span>,<span class="dv">10</span>),
                <span class="dt">c =</span> <span class="kw">c</span>(<span class="dv">3</span>,<span class="dv">5</span>,<span class="dv">9</span>,<span class="dv">5</span>,<span class="dv">5</span>,<span class="dv">8</span>,<span class="dv">13</span>,<span class="dv">3</span>,<span class="dv">9</span>,<span class="dv">9</span>))
a =<span class="st"> </span><span class="fl">0.1</span>

r.res =<span class="st"> </span><span class="kw">cor.test</span>(<span class="op">~</span>a<span class="op">+</span>b,<span class="dt">data =</span> cantos,
                 <span class="dt">method =</span> <span class="st">&#39;pearson&#39;</span>,
                 <span class="dt">conf.level =</span> <span class="dv">1</span><span class="op">-</span>a)
r.res</code></pre>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  a and b
## t = 2.1031, df = 8, p-value = 0.06861
## alternative hypothesis: true correlation is not equal to 0
## 90 percent confidence interval:
##  0.0661825 0.8641924
## sample estimates:
##       cor 
## 0.5966799</code></pre>
<blockquote>
<p>Conclusión: Los ejes <span class="math inline">\(a\)</span> y <span class="math inline">\(b\)</span> están correlacionados, <span class="math inline">\(r = .60\)</span>, 90% IC <span class="math inline">\([.07\)</span>, <span class="math inline">\(.86]\)</span>, <span class="math inline">\(t(8) = 2.10\)</span>, <span class="math inline">\(p = .069\)</span>. El efecto se puede considerar grande, con un rango de pequeño, hasta muy grande.</p>
</blockquote>
</div>
<div id="prueba-chi" class="section level2">
<h2><span class="header-section-number">15.10</span> <span class="math inline">\(\chi^2\)</span> para 1 varianza</h2>
<p>Así como se pueden realizar pruebas estadísticas sobre la media poblacional (<span class="math inline">\(\mu\)</span>), se pueden realizar pruebas estadísticas sobre la varianza poblacional (<span class="math inline">\(\sigma^2\)</span>), aunque son menos comunes. Por esto último es que para estas pruebas no hay tamaños de efecto estandarizados, sino más bien se usan los datos en escala original.</p>
<p>El uso de la prueba <span class="math inline">\(\chi^2\)</span> de 1 muestra se realiza con el ejemplo de la sección <a href="estimación-e-hipótesis.html#estim-ic-chi">14.2.3</a> <span class="citation">(Swan &amp; Sandilands, <a href="#ref-swan1995">1995</a>)</span>, donde se tenía el contenido de cuarzo en secciones delgadas de una roca ígnea. Es posible que esta muestra provenga de una población con varianza 12 (<span class="math inline">\(\sigma^2_0=12\)</span>)? Asuma <span class="math inline">\(\alpha = 0.05\)</span>.</p>
<ol style="list-style-type: decimal">
<li>Identificar la población, distribución, y la prueba apropiada:
<ul>
<li>Población: variabilidad del contenido de cuarzo en la roca ígnea</li>
<li>Distribución: de varianza</li>
<li>Prueba: <span class="math inline">\(\chi^2\)</span> de 1 muestra porque se tiene 1 muestra, se quiere hacer inferencia sobre la variabilidad, y se quiere comparar con un valor hipotético</li>
</ul></li>
<li>Establecer las hipótesis nula y alterna:
<ul>
<li><span class="math inline">\(H_0: \sigma^2 = \sigma^2_0 \to\)</span> La variabilidad en el contenido de cuarzo en la roca ígnea es <em>igual</em> a un valor hipotético o conocido (12)</li>
<li><span class="math inline">\(H_1: \sigma^2 \neq \sigma^2_0 \to\)</span> La variabilidad en el contenido de cuarzo en la roca ígnea es <em>diferente</em> a un valor hipotético o conocido (12)</li>
</ul></li>
<li>Determinar parámetros de la distribución a comparar (<span class="math inline">\(H_0\)</span>):
<ul>
<li><span class="math inline">\(\sigma^2_0 = 20\)</span></li>
<li><span class="math inline">\(v = N-1 = 8-1 = 7\)</span></li>
</ul></li>
<li>Determinar valores críticos
<ul>
<li><span class="math inline">\(\alpha = 0.05\)</span></li>
<li><span class="math inline">\(\chi^2_{\alpha/2,v} = \chi^2_{0.05/2,7} = 12.83\)</span></li>
<li><span class="math inline">\(\chi^2_{1-\alpha/2,v} = \chi^2_{1-0.05/2,7} = 0.83\)</span></li>
</ul></li>
<li>Calcular el estadístico de prueba
<ul>
<li><span class="math inline">\(\chi^2 = \frac{(n-1)s^2}{\sigma_0^2} = \frac{(8-1)9.507}{12} = 5.546\)</span></li>
<li><span class="math inline">\(4.16 &lt; \sigma^2 &lt; 39.38 \to 95\% \ IC \ [4.16,39.38]\)</span></li>
</ul></li>
<li>Tomar una decisión
<ul>
<li>El estadístico de prueba cae entre los valores críticos</li>
<li>El valor-<em>p</em> es mayor a <span class="math inline">\(\alpha = 0.05\)</span>, <span class="math inline">\(p = 0.8127\)</span></li>
<li>El valor hipotético del parámetro cae dentro del intervalo de confianza, <span class="math inline">\(IC \ [4.16, 39.38]\)</span></li>
<li><em>Decisión</em>: No se rechaza <span class="math inline">\(H_0\)</span></li>
</ul></li>
</ol>
<p>En <strong>R</strong> el paquete <em>DescTools</em> trae la función <code>VarTest</code> para realizar esta prueba, donde ocupa brindar el vector de datos, la varianza poblacional (<code>sigma.squared</code>), y el nivel de confianza.</p>
<pre class="sourceCode r"><code class="sourceCode r">sigma0 =<span class="st"> </span><span class="dv">12</span>
a =<span class="st"> </span><span class="fl">0.05</span>

cuarzo =<span class="st"> </span><span class="kw">c</span>(<span class="fl">23.5</span>, <span class="fl">16.6</span>, <span class="fl">25.4</span>, <span class="fl">19.1</span>, <span class="fl">19.3</span>, <span class="fl">22.4</span>, <span class="fl">20.9</span>, <span class="fl">24.9</span>)
n =<span class="st"> </span><span class="kw">length</span>(cuarzo)

chi.res =<span class="st"> </span><span class="kw">VarTest</span>(<span class="dt">x =</span> cuarzo, 
                  <span class="dt">sigma.squared =</span> sigma0,
                  <span class="dt">conf.level =</span> <span class="dv">1</span><span class="op">-</span>a)
chi.res</code></pre>
<pre><code>## 
##  One Sample Chi-Square test on variance
## 
## data:  cuarzo
## X-squared = 5.5457, df = 7, p-value = 0.8127
## alternative hypothesis: true variance is not equal to 12
## 95 percent confidence interval:
##   4.155981 39.381007
## sample estimates:
## variance of x 
##      9.506964</code></pre>
<blockquote>
<p>Conclusión: La variabilidad del contenido de cuarzo no difiere significativamente del valor propuesto, <span class="math inline">\(s^2 = 9.51\)</span>, 95% IC <span class="math inline">\([4.16\)</span>, <span class="math inline">\(39.38]\)</span>, <span class="math inline">\(\chi^2(7, n = 8) = 5.55\)</span>, <span class="math inline">\(p = .813\)</span>.</p>
</blockquote>
</div>
<div id="prueba-f" class="section level2">
<h2><span class="header-section-number">15.11</span> <span class="math inline">\(F\)</span> para 2 varianzas</h2>
<p>En algunas de las pruebas se hace la suposicion de igualdad de varianzas. Lo anterior se puede evaluar empiricamente comparando la menor y mayor desviacion estandar, donde la relacion entre ellas no debiera ser mayor a 2 <span class="citation">(Cumming &amp; Calin-Jageman, <a href="#ref-cumming2017">2017</a>)</span>. Si se quiere realizar de manera formal se puede realizar la prueba aqui descrita.</p>
<p>El uso de la prueba <span class="math inline">\(F\)</span> para 2 varianzas se realiza con el ejemplo de la sección <a href="pruebas-estadísticas.html#prueba-t2-ind">15.6</a> <span class="citation">(Swan &amp; Sandilands, <a href="#ref-swan1995">1995</a>)</span>, donde se tenían braquiópodos en dos capas (A, B) y se les midió la longitud (cm). Es factible la suposicion de igualdad de varianzas (<span class="math inline">\(\sigma^2_1=\sigma^2_2\)</span>)? Asuma <span class="math inline">\(\alpha = 0.05\)</span>.</p>
<ol style="list-style-type: decimal">
<li>Identificar la población, distribución, y la prueba apropiada:
<ul>
<li>Población: variabilidad de la longitud de braquiopodos en las capas A y B</li>
<li>Distribución: de razon de varianzas (<span class="math inline">\(F\)</span>)</li>
<li>Prueba: <span class="math inline">\(F\)</span> para 2 muestras (varianzas), se quiere hacer inferencia sobre la variabilidad, y se quieren comparar las varianzas de 2 muestras</li>
</ul></li>
<li>Establecer las hipótesis nula y alterna:
<ul>
<li><span class="math inline">\(H_0: \sigma^2_1 = \sigma^2_2, \ \frac{\sigma^2_1}{\sigma^2_2} = 1 \to\)</span> La variabilidad la longitud de braquiopodos de la capa A es <em>igual</em> a la variabilidad la longitud de braquiopodos de la capa B</li>
<li><span class="math inline">\(H_1: \sigma^2_1 \neq \sigma^2_2, \ \frac{\sigma^2_1}{\sigma^2_2} \neq 1 \to\)</span> La variabilidad la longitud de braquiopodos de la capa A es <em>diferente</em> a la variabilidad la longitud de braquiopodos de la capa B</li>
</ul></li>
<li>Determinar parámetros de la distribución a comparar (<span class="math inline">\(H_0\)</span>):
<ul>
<li><span class="math inline">\(v_1 = n_1-1 = 8-1 = 7\)</span></li>
<li><span class="math inline">\(v_2 = n_2-1 = 10-1 = 9\)</span></li>
</ul></li>
<li>Determinar valores críticos
<ul>
<li><span class="math inline">\(\alpha = 0.05\)</span></li>
<li><span class="math inline">\(F_{\alpha/2,v_1,v_2} = F_{0.05/2,8,10} = 3.85\)</span></li>
<li><span class="math inline">\(F_{1-\alpha/2,v_1,v_2} = F_{1-0.05/2,8,10} = 0.23\)</span></li>
</ul></li>
<li>Calcular el estadístico de prueba
<ul>
<li><span class="math inline">\(\frac{\sigma^2_1}{\sigma^2_2} = \frac{0.042}{0.029} = 1.45\)</span></li>
<li><span class="math inline">\(0.345 &lt; \frac{\sigma^2_1}{\sigma^2_2} &lt; 6.985 \to 95\% \ IC \ [0.345,6.985]\)</span></li>
</ul></li>
<li>Tomar una decisión
<ul>
<li>El estadístico de prueba cae entre los valores críticos</li>
<li>El valor-<em>p</em> es mayor a <span class="math inline">\(\alpha = 0.05\)</span>, <span class="math inline">\(p = 0.599\)</span></li>
<li>El valor hipotético del parámetro (1) cae dentro del intervalo de confianza, <span class="math inline">\(IC \ [0.345, 6.985]\)</span></li>
<li><em>Decisión</em>: No se rechaza <span class="math inline">\(H_0\)</span></li>
</ul></li>
</ol>
<p>En <strong>R</strong> la función <code>var.test</code> para realizar esta prueba, donde se ocupan brindar los vectores de datos, la razon de varianzas (<code>ratio</code>), y el nivel de confianza.</p>
<pre class="sourceCode r"><code class="sourceCode r">a =<span class="st"> </span><span class="fl">0.05</span>

f.res =<span class="st"> </span><span class="kw">var.test</span>(<span class="dt">x =</span> A,<span class="dt">y =</span> B,
                 <span class="dt">ratio =</span> <span class="dv">1</span>,
                 <span class="dt">conf.level =</span> <span class="dv">1</span><span class="op">-</span>a)
f.res</code></pre>
<pre><code>## 
##  F test to compare two variances
## 
## data:  A and B
## F = 1.4367, num df = 7, denom df = 9, p-value = 0.5994
## alternative hypothesis: true ratio of variances is not equal to 1
## 95 percent confidence interval:
##  0.3423094 6.9294596
## sample estimates:
## ratio of variances 
##           1.436688</code></pre>
<blockquote>
<p>Conclusión: La variabilidad de la longitud de los braquiopodos en las capas A y B no varia significativamente, <span class="math inline">\(\text{razon de varianzas} = 1.44\)</span>, 95% IC <span class="math inline">\([0.34\)</span>, <span class="math inline">\(6.93]\)</span>, <span class="math inline">\(F(7, 9) = 1.44\)</span>, <span class="math inline">\(p = .599\)</span>.</p>
</blockquote>

</div>
</div>
<h3>Referencias</h3>
<div id="refs" class="references">
<div id="ref-americanpsychologicalassociation2010">
<p>American Psychological Association. (2010). <em>Publication Manual of the American Psychological Association</em> (6.ª ed.).</p>
</div>
<div id="ref-R-effectsize">
<p>Ben-Shachar, M. S., Makowski, D., &amp; Lüdecke, D. (2020). <em>effectsize: Indices of Effect Size and Standardized Parameters</em>. <a href="https://CRAN.R-project.org/package=effectsize">https://CRAN.R-project.org/package=effectsize</a></p>
</div>
<div id="ref-borradaile2003">
<p>Borradaile, G. J. (2003). <em>Statistics of Earth Science Data: Their Distribution in Time, Space and Orientation</em>. Springer-Verlag Berlin Heidelberg.</p>
</div>
<div id="ref-R-MOTE">
<p>Buchanan, E. M., Gillenwaters, A. M., Scofield, J. E., &amp; Valentine, K. D. (2019). <em>MOTE: Effect Size and Confidence Interval Calculator</em>. <a href="https://CRAN.R-project.org/package=MOTE">https://CRAN.R-project.org/package=MOTE</a></p>
</div>
<div id="ref-cohen1988">
<p>Cohen, J. (1988). <em>Statistical Power Analysis for the Behavioral Sciences</em> (2.ª ed.). Erlbaum.</p>
</div>
<div id="ref-cumming2012">
<p>Cumming, G. (2012). <em>Understanding The New Statistics - Effect Sizes, Confidence Intervals, and Meta-Analysis</em>. Rutledge.</p>
</div>
<div id="ref-cumming2017">
<p>Cumming, G., &amp; Calin-Jageman, R. (2017). <em>Introduction to the New Statistics: Estimation, Open Science, and Beyond</em>. Rutledge.</p>
</div>
<div id="ref-cumming2005ap">
<p>Cumming, G., &amp; Finch, S. (2005). Inference by Eye: Confidence Intervals and How to Read Pictures of Data. <em>American Psychologist</em>, <em>60</em>(2), 170-180. <a href="https://doi.org/10.1037/0003-066X.60.2.170">https://doi.org/10.1037/0003-066X.60.2.170</a></p>
</div>
<div id="ref-davis2002">
<p>Davis, J. C. (2002). <em>Statistics and Data Analysis in Geology</em> (3.ª ed.). John Woley &amp; Sons.</p>
</div>
<div id="ref-ellis2010">
<p>Ellis, P. D. (2010). <em>The Essential Guide to Effect Sizes : Statistical Power, Meta-Analysis, and the Interpretation of Research Results</em>. Cambridge University Press.</p>
</div>
<div id="ref-R-itns">
<p>Erceg-Hurn, D., Cumming, G., &amp; Calin-Jageman, R. (2017). <em>itns: Datasets from the book Introduction to the New Statistics</em>.</p>
</div>
<div id="ref-fritz2012joepg">
<p>Fritz, C. O., Morris, P. E., &amp; Richler, J. J. (2012). Effect size estimates: Current use, calculations, and interpretation. <em>Journal of Experimental Psychology: General</em>, <em>141</em>(1), 2-18. <a href="https://doi.org/10.1037/a0024338">https://doi.org/10.1037/a0024338</a></p>
</div>
<div id="ref-grissom2005">
<p>Grissom, R. J., &amp; Kim, J. J. (2005). <em>Effect Sizes for Research: A Broad Practical Approach</em>. Erlbaum.</p>
</div>
<div id="ref-hedges1985">
<p>Hedges, L. V., &amp; Olkin, I. (1985). <em>Statistical Methods for Meta-Analysis</em>. Academic Press.</p>
</div>
<div id="ref-lakens2013fp">
<p>Lakens, D. (2013). Calculating and reporting effect sizes to facilitate cumulative science: A practical primer for t-tests and ANOVAs. <em>Frontiers in Psychology</em>, <em>4</em>. <a href="https://doi.org/10.3389/fpsyg.2013.00863">https://doi.org/10.3389/fpsyg.2013.00863</a></p>
</div>
<div id="ref-magnusson2020">
<p>Magnusson, K. (2020). <em>Interpreting Cohen’s d Effect Size: An Interactive Visualization</em> (Versión 2.1.1) [Computer software]. <a href="https://rpsychologist.com/d3/cohend/">https://rpsychologist.com/d3/cohend/</a></p>
</div>
<div id="ref-mcgrath2006pm">
<p>McGrath, R. E., &amp; Meyer, G. J. (2006). When effect sizes disagree: The case of r and d. <em>Psychological Methods</em>, <em>11</em>(4), 386-401. <a href="https://doi.org/10.1037/1082-989X.11.4.386">https://doi.org/10.1037/1082-989X.11.4.386</a></p>
</div>
<div id="ref-mcgraw1992pb">
<p>McGraw, K. O., &amp; Wong, S. P. (1992). A Common Language Effect Size Statistic. <em>Psychonomic Bulletin</em>, <em>111</em>(2), 361-365.</p>
</div>
<div id="ref-mckillup2010">
<p>McKillup, S., &amp; Darby Dyar, M. (2010). <em>Geostatistics Explained: An Introductory Guide for Earth Scientists</em>. Cambridge University Press. <a href="www.cambridge.org/9780521763226">www.cambridge.org/9780521763226</a></p>
</div>
<div id="ref-nakagawa2007br">
<p>Nakagawa, S., &amp; Cuthill, I. C. (2007). Effect size, confidence interval and statistical significance: A practical guide for biologists. <em>Biological Reviews</em>, <em>82</em>(4), 591-605. <a href="https://doi.org/10.1111/j.1469-185X.2007.00027.x">https://doi.org/10.1111/j.1469-185X.2007.00027.x</a></p>
</div>
<div id="ref-nolan2014">
<p>Nolan, S. A., &amp; Heinzen, T. E. (2014). <em>Statistics for the Behavioral Sciences</em> (3.ª ed.). Worth Publishers.</p>
</div>
<div id="ref-reiser1999jrss">
<p>Reiser, B., &amp; Faraggi, D. (1999). Confidence intervals for the overlapping coefficient: The normal equal variance case. <em>Journal of the Royal Statistical Society</em>, <em>48</em>(3), 413-418.</p>
</div>
<div id="ref-R-psych">
<p>Revelle, W. (2020). <em>psych: Procedures for Psychological, Psychometric, and Personality Research</em>. <a href="https://CRAN.R-project.org/package=psych">https://CRAN.R-project.org/package=psych</a></p>
</div>
<div id="ref-ruscio2008pm">
<p>Ruscio, J. (2008). A probability-based measure of effect size: Robustness to base rates and other factors. <em>Psychological Methods</em>, <em>13</em>(1), 19-30. <a href="https://doi.org/10.1037/1082-989X.13.1.19">https://doi.org/10.1037/1082-989X.13.1.19</a></p>
</div>
<div id="ref-swan1995">
<p>Swan, A., &amp; Sandilands, M. (1995). <em>Introduction to Geological Data Analysis</em>. Blackwell Science.</p>
</div>
<div id="ref-thompson2007ps">
<p>Thompson, B. (2007). Effect sizes, confidence intervals, and confidence intervals for effect sizes. <em>Psychology in the Schools</em>, <em>44</em>(5), 423-432. <a href="https://doi.org/10.1002/pits.20234">https://doi.org/10.1002/pits.20234</a></p>
</div>
<div id="ref-tomczak2014tss">
<p>Tomczak, M., &amp; Tomczak, E. (2014). The need to report effect size estimates revisited. An overview of some recommended measures of effect size. <em>Trends in Sport Sciences</em>, <em>1</em>(21), 19-25.</p>
</div>
<div id="ref-R-effsize">
<p>Torchiano, M. (2018). <em>effsize: Efficient Effect Size Computation</em>. <a href="https://CRAN.R-project.org/package=effsize">https://CRAN.R-project.org/package=effsize</a></p>
</div>
<div id="ref-trauth2015">
<p>Trauth, M. (2015). <em>MATLAB® Recipes for Earth Sciences</em> (4.ª ed.). Springer-Verlag Berlin Heidelberg.</p>
</div>
<div id="ref-triola2004">
<p>Triola, M. F. (2004). <em>Probabilidad y Estadística</em> (9.ª ed.). Pearson Educación.</p>
</div>
<div id="ref-walpole2012">
<p>Walpole, R. E., Myers, R. H., &amp; Myers, S. L. (2012). <em>Probabilidad y Estadística Para Ingeniería y Ciencias</em>. Pearson.</p>
</div>
<div id="ref-zou2007pm">
<p>Zou, G. Y. (2007). Toward using confidence intervals to compare correlations. <em>Psychological Methods</em>, <em>12</em>(4), 399-413. <a href="https://doi.org/10.1037/1082-989X.12.4.399">https://doi.org/10.1037/1082-989X.12.4.399</a></p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="estimación-e-hipótesis.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="estadística-no-paramétrica.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
