<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="es" xml:lang="es">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 15 Pruebas Estadísticas | Geología Numérica: Ciencia de Datos para Geociencias</title>
  <meta name="description" content="Este documento compila el funcionamiento básico del software estadístico y de programación R, así como rutinas y/o comandos específicos para resolver problemas de análisis de datos en geociencias." />
  <meta name="generator" content="bookdown 0.11 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 15 Pruebas Estadísticas | Geología Numérica: Ciencia de Datos para Geociencias" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Este documento compila el funcionamiento básico del software estadístico y de programación R, así como rutinas y/o comandos específicos para resolver problemas de análisis de datos en geociencias." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 15 Pruebas Estadísticas | Geología Numérica: Ciencia de Datos para Geociencias" />
  
  <meta name="twitter:description" content="Este documento compila el funcionamiento básico del software estadístico y de programación R, así como rutinas y/o comandos específicos para resolver problemas de análisis de datos en geociencias." />
  

<meta name="author" content="Maximiliano Garnier Villarreal" />


<meta name="date" content="2020-07-24" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="estimación-e-hipótesis.html">
<link rel="next" href="estadística-no-paramétrica.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.5.1/htmlwidgets.js"></script>
<link href="libs/dygraphs-1.1.1/dygraph.css" rel="stylesheet" />
<script src="libs/dygraphs-1.1.1/dygraph-combined.js"></script>
<script src="libs/dygraphs-1.1.1/shapes.js"></script>
<script src="libs/moment-2.8.4/moment.js"></script>
<script src="libs/moment-timezone-0.2.5/moment-timezone-with-data.js"></script>
<script src="libs/moment-fquarter-1.0.0/moment-fquarter.min.js"></script>
<script src="libs/dygraphs-binding-1.1.1.6/dygraphs.js"></script>
<script src="libs/plotly-binding-4.9.2/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-1.52.2/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-1.52.2/plotly-latest.min.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.11/datatables.js"></script>
<link href="libs/dt-core-1.10.19/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.19/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.19/js/jquery.dataTables.min.js"></script>
<link href="libs/nouislider-7.0.10/jquery.nouislider.min.css" rel="stylesheet" />
<script src="libs/nouislider-7.0.10/jquery.nouislider.min.js"></script>
<link href="libs/selectize-0.12.0/selectize.bootstrap3.css" rel="stylesheet" />
<script src="libs/selectize-0.12.0/selectize.min.js"></script>
<script src="libs/proj4js-2.3.15/proj4.js"></script>
<link href="libs/highcharts-7.0.1/css/motion.css" rel="stylesheet" />
<link href="libs/highcharts-7.0.1/css/htmlwdgtgrid.css" rel="stylesheet" />
<script src="libs/highcharts-7.0.1/highcharts.js"></script>
<script src="libs/highcharts-7.0.1/highcharts-3d.js"></script>
<script src="libs/highcharts-7.0.1/highcharts-more.js"></script>
<script src="libs/highcharts-7.0.1/modules/stock.js"></script>
<script src="libs/highcharts-7.0.1/modules/map.js"></script>
<script src="libs/highcharts-7.0.1/modules/annotations.js"></script>
<script src="libs/highcharts-7.0.1/modules/boost.js"></script>
<script src="libs/highcharts-7.0.1/modules/data.js"></script>
<script src="libs/highcharts-7.0.1/modules/drag-panes.js"></script>
<script src="libs/highcharts-7.0.1/modules/drilldown.js"></script>
<script src="libs/highcharts-7.0.1/modules/item-series.js"></script>
<script src="libs/highcharts-7.0.1/modules/offline-exporting.js"></script>
<script src="libs/highcharts-7.0.1/modules/overlapping-datalabels.js"></script>
<script src="libs/highcharts-7.0.1/modules/exporting.js"></script>
<script src="libs/highcharts-7.0.1/modules/export-data.js"></script>
<script src="libs/highcharts-7.0.1/modules/funnel.js"></script>
<script src="libs/highcharts-7.0.1/modules/heatmap.js"></script>
<script src="libs/highcharts-7.0.1/modules/treemap.js"></script>
<script src="libs/highcharts-7.0.1/modules/sankey.js"></script>
<script src="libs/highcharts-7.0.1/modules/solid-gauge.js"></script>
<script src="libs/highcharts-7.0.1/modules/streamgraph.js"></script>
<script src="libs/highcharts-7.0.1/modules/sunburst.js"></script>
<script src="libs/highcharts-7.0.1/modules/vector.js"></script>
<script src="libs/highcharts-7.0.1/modules/wordcloud.js"></script>
<script src="libs/highcharts-7.0.1/modules/xrange.js"></script>
<script src="libs/highcharts-7.0.1/modules/tilemap.js"></script>
<script src="libs/highcharts-7.0.1/modules/venn.js"></script>
<script src="libs/highcharts-7.0.1/modules/gantt.js"></script>
<script src="libs/highcharts-7.0.1/modules/timeline.js"></script>
<script src="libs/highcharts-7.0.1/modules/parallel-coordinates.js"></script>
<script src="libs/highcharts-7.0.1/plugins/grouped-categories.js"></script>
<script src="libs/highcharts-7.0.1/plugins/motion.js"></script>
<script src="libs/highcharts-7.0.1/plugins/multicolor_series.js"></script>
<script src="libs/highcharts-7.0.1/custom/reset.js"></script>
<script src="libs/highcharts-7.0.1/custom/symbols-extra.js"></script>
<script src="libs/highcharts-7.0.1/custom/text-symbols.js"></script>
<script src="libs/highchart-binding-0.7.0/highchart.js"></script>
<script src="libs/highcharts-regression.js-7.0.1/highcharts-regression.js"></script>
<link href="libs/leaflet-1.3.1/leaflet.css" rel="stylesheet" />
<script src="libs/leaflet-1.3.1/leaflet.js"></script>
<link href="libs/leafletfix-1.0.0/leafletfix.css" rel="stylesheet" />
<script src="libs/Proj4Leaflet-1.0.1/proj4-compressed.js"></script>
<script src="libs/Proj4Leaflet-1.0.1/proj4leaflet.js"></script>
<link href="libs/rstudio_leaflet-1.3.1/rstudio_leaflet.css" rel="stylesheet" />
<script src="libs/leaflet-binding-2.0.2/leaflet.js"></script>
<script src="libs/leaflet-providers-1.1.17/leaflet-providers.js"></script>
<script src="libs/leaflet-providers-plugin-2.0.2/leaflet-providers-plugin.js"></script>
<link href="libs/HomeButton-0.0.1/home-button.css" rel="stylesheet" />
<script src="libs/HomeButton-0.0.1/home-button.js"></script>
<script src="libs/HomeButton-0.0.1/easy-button-src.min.js"></script>
<script src="libs/clipboard-0.0.1/setClipboardText.js"></script>
<link href="libs/PopupTable-0.0.1/popup.css" rel="stylesheet" />
<script src="libs/pacifico-1/data_stars_pacificocdf13b.txt"></script>
<script src="libs/joda-0.0.1/joda.js"></script>
<script src="libs/joda-0.0.1/addImageQuery-bindings.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Geologia Numerica</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prefacio</a></li>
<li class="part"><span><b>R</b></span></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introducción</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#instalación-de-r-y-rstudio"><i class="fa fa-check"></i><b>1.1</b> Instalación de R y RStudio</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#paquetes"><i class="fa fa-check"></i><b>1.2</b> Paquetes</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#ayuda-en-r"><i class="fa fa-check"></i><b>1.3</b> Ayuda en R</a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#rmarkdown"><i class="fa fa-check"></i><b>1.4</b> RMarkdown</a><ul>
<li class="chapter" data-level="1.4.1" data-path="intro.html"><a href="intro.html#tipos-de-resultados"><i class="fa fa-check"></i><b>1.4.1</b> Tipos de resultados</a></li>
<li class="chapter" data-level="1.4.2" data-path="intro.html"><a href="intro.html#formulas"><i class="fa fa-check"></i><b>1.4.2</b> Formulas</a></li>
<li class="chapter" data-level="1.4.3" data-path="intro.html"><a href="intro.html#importando-datos"><i class="fa fa-check"></i><b>1.4.3</b> Importando datos</a></li>
<li class="chapter" data-level="1.4.4" data-path="intro.html"><a href="intro.html#cálculos-en-linea"><i class="fa fa-check"></i><b>1.4.4</b> Cálculos en linea</a></li>
<li class="chapter" data-level="1.4.5" data-path="intro.html"><a href="intro.html#importando-figuras"><i class="fa fa-check"></i><b>1.4.5</b> Importando figuras</a></li>
<li class="chapter" data-level="1.4.6" data-path="intro.html"><a href="intro.html#salvando-y-compartiendo"><i class="fa fa-check"></i><b>1.4.6</b> Salvando y compartiendo</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="intro.html"><a href="intro.html#recursos"><i class="fa fa-check"></i><b>1.5</b> Recursos</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="basico.html"><a href="basico.html"><i class="fa fa-check"></i><b>2</b> Funcionamiento básico de R</a><ul>
<li class="chapter" data-level="2.1" data-path="basico.html"><a href="basico.html#introducción"><i class="fa fa-check"></i><b>2.1</b> Introducción</a></li>
<li class="chapter" data-level="2.2" data-path="basico.html"><a href="basico.html#operaciones-básicas"><i class="fa fa-check"></i><b>2.2</b> Operaciones básicas</a></li>
<li class="chapter" data-level="2.3" data-path="basico.html"><a href="basico.html#crear-objetos"><i class="fa fa-check"></i><b>2.3</b> Crear objetos</a></li>
<li class="chapter" data-level="2.4" data-path="basico.html"><a href="basico.html#vectores"><i class="fa fa-check"></i><b>2.4</b> Vectores</a><ul>
<li class="chapter" data-level="2.4.1" data-path="basico.html"><a href="basico.html#numéricos"><i class="fa fa-check"></i><b>2.4.1</b> Numéricos</a></li>
<li class="chapter" data-level="2.4.2" data-path="basico.html"><a href="basico.html#texto-string-character"><i class="fa fa-check"></i><b>2.4.2</b> Texto (string, character)</a></li>
<li class="chapter" data-level="2.4.3" data-path="basico.html"><a href="basico.html#categóricos-factores"><i class="fa fa-check"></i><b>2.4.3</b> Categóricos (factores)</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="basico.html"><a href="basico.html#matrices"><i class="fa fa-check"></i><b>2.5</b> Matrices</a></li>
<li class="chapter" data-level="2.6" data-path="basico.html"><a href="basico.html#dataframes-listas-y-tibbles"><i class="fa fa-check"></i><b>2.6</b> DataFrames, listas y tibbles</a></li>
<li class="chapter" data-level="2.7" data-path="basico.html"><a href="basico.html#verificando-objetos"><i class="fa fa-check"></i><b>2.7</b> Verificando objetos</a></li>
<li class="chapter" data-level="2.8" data-path="basico.html"><a href="basico.html#guardando-el-espacio-de-trabajo"><i class="fa fa-check"></i><b>2.8</b> Guardando el espacio de trabajo</a></li>
<li class="chapter" data-level="2.9" data-path="basico.html"><a href="basico.html#importandocargando-datos"><i class="fa fa-check"></i><b>2.9</b> Importando/cargando datos</a></li>
<li class="chapter" data-level="2.10" data-path="basico.html"><a href="basico.html#exportando-datos"><i class="fa fa-check"></i><b>2.10</b> Exportando datos</a></li>
<li class="chapter" data-level="2.11" data-path="basico.html"><a href="basico.html#inspeccionando-los-datos"><i class="fa fa-check"></i><b>2.11</b> Inspeccionando los datos</a></li>
<li class="chapter" data-level="2.12" data-path="basico.html"><a href="basico.html#descripciones-generales-globales"><i class="fa fa-check"></i><b>2.12</b> Descripciones generales (globales)</a></li>
<li class="chapter" data-level="2.13" data-path="basico.html"><a href="basico.html#recursos-1"><i class="fa fa-check"></i><b>2.13</b> Recursos</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="avanzado.html"><a href="avanzado.html"><i class="fa fa-check"></i><b>3</b> Funcionamiento avanzado de R</a><ul>
<li class="chapter" data-level="3.1" data-path="avanzado.html"><a href="avanzado.html#introducción-1"><i class="fa fa-check"></i><b>3.1</b> Introducción</a></li>
<li class="chapter" data-level="3.2" data-path="avanzado.html"><a href="avanzado.html#operadores-lógicos"><i class="fa fa-check"></i><b>3.2</b> Operadores lógicos</a></li>
<li class="chapter" data-level="3.3" data-path="avanzado.html"><a href="avanzado.html#operador-de-secuencia-pipe-operator"><i class="fa fa-check"></i><b>3.3</b> Operador de secuencia (Pipe operator)</a></li>
<li class="chapter" data-level="3.4" data-path="avanzado.html"><a href="avanzado.html#resumen-de-variables"><i class="fa fa-check"></i><b>3.4</b> Resumen de variables</a></li>
<li class="chapter" data-level="3.5" data-path="avanzado.html"><a href="avanzado.html#selección-y-renombre-de-variables"><i class="fa fa-check"></i><b>3.5</b> Selección y renombre de variables</a><ul>
<li class="chapter" data-level="3.5.1" data-path="avanzado.html"><a href="avanzado.html#select-helpers"><i class="fa fa-check"></i><b>3.5.1</b> <code>select</code> helpers</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="avanzado.html"><a href="avanzado.html#filtrado-de-observaciones"><i class="fa fa-check"></i><b>3.6</b> Filtrado de observaciones</a></li>
<li class="chapter" data-level="3.7" data-path="avanzado.html"><a href="avanzado.html#orden-de-acuerdo-a-variables"><i class="fa fa-check"></i><b>3.7</b> Orden de acuerdo a variables</a></li>
<li class="chapter" data-level="3.8" data-path="avanzado.html"><a href="avanzado.html#creación-de-variables"><i class="fa fa-check"></i><b>3.8</b> Creación de variables</a></li>
<li class="chapter" data-level="3.9" data-path="avanzado.html"><a href="avanzado.html#conteo-de-variables-cualitativas"><i class="fa fa-check"></i><b>3.9</b> Conteo de variables cualitativas</a></li>
<li class="chapter" data-level="3.10" data-path="avanzado.html"><a href="avanzado.html#tabla-interactiva"><i class="fa fa-check"></i><b>3.10</b> Tabla interactiva</a></li>
<li class="chapter" data-level="3.11" data-path="avanzado.html"><a href="avanzado.html#datos-relacionales"><i class="fa fa-check"></i><b>3.11</b> Datos relacionales</a><ul>
<li class="chapter" data-level="3.11.1" data-path="avanzado.html"><a href="avanzado.html#uniones-de-transformación"><i class="fa fa-check"></i><b>3.11.1</b> Uniones de transformación</a></li>
<li class="chapter" data-level="3.11.2" data-path="avanzado.html"><a href="avanzado.html#uniones-de-filtro"><i class="fa fa-check"></i><b>3.11.2</b> Uniones de filtro</a></li>
</ul></li>
<li class="chapter" data-level="3.12" data-path="avanzado.html"><a href="avanzado.html#datos-ordenados-tidy-data"><i class="fa fa-check"></i><b>3.12</b> Datos ordenados (Tidy data)</a><ul>
<li class="chapter" data-level="3.12.1" data-path="avanzado.html"><a href="avanzado.html#formatos-largo-y-ancho"><i class="fa fa-check"></i><b>3.12.1</b> Formatos largo y ancho</a></li>
<li class="chapter" data-level="3.12.2" data-path="avanzado.html"><a href="avanzado.html#separar-y-unir"><i class="fa fa-check"></i><b>3.12.2</b> Separar y unir</a></li>
</ul></li>
<li class="chapter" data-level="3.13" data-path="avanzado.html"><a href="avanzado.html#nest"><i class="fa fa-check"></i><b>3.13</b> Datos anidados (Nesting)</a></li>
<li class="chapter" data-level="3.14" data-path="avanzado.html"><a href="avanzado.html#recursos-2"><i class="fa fa-check"></i><b>3.14</b> Recursos</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="gráficos-1.html"><a href="gráficos-1.html"><i class="fa fa-check"></i><b>4</b> Gráficos</a><ul>
<li class="chapter" data-level="4.1" data-path="gráficos-1.html"><a href="gráficos-1.html#introducción-2"><i class="fa fa-check"></i><b>4.1</b> Introducción</a></li>
<li class="chapter" data-level="4.2" data-path="gráficos-1.html"><a href="gráficos-1.html#estáticos"><i class="fa fa-check"></i><b>4.2</b> Estáticos</a><ul>
<li class="chapter" data-level="4.2.1" data-path="gráficos-1.html"><a href="gráficos-1.html#histograma"><i class="fa fa-check"></i><b>4.2.1</b> Histograma</a></li>
<li class="chapter" data-level="4.2.2" data-path="gráficos-1.html"><a href="gráficos-1.html#barras"><i class="fa fa-check"></i><b>4.2.2</b> Barras</a></li>
<li class="chapter" data-level="4.2.3" data-path="gráficos-1.html"><a href="gráficos-1.html#boxplot"><i class="fa fa-check"></i><b>4.2.3</b> Boxplot</a></li>
<li class="chapter" data-level="4.2.4" data-path="gráficos-1.html"><a href="gráficos-1.html#dispersión"><i class="fa fa-check"></i><b>4.2.4</b> Dispersión</a></li>
<li class="chapter" data-level="4.2.5" data-path="gráficos-1.html"><a href="gráficos-1.html#líneas"><i class="fa fa-check"></i><b>4.2.5</b> líneas</a></li>
<li class="chapter" data-level="4.2.6" data-path="gráficos-1.html"><a href="gráficos-1.html#gráficos-estadísticos"><i class="fa fa-check"></i><b>4.2.6</b> Gráficos estadísticos</a></li>
<li class="chapter" data-level="4.2.7" data-path="gráficos-1.html"><a href="gráficos-1.html#transformación-de-ejes"><i class="fa fa-check"></i><b>4.2.7</b> Transformación de ejes</a></li>
<li class="chapter" data-level="4.2.8" data-path="gráficos-1.html"><a href="gráficos-1.html#limites-de-ejes-zoom"><i class="fa fa-check"></i><b>4.2.8</b> Limites de ejes (Zoom)</a></li>
<li class="chapter" data-level="4.2.9" data-path="gráficos-1.html"><a href="gráficos-1.html#salvando-gráficos"><i class="fa fa-check"></i><b>4.2.9</b> Salvando gráficos</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="gráficos-1.html"><a href="gráficos-1.html#interactivos"><i class="fa fa-check"></i><b>4.3</b> Interactivos</a><ul>
<li class="chapter" data-level="4.3.1" data-path="gráficos-1.html"><a href="gráficos-1.html#histograma-1"><i class="fa fa-check"></i><b>4.3.1</b> Histograma</a></li>
<li class="chapter" data-level="4.3.2" data-path="gráficos-1.html"><a href="gráficos-1.html#barras-1"><i class="fa fa-check"></i><b>4.3.2</b> Barras</a></li>
<li class="chapter" data-level="4.3.3" data-path="gráficos-1.html"><a href="gráficos-1.html#boxplot-1"><i class="fa fa-check"></i><b>4.3.3</b> Boxplot</a></li>
<li class="chapter" data-level="4.3.4" data-path="gráficos-1.html"><a href="gráficos-1.html#dispersión-1"><i class="fa fa-check"></i><b>4.3.4</b> Dispersión</a></li>
<li class="chapter" data-level="4.3.5" data-path="gráficos-1.html"><a href="gráficos-1.html#líneas-1"><i class="fa fa-check"></i><b>4.3.5</b> líneas</a></li>
<li class="chapter" data-level="4.3.6" data-path="gráficos-1.html"><a href="gráficos-1.html#transformación-de-ejes-1"><i class="fa fa-check"></i><b>4.3.6</b> Transformación de ejes</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="gráficos-1.html"><a href="gráficos-1.html#recursos-3"><i class="fa fa-check"></i><b>4.4</b> Recursos</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="iteración.html"><a href="iteración.html"><i class="fa fa-check"></i><b>5</b> Iteración</a><ul>
<li class="chapter" data-level="5.1" data-path="iteración.html"><a href="iteración.html#introducción-3"><i class="fa fa-check"></i><b>5.1</b> Introducción</a></li>
<li class="chapter" data-level="5.2" data-path="iteración.html"><a href="iteración.html#iterando-sobre-un-objeto"><i class="fa fa-check"></i><b>5.2</b> Iterando sobre un objeto</a></li>
<li class="chapter" data-level="5.3" data-path="iteración.html"><a href="iteración.html#iterando-sobre-dos-objetos"><i class="fa fa-check"></i><b>5.3</b> Iterando sobre dos objetos</a></li>
<li class="chapter" data-level="5.4" data-path="iteración.html"><a href="iteración.html#leyendo-archivos-y-combinándolos"><i class="fa fa-check"></i><b>5.4</b> Leyendo archivos y combinándolos</a></li>
<li class="chapter" data-level="5.5" data-path="iteración.html"><a href="iteración.html#datos-anidados-caso-1"><i class="fa fa-check"></i><b>5.5</b> Datos anidados, caso 1</a><ul>
<li class="chapter" data-level="5.5.1" data-path="iteración.html"><a href="iteración.html#efectos-secundarios"><i class="fa fa-check"></i><b>5.5.1</b> Efectos secundarios</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="iteración.html"><a href="iteración.html#datos-anidados-caso-2"><i class="fa fa-check"></i><b>5.6</b> Datos anidados, caso 2</a></li>
<li class="chapter" data-level="5.7" data-path="iteración.html"><a href="iteración.html#recursos-4"><i class="fa fa-check"></i><b>5.7</b> Recursos</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="datos-espaciales.html"><a href="datos-espaciales.html"><i class="fa fa-check"></i><b>6</b> Datos espaciales</a><ul>
<li class="chapter" data-level="6.1" data-path="datos-espaciales.html"><a href="datos-espaciales.html#introducción-4"><i class="fa fa-check"></i><b>6.1</b> Introducción</a></li>
<li class="chapter" data-level="6.2" data-path="datos-espaciales.html"><a href="datos-espaciales.html#paquetes-para-datos-espaciales"><i class="fa fa-check"></i><b>6.2</b> Paquetes para datos espaciales</a></li>
<li class="chapter" data-level="6.3" data-path="datos-espaciales.html"><a href="datos-espaciales.html#sistemas-de-referencias-de-coordenadas-crs"><i class="fa fa-check"></i><b>6.3</b> Sistemas de Referencias de Coordenadas (CRS)</a></li>
<li class="chapter" data-level="6.4" data-path="datos-espaciales.html"><a href="datos-espaciales.html#importar-datos"><i class="fa fa-check"></i><b>6.4</b> Importar datos</a><ul>
<li class="chapter" data-level="6.4.1" data-path="datos-espaciales.html"><a href="datos-espaciales.html#desde-archivos-de-texto"><i class="fa fa-check"></i><b>6.4.1</b> Desde archivos de texto</a></li>
<li class="chapter" data-level="6.4.2" data-path="datos-espaciales.html"><a href="datos-espaciales.html#desde-archivos-espaciales"><i class="fa fa-check"></i><b>6.4.2</b> Desde archivos espaciales</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="datos-espaciales.html"><a href="datos-espaciales.html#exportar-datos"><i class="fa fa-check"></i><b>6.5</b> Exportar datos</a><ul>
<li class="chapter" data-level="6.5.1" data-path="datos-espaciales.html"><a href="datos-espaciales.html#vectoriales"><i class="fa fa-check"></i><b>6.5.1</b> Vectoriales</a></li>
<li class="chapter" data-level="6.5.2" data-path="datos-espaciales.html"><a href="datos-espaciales.html#raster-1"><i class="fa fa-check"></i><b>6.5.2</b> Raster</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="datos-espaciales.html"><a href="datos-espaciales.html#mapas"><i class="fa fa-check"></i><b>6.6</b> Mapas</a><ul>
<li class="chapter" data-level="6.6.1" data-path="datos-espaciales.html"><a href="datos-espaciales.html#estáticos-1"><i class="fa fa-check"></i><b>6.6.1</b> Estáticos</a></li>
<li class="chapter" data-level="6.6.2" data-path="datos-espaciales.html"><a href="datos-espaciales.html#dinámicos"><i class="fa fa-check"></i><b>6.6.2</b> Dinámicos</a></li>
<li class="chapter" data-level="6.6.3" data-path="datos-espaciales.html"><a href="datos-espaciales.html#modelos-de-sombras"><i class="fa fa-check"></i><b>6.6.3</b> Modelos de sombras</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="datos-espaciales.html"><a href="datos-espaciales.html#recursos-5"><i class="fa fa-check"></i><b>6.7</b> Recursos</a></li>
</ul></li>
<li class="part"><span><b>Análisis de datos</b></span></li>
<li class="chapter" data-level="7" data-path="álgebra-lineal.html"><a href="álgebra-lineal.html"><i class="fa fa-check"></i><b>7</b> Álgebra lineal</a><ul>
<li class="chapter" data-level="7.1" data-path="álgebra-lineal.html"><a href="álgebra-lineal.html#introducción-5"><i class="fa fa-check"></i><b>7.1</b> Introducción</a></li>
<li class="chapter" data-level="7.2" data-path="álgebra-lineal.html"><a href="álgebra-lineal.html#tensores"><i class="fa fa-check"></i><b>7.2</b> Tensores</a><ul>
<li class="chapter" data-level="7.2.1" data-path="álgebra-lineal.html"><a href="álgebra-lineal.html#vectores-1"><i class="fa fa-check"></i><b>7.2.1</b> Vectores</a></li>
<li class="chapter" data-level="7.2.2" data-path="álgebra-lineal.html"><a href="álgebra-lineal.html#matrices-1"><i class="fa fa-check"></i><b>7.2.2</b> Matrices</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="álgebra-lineal.html"><a href="álgebra-lineal.html#eigenvectors-y-eigenvalues"><i class="fa fa-check"></i><b>7.3</b> Eigenvectors y Eigenvalues</a><ul>
<li class="chapter" data-level="7.3.1" data-path="álgebra-lineal.html"><a href="álgebra-lineal.html#definición"><i class="fa fa-check"></i><b>7.3.1</b> Definición</a></li>
<li class="chapter" data-level="7.3.2" data-path="álgebra-lineal.html"><a href="álgebra-lineal.html#cálculo"><i class="fa fa-check"></i><b>7.3.2</b> Cálculo</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="introducción-a-estadística.html"><a href="introducción-a-estadística.html"><i class="fa fa-check"></i><b>8</b> Introducción a estadística</a><ul>
<li class="chapter" data-level="8.1" data-path="introducción-a-estadística.html"><a href="introducción-a-estadística.html#introducción-6"><i class="fa fa-check"></i><b>8.1</b> Introducción</a></li>
<li class="chapter" data-level="8.2" data-path="introducción-a-estadística.html"><a href="introducción-a-estadística.html#tipos"><i class="fa fa-check"></i><b>8.2</b> Tipos</a></li>
<li class="chapter" data-level="8.3" data-path="introducción-a-estadística.html"><a href="introducción-a-estadística.html#modelos"><i class="fa fa-check"></i><b>8.3</b> Modelos</a></li>
<li class="chapter" data-level="8.4" data-path="introducción-a-estadística.html"><a href="introducción-a-estadística.html#nomenclatura"><i class="fa fa-check"></i><b>8.4</b> Nomenclatura</a></li>
<li class="chapter" data-level="8.5" data-path="introducción-a-estadística.html"><a href="introducción-a-estadística.html#variables"><i class="fa fa-check"></i><b>8.5</b> Variables</a><ul>
<li class="chapter" data-level="8.5.1" data-path="introducción-a-estadística.html"><a href="introducción-a-estadística.html#cualitativa"><i class="fa fa-check"></i><b>8.5.1</b> Cualitativa</a></li>
<li class="chapter" data-level="8.5.2" data-path="introducción-a-estadística.html"><a href="introducción-a-estadística.html#cuantitativa"><i class="fa fa-check"></i><b>8.5.2</b> Cuantitativa</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="introducción-a-estadística.html"><a href="introducción-a-estadística.html#métodos-de-análisis"><i class="fa fa-check"></i><b>8.6</b> Métodos de análisis</a></li>
<li class="chapter" data-level="8.7" data-path="introducción-a-estadística.html"><a href="introducción-a-estadística.html#muestreo"><i class="fa fa-check"></i><b>8.7</b> Muestreo</a><ul>
<li class="chapter" data-level="8.7.1" data-path="introducción-a-estadística.html"><a href="introducción-a-estadística.html#tipos-1"><i class="fa fa-check"></i><b>8.7.1</b> Tipos</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="introducción-a-estadística.html"><a href="introducción-a-estadística.html#incertidumbre"><i class="fa fa-check"></i><b>8.8</b> Incertidumbre</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="estadística-descriptiva-univariable.html"><a href="estadística-descriptiva-univariable.html"><i class="fa fa-check"></i><b>9</b> Estadística Descriptiva Univariable</a><ul>
<li class="chapter" data-level="9.1" data-path="estadística-descriptiva-univariable.html"><a href="estadística-descriptiva-univariable.html#introducción-7"><i class="fa fa-check"></i><b>9.1</b> Introducción</a></li>
<li class="chapter" data-level="9.2" data-path="estadística-descriptiva-univariable.html"><a href="estadística-descriptiva-univariable.html#tablas-de-frecuencias"><i class="fa fa-check"></i><b>9.2</b> Tablas de frecuencias</a></li>
<li class="chapter" data-level="9.3" data-path="estadística-descriptiva-univariable.html"><a href="estadística-descriptiva-univariable.html#gráficas"><i class="fa fa-check"></i><b>9.3</b> Gráficas</a></li>
<li class="chapter" data-level="9.4" data-path="estadística-descriptiva-univariable.html"><a href="estadística-descriptiva-univariable.html#resúmenes-numéricos"><i class="fa fa-check"></i><b>9.4</b> Resúmenes numéricos</a><ul>
<li class="chapter" data-level="9.4.1" data-path="estadística-descriptiva-univariable.html"><a href="estadística-descriptiva-univariable.html#medidas-de-tendencia-central"><i class="fa fa-check"></i><b>9.4.1</b> Medidas de tendencia central</a></li>
<li class="chapter" data-level="9.4.2" data-path="estadística-descriptiva-univariable.html"><a href="estadística-descriptiva-univariable.html#medidas-de-dispersión"><i class="fa fa-check"></i><b>9.4.2</b> Medidas de dispersión</a></li>
<li class="chapter" data-level="9.4.3" data-path="estadística-descriptiva-univariable.html"><a href="estadística-descriptiva-univariable.html#medidas-de-posición"><i class="fa fa-check"></i><b>9.4.3</b> Medidas de posición</a></li>
<li class="chapter" data-level="9.4.4" data-path="estadística-descriptiva-univariable.html"><a href="estadística-descriptiva-univariable.html#medidas-de-forma"><i class="fa fa-check"></i><b>9.4.4</b> Medidas de forma</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="estadística-descriptiva-univariable.html"><a href="estadística-descriptiva-univariable.html#resumen-general"><i class="fa fa-check"></i><b>9.5</b> Resumen general</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="estadística-descriptiva-bivariable.html"><a href="estadística-descriptiva-bivariable.html"><i class="fa fa-check"></i><b>10</b> Estadística Descriptiva Bivariable</a><ul>
<li class="chapter" data-level="10.1" data-path="estadística-descriptiva-bivariable.html"><a href="estadística-descriptiva-bivariable.html#introducción-8"><i class="fa fa-check"></i><b>10.1</b> Introducción</a></li>
<li class="chapter" data-level="10.2" data-path="estadística-descriptiva-bivariable.html"><a href="estadística-descriptiva-bivariable.html#covarianza"><i class="fa fa-check"></i><b>10.2</b> Covarianza</a></li>
<li class="chapter" data-level="10.3" data-path="estadística-descriptiva-bivariable.html"><a href="estadística-descriptiva-bivariable.html#bivar-cor"><i class="fa fa-check"></i><b>10.3</b> Correlación</a></li>
<li class="chapter" data-level="10.4" data-path="estadística-descriptiva-bivariable.html"><a href="estadística-descriptiva-bivariable.html#bivar-reg"><i class="fa fa-check"></i><b>10.4</b> Regresión</a><ul>
<li class="chapter" data-level="10.4.1" data-path="estadística-descriptiva-bivariable.html"><a href="estadística-descriptiva-bivariable.html#nomenclatura-1"><i class="fa fa-check"></i><b>10.4.1</b> Nomenclatura</a></li>
<li class="chapter" data-level="10.4.2" data-path="estadística-descriptiva-bivariable.html"><a href="estadística-descriptiva-bivariable.html#supuestos"><i class="fa fa-check"></i><b>10.4.2</b> Supuestos</a></li>
<li class="chapter" data-level="10.4.3" data-path="estadística-descriptiva-bivariable.html"><a href="estadística-descriptiva-bivariable.html#tipos-2"><i class="fa fa-check"></i><b>10.4.3</b> Tipos</a></li>
<li class="chapter" data-level="10.4.4" data-path="estadística-descriptiva-bivariable.html"><a href="estadística-descriptiva-bivariable.html#medidas-de-ajuste-y-error"><i class="fa fa-check"></i><b>10.4.4</b> Medidas de ajuste y error</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="probabilidad.html"><a href="probabilidad.html"><i class="fa fa-check"></i><b>11</b> Probabilidad</a><ul>
<li class="chapter" data-level="11.1" data-path="probabilidad.html"><a href="probabilidad.html#introducción-9"><i class="fa fa-check"></i><b>11.1</b> Introducción</a></li>
<li class="chapter" data-level="11.2" data-path="probabilidad.html"><a href="probabilidad.html#axiomas-y-nomenclatura"><i class="fa fa-check"></i><b>11.2</b> Axiomas y Nomenclatura</a></li>
<li class="chapter" data-level="11.3" data-path="probabilidad.html"><a href="probabilidad.html#reglas-de-probabilidad"><i class="fa fa-check"></i><b>11.3</b> Reglas de probabilidad</a><ul>
<li class="chapter" data-level="11.3.1" data-path="probabilidad.html"><a href="probabilidad.html#regla-de-la-suma"><i class="fa fa-check"></i><b>11.3.1</b> Regla de la suma</a></li>
<li class="chapter" data-level="11.3.2" data-path="probabilidad.html"><a href="probabilidad.html#regla-de-la-multiplicación"><i class="fa fa-check"></i><b>11.3.2</b> Regla de la multiplicación</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="probabilidad.html"><a href="probabilidad.html#variables-aleatorias"><i class="fa fa-check"></i><b>11.4</b> Variables aleatorias</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="distribuciones-de-probabilidad.html"><a href="distribuciones-de-probabilidad.html"><i class="fa fa-check"></i><b>12</b> Distribuciones de Probabilidad</a><ul>
<li class="chapter" data-level="12.1" data-path="distribuciones-de-probabilidad.html"><a href="distribuciones-de-probabilidad.html#introducción-10"><i class="fa fa-check"></i><b>12.1</b> Introducción</a></li>
<li class="chapter" data-level="12.2" data-path="distribuciones-de-probabilidad.html"><a href="distribuciones-de-probabilidad.html#distribución-binomial"><i class="fa fa-check"></i><b>12.2</b> Distribución Binomial</a></li>
<li class="chapter" data-level="12.3" data-path="distribuciones-de-probabilidad.html"><a href="distribuciones-de-probabilidad.html#distribución-de-poisson"><i class="fa fa-check"></i><b>12.3</b> Distribución de Poisson</a></li>
<li class="chapter" data-level="12.4" data-path="distribuciones-de-probabilidad.html"><a href="distribuciones-de-probabilidad.html#distribución-normal-o-gaussiana"><i class="fa fa-check"></i><b>12.4</b> Distribución Normal o Gaussiana</a><ul>
<li class="chapter" data-level="12.4.1" data-path="distribuciones-de-probabilidad.html"><a href="distribuciones-de-probabilidad.html#distribución-normal-estándar-z"><i class="fa fa-check"></i><b>12.4.1</b> Distribución Normal Estándar (Z)</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="distribuciones-de-probabilidad.html"><a href="distribuciones-de-probabilidad.html#distribuciones-de-probabilidad-en-r"><i class="fa fa-check"></i><b>12.5</b> Distribuciones de probabilidad en <strong>R</strong></a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="introducción-a-estadística-inferencial.html"><a href="introducción-a-estadística-inferencial.html"><i class="fa fa-check"></i><b>13</b> Introducción a Estadística Inferencial</a><ul>
<li class="chapter" data-level="13.1" data-path="introducción-a-estadística-inferencial.html"><a href="introducción-a-estadística-inferencial.html#introducción-11"><i class="fa fa-check"></i><b>13.1</b> Introducción</a></li>
<li class="chapter" data-level="13.2" data-path="introducción-a-estadística-inferencial.html"><a href="introducción-a-estadística-inferencial.html#distribuciones-muestrales"><i class="fa fa-check"></i><b>13.2</b> Distribuciones muestrales</a><ul>
<li class="chapter" data-level="13.2.1" data-path="introducción-a-estadística-inferencial.html"><a href="introducción-a-estadística-inferencial.html#infer-x"><i class="fa fa-check"></i><b>13.2.1</b> Media <span class="math inline">\((\bar{x})\)</span></a></li>
<li class="chapter" data-level="13.2.2" data-path="introducción-a-estadística-inferencial.html"><a href="introducción-a-estadística-inferencial.html#infer-x2"><i class="fa fa-check"></i><b>13.2.2</b> Diferencia de medias <span class="math inline">\((\bar{x}_1-\bar{x}_2)\)</span></a></li>
<li class="chapter" data-level="13.2.3" data-path="introducción-a-estadística-inferencial.html"><a href="introducción-a-estadística-inferencial.html#infer-chi"><i class="fa fa-check"></i><b>13.2.3</b> Varianza <span class="math inline">\((s^2)\)</span></a></li>
<li class="chapter" data-level="13.2.4" data-path="introducción-a-estadística-inferencial.html"><a href="introducción-a-estadística-inferencial.html#infer-f"><i class="fa fa-check"></i><b>13.2.4</b> Dos varianzas <span class="math inline">\(\left( \frac{s_1^2}{s_2^2} \right)\)</span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="estimación-e-hipótesis.html"><a href="estimación-e-hipótesis.html"><i class="fa fa-check"></i><b>14</b> Estimación e Hipótesis</a><ul>
<li class="chapter" data-level="14.1" data-path="estimación-e-hipótesis.html"><a href="estimación-e-hipótesis.html#introducción-12"><i class="fa fa-check"></i><b>14.1</b> Introducción</a></li>
<li class="chapter" data-level="14.2" data-path="estimación-e-hipótesis.html"><a href="estimación-e-hipótesis.html#estim"><i class="fa fa-check"></i><b>14.2</b> Estimación</a><ul>
<li class="chapter" data-level="14.2.1" data-path="estimación-e-hipótesis.html"><a href="estimación-e-hipótesis.html#media-1"><i class="fa fa-check"></i><b>14.2.1</b> Media</a></li>
<li class="chapter" data-level="14.2.2" data-path="estimación-e-hipótesis.html"><a href="estimación-e-hipótesis.html#estim-diff-medias"><i class="fa fa-check"></i><b>14.2.2</b> Diferencia de medias</a></li>
<li class="chapter" data-level="14.2.3" data-path="estimación-e-hipótesis.html"><a href="estimación-e-hipótesis.html#estim-ic-chi"><i class="fa fa-check"></i><b>14.2.3</b> Varianza</a></li>
<li class="chapter" data-level="14.2.4" data-path="estimación-e-hipótesis.html"><a href="estimación-e-hipótesis.html#estim-ic-f"><i class="fa fa-check"></i><b>14.2.4</b> Dos varianzas</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="estimación-e-hipótesis.html"><a href="estimación-e-hipótesis.html#hip"><i class="fa fa-check"></i><b>14.3</b> Hipótesis</a><ul>
<li class="chapter" data-level="14.3.1" data-path="estimación-e-hipótesis.html"><a href="estimación-e-hipótesis.html#nula-h_0-y-alterna-h_1"><i class="fa fa-check"></i><b>14.3.1</b> Nula (<span class="math inline">\(H_0\)</span>) y Alterna (<span class="math inline">\(H_1\)</span>)</a></li>
<li class="chapter" data-level="14.3.2" data-path="estimación-e-hipótesis.html"><a href="estimación-e-hipótesis.html#resultados-y-errores"><i class="fa fa-check"></i><b>14.3.2</b> Resultados y Errores</a></li>
<li class="chapter" data-level="14.3.3" data-path="estimación-e-hipótesis.html"><a href="estimación-e-hipótesis.html#estadístico-de-prueba-y-crítico"><i class="fa fa-check"></i><b>14.3.3</b> Estadístico de prueba y crítico</a></li>
<li class="chapter" data-level="14.3.4" data-path="estimación-e-hipótesis.html"><a href="estimación-e-hipótesis.html#contrastes-y-valor-p"><i class="fa fa-check"></i><b>14.3.4</b> Contrastes y valor-<em>p</em></a></li>
<li class="chapter" data-level="14.3.5" data-path="estimación-e-hipótesis.html"><a href="estimación-e-hipótesis.html#decisión"><i class="fa fa-check"></i><b>14.3.5</b> Decisión</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="pruebas-estadísticas.html"><a href="pruebas-estadísticas.html"><i class="fa fa-check"></i><b>15</b> Pruebas Estadísticas</a><ul>
<li class="chapter" data-level="15.1" data-path="pruebas-estadísticas.html"><a href="pruebas-estadísticas.html#introducción-13"><i class="fa fa-check"></i><b>15.1</b> Introducción</a></li>
<li class="chapter" data-level="15.2" data-path="pruebas-estadísticas.html"><a href="pruebas-estadísticas.html#pruebas-param"><i class="fa fa-check"></i><b>15.2</b> Pruebas paramétricas</a><ul>
<li class="chapter" data-level="15.2.1" data-path="pruebas-estadísticas.html"><a href="pruebas-estadísticas.html#supuestos-pasos"><i class="fa fa-check"></i><b>15.2.1</b> Supuestos y Pasos</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="pruebas-estadísticas.html"><a href="pruebas-estadísticas.html#ES-p"><i class="fa fa-check"></i><b>15.3</b> Tamaño del Efecto</a><ul>
<li class="chapter" data-level="15.3.1" data-path="pruebas-estadísticas.html"><a href="pruebas-estadísticas.html#familias-de-tamaño-del-efecto"><i class="fa fa-check"></i><b>15.3.1</b> Familias de tamaño del efecto</a></li>
<li class="chapter" data-level="15.3.2" data-path="pruebas-estadísticas.html"><a href="pruebas-estadísticas.html#ecuaciones-para-tamaños-de-efecto"><i class="fa fa-check"></i><b>15.3.2</b> Ecuaciones para tamaños de efecto</a></li>
<li class="chapter" data-level="15.3.3" data-path="pruebas-estadísticas.html"><a href="pruebas-estadísticas.html#clasificación-de-tamaños-de-efecto"><i class="fa fa-check"></i><b>15.3.3</b> Clasificación de tamaños de efecto</a></li>
<li class="chapter" data-level="15.3.4" data-path="pruebas-estadísticas.html"><a href="pruebas-estadísticas.html#importancia-del-tamaño-del-efecto"><i class="fa fa-check"></i><b>15.3.4</b> Importancia del tamaño del efecto</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="pruebas-estadísticas.html"><a href="pruebas-estadísticas.html#prueba-z1"><i class="fa fa-check"></i><b>15.4</b> <span class="math inline">\(z\)</span> de 1 muestra</a></li>
<li class="chapter" data-level="15.5" data-path="pruebas-estadísticas.html"><a href="pruebas-estadísticas.html#prueba-t1"><i class="fa fa-check"></i><b>15.5</b> <span class="math inline">\(t\)</span> de 1 muestra</a></li>
<li class="chapter" data-level="15.6" data-path="pruebas-estadísticas.html"><a href="pruebas-estadísticas.html#prueba-t2-ind"><i class="fa fa-check"></i><b>15.6</b> <span class="math inline">\(t\)</span> de 2 muestras independientes</a></li>
<li class="chapter" data-level="15.7" data-path="pruebas-estadísticas.html"><a href="pruebas-estadísticas.html#prueba-t2-dep"><i class="fa fa-check"></i><b>15.7</b> <span class="math inline">\(t\)</span> de 2 muestras dependientes</a></li>
<li class="chapter" data-level="15.8" data-path="pruebas-estadísticas.html"><a href="pruebas-estadísticas.html#prueba-aov"><i class="fa fa-check"></i><b>15.8</b> ANOVA de 1-factor entre-sujetos</a><ul>
<li class="chapter" data-level="15.8.1" data-path="pruebas-estadísticas.html"><a href="pruebas-estadísticas.html#relación-entre-la-prueba-t-de-2-muestras-independientes-y-anova-de-1-factor-entre-sujetos"><i class="fa fa-check"></i><b>15.8.1</b> Relación entre la prueba <span class="math inline">\(t\)</span> de 2 muestras independientes y ANOVA de 1-factor entre-sujetos</a></li>
</ul></li>
<li class="chapter" data-level="15.9" data-path="pruebas-estadísticas.html"><a href="pruebas-estadísticas.html#prueba-pearson"><i class="fa fa-check"></i><b>15.9</b> Correlación de Pearson</a></li>
<li class="chapter" data-level="15.10" data-path="pruebas-estadísticas.html"><a href="pruebas-estadísticas.html#prueba-rpb"><i class="fa fa-check"></i><b>15.10</b> Correlación Punto Biserial</a></li>
<li class="chapter" data-level="15.11" data-path="pruebas-estadísticas.html"><a href="pruebas-estadísticas.html#prueba-chi"><i class="fa fa-check"></i><b>15.11</b> <span class="math inline">\(\chi^2\)</span> para 1 varianza</a></li>
<li class="chapter" data-level="15.12" data-path="pruebas-estadísticas.html"><a href="pruebas-estadísticas.html#prueba-f"><i class="fa fa-check"></i><b>15.12</b> <span class="math inline">\(F\)</span> para 2 varianzas</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html"><i class="fa fa-check"></i><b>16</b> Estadística No Paramétrica</a><ul>
<li class="chapter" data-level="16.1" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html#introducción-14"><i class="fa fa-check"></i><b>16.1</b> Introducción</a></li>
<li class="chapter" data-level="16.2" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html#pruebas-noparam"><i class="fa fa-check"></i><b>16.2</b> Pruebas no-paramétricas</a></li>
<li class="chapter" data-level="16.3" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html#ES-np"><i class="fa fa-check"></i><b>16.3</b> Tamaño del efecto</a></li>
<li class="chapter" data-level="16.4" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html#pruebas-chi2-nominales"><i class="fa fa-check"></i><b>16.4</b> Pruebas <span class="math inline">\(\chi^2\)</span> (nominales)</a><ul>
<li class="chapter" data-level="16.4.1" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html#prueba-chi-gof"><i class="fa fa-check"></i><b>16.4.1</b> Bondad de ajuste</a></li>
<li class="chapter" data-level="16.4.2" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html#tab-contingencia"><i class="fa fa-check"></i><b>16.4.2</b> Tablas de Contingencia</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html#pruebas-sobre-rangos-ordinales"><i class="fa fa-check"></i><b>16.5</b> Pruebas sobre rangos (ordinales)</a><ul>
<li class="chapter" data-level="16.5.1" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html#prueba-wilcoxon"><i class="fa fa-check"></i><b>16.5.1</b> Rango con signo de Wilcoxon</a></li>
<li class="chapter" data-level="16.5.2" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html#prueba-mwu"><i class="fa fa-check"></i><b>16.5.2</b> Suma de rangos de Wilcoxon / U de Mann-Whitney</a></li>
<li class="chapter" data-level="16.5.3" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html#prueba-kruskal"><i class="fa fa-check"></i><b>16.5.3</b> Kruskal-Wallis</a></li>
<li class="chapter" data-level="16.5.4" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html#prueba-spearman"><i class="fa fa-check"></i><b>16.5.4</b> Correlación de Spearman</a></li>
</ul></li>
<li class="chapter" data-level="16.6" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html#bootstrap"><i class="fa fa-check"></i><b>16.6</b> Bootstrap (remuestreo)</a><ul>
<li class="chapter" data-level="16.6.1" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html#infer"><i class="fa fa-check"></i><b>16.6.1</b> <em>infer</em></a></li>
<li class="chapter" data-level="16.6.2" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html#rsample"><i class="fa fa-check"></i><b>16.6.2</b> <em>rsample</em></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="estadística-direccional.html"><a href="estadística-direccional.html"><i class="fa fa-check"></i><b>17</b> Estadística Direccional</a><ul>
<li class="chapter" data-level="17.1" data-path="estadística-direccional.html"><a href="estadística-direccional.html#introducción-15"><i class="fa fa-check"></i><b>17.1</b> Introducción</a></li>
<li class="chapter" data-level="17.2" data-path="estadística-direccional.html"><a href="estadística-direccional.html#representación-gráfica"><i class="fa fa-check"></i><b>17.2</b> Representación gráfica</a></li>
<li class="chapter" data-level="17.3" data-path="estadística-direccional.html"><a href="estadística-direccional.html#datos-circulares"><i class="fa fa-check"></i><b>17.3</b> Datos circulares</a><ul>
<li class="chapter" data-level="17.3.1" data-path="estadística-direccional.html"><a href="estadística-direccional.html#estadística-descriptiva"><i class="fa fa-check"></i><b>17.3.1</b> Estadística descriptiva</a></li>
<li class="chapter" data-level="17.3.2" data-path="estadística-direccional.html"><a href="estadística-direccional.html#estadística-inferencial"><i class="fa fa-check"></i><b>17.3.2</b> Estadística inferencial</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="estadística-direccional.html"><a href="estadística-direccional.html#datos-esféricos"><i class="fa fa-check"></i><b>17.4</b> Datos esféricos</a><ul>
<li class="chapter" data-level="17.4.1" data-path="estadística-direccional.html"><a href="estadística-direccional.html#estadística-descriptiva-1"><i class="fa fa-check"></i><b>17.4.1</b> Estadística descriptiva</a></li>
<li class="chapter" data-level="17.4.2" data-path="estadística-direccional.html"><a href="estadística-direccional.html#estadística-inferencial-1"><i class="fa fa-check"></i><b>17.4.2</b> Estadística inferencial</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18" data-path="secuencias-de-datos.html"><a href="secuencias-de-datos.html"><i class="fa fa-check"></i><b>18</b> Secuencias de Datos</a></li>
<li class="chapter" data-level="19" data-path="geoestadística.html"><a href="geoestadística.html"><i class="fa fa-check"></i><b>19</b> Geoestadística</a></li>
<li class="chapter" data-level="" data-path="referencias.html"><a href="referencias.html"><i class="fa fa-check"></i>Referencias</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Creado con bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Geología Numérica: Ciencia de Datos para Geociencias</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="pruebas-estadísticas" class="section level1">
<h1><span class="header-section-number">Capítulo 15</span> Pruebas Estadísticas</h1>
<div id="introducción-13" class="section level2">
<h2><span class="header-section-number">15.1</span> Introducción</h2>
<p>En la sección <a href="estimación-e-hipótesis.html#hip">14.3</a> se introdujeron las bases teóricas de lo que son las pruebas de hipótesis, las partes o elementos que la componen, y cómo tomar una decisión una vez llevada a cabo la prueba. Este capítulo se centra en la parte práctica de cómo realizar una prueba estadística paramétrica (los pasos generales). Además se introduce el concepto de tamaño del efecto (effect size - ES - en inglés), y de cómo puede éste agregar información después de realizada la prueba, así como la importancia práctica que representa.</p>
</div>
<div id="pruebas-param" class="section level2">
<h2><span class="header-section-number">15.2</span> Pruebas paramétricas</h2>
<p>De manera general se van a cubrir las pruebas estadísticas homólogas con las estimaciones que se presentaron en el capítulo anterior en la sección <a href="estadística-no-paramétrica.html#estimación-1">Estimación</a> (<a href="estimación-e-hipótesis.html#estim">14.2</a>), donde la práctica en general es usar un contraste bilateral a menos que sea muy justificado un contraste unilateral. Las pruebas se resumen a continuación y serán detalladas más adelante:</p>
<ul>
<li>Prueba <span class="math inline">\(z\)</span> de 1 muestra (<a href="pruebas-estadísticas.html#prueba-z1">15.4</a>)
<ul>
<li><span class="math inline">\(H_0: \mu = \mu_0\)</span></li>
</ul></li>
<li>Prueba <span class="math inline">\(t\)</span> de 1 muestra (<a href="pruebas-estadísticas.html#prueba-t1">15.5</a>)
<ul>
<li><span class="math inline">\(H_0: \mu = \mu_0\)</span></li>
</ul></li>
<li>Prueba <span class="math inline">\(t\)</span> de 2 muestras independientes (<a href="pruebas-estadísticas.html#prueba-t2-ind">15.6</a>)
<ul>
<li><span class="math inline">\(H_0: \mu_1 = \mu_2\)</span></li>
</ul></li>
<li>Prueba <span class="math inline">\(t\)</span> de 2 muestras dependientes (<a href="pruebas-estadísticas.html#prueba-t2-dep">15.7</a>)
<ul>
<li><span class="math inline">\(H_0: \mu_D = 0\)</span></li>
</ul></li>
<li>Prueba ANOVA 1-factor entre-sujetos (<a href="pruebas-estadísticas.html#prueba-aov">15.8</a>)
<ul>
<li><span class="math inline">\(H_0: \mu_1 = \mu_2 = \mu_3 = \cdots = \mu_k\)</span></li>
</ul></li>
<li>Correlación de Pearson (<a href="pruebas-estadísticas.html#prueba-pearson">15.9</a>)
<ul>
<li><span class="math inline">\(H_0: \rho = 0\)</span></li>
</ul></li>
<li>Correlación de Pearson (<a href="pruebas-estadísticas.html#prueba-rpb">15.10</a>)
<ul>
<li><span class="math inline">\(H_0: \rho_{pb} = 0\)</span></li>
</ul></li>
<li>Prueba <span class="math inline">\(\chi^2\)</span> para 1 varianza (<a href="pruebas-estadísticas.html#prueba-chi">15.11</a>)
<ul>
<li><span class="math inline">\(H_0: \sigma^2 = \sigma^2_0\)</span></li>
</ul></li>
<li>Prueba <span class="math inline">\(F\)</span> para 2 varianzas (<a href="pruebas-estadísticas.html#prueba-f">15.12</a>)
<ul>
<li><span class="math inline">\(H_0: \sigma^2_1 = \sigma^2_2 \to \frac{\sigma^2_1}{\sigma^2_2} = 1\)</span></li>
</ul></li>
</ul>
<div id="supuestos-pasos" class="section level3">
<h3><span class="header-section-number">15.2.1</span> Supuestos y Pasos</h3>
<p>Las pruebas presentadas en este capítulo se conocen como pruebas paramétricas, que a diferencia de las pruebas no-parámetricas que se presentan en el próximo capítulo, hacen supuestos sobre los datos que se van a analizar, siendo el mayor supuesto de que los datos siguen una distribución aproximadamente normal (o se tiene una muestra grande, <span class="math inline">\(N &gt; 30\)</span>), y que las muestras son aleatorias independientes (excepto en el caso de datos apareados) <span class="citation">(Nolan &amp; Heinzen, <a href="#ref-nolan2014">2014</a>; Triola, <a href="#ref-triola2004">2004</a>)</span>; en algunos casos pueden haber otros supuestos (parámetros conocidos, varianzas iguales, etc.) pero en general éstos son los más importantes.</p>
<p>Para evaluar la “normalidad” de los datos se pueden generar gráficos como el de caja, histogramas, y QQ (Figura <a href="pruebas-estadísticas.html#fig:normalidad">15.1</a>). El gráfico de caja muestra la mediana y los cuartiles, mientras la mediana no se encuentre muy cerca de alguno de los extremos de la caja se puede considerar normalmente distribuida; en caso de haber valores atípicos (extremos) éstos aparecerían como puntos en los extremos. El gráfico QQ hace una comparación de los valores originales con los cuantiles teóricos, la idea es que si los puntos caen cerca de la línea se puede considerar normalmente distribuida; puede que en las colas haya cierta desviación pero eso es normal siempre y cuando no sea muy extrema. El histograma se puede comparar con una curva normal y ver asimetrías, similar al de caja, mientras las asimetría sea nula o mínima se puede considerar normalmente distribuida. Hay pruebas específicas para evaluar la normalidad (Shapiro-Wilk), pero éstas tienden a ser muy sensibles a desviaciones por lo que en general es más recomendado hacer una evaluación visual</p>
<div class="figure" style="text-align: center"><span id="fig:normalidad"></span>
<img src="geolonum_files/figure-html/normalidad-1.png" alt="Gráficos que se pueden usar para evaluar si los datos siguen una distribución aproximandamente normal. **A** Gráfico de caja. **B** Gráfico QQ. **C** Histograma." width="90%" />
<p class="caption">
Figura 15.1: Gráficos que se pueden usar para evaluar si los datos siguen una distribución aproximandamente normal. <strong>A</strong> Gráfico de caja. <strong>B</strong> Gráfico QQ. <strong>C</strong> Histograma.
</p>
</div>
<p><span class="citation">Nolan &amp; Heinzen (<a href="#ref-nolan2014">2014</a>)</span> establecen una serie de pasos que se pueden aplicar de manera general a las pruebas estadísticas:</p>
<ol style="list-style-type: decimal">
<li>Identificar la población, distribución, y la prueba apropiada:
<ul>
<li>En función del parámetro de interés (<span class="math inline">\(\mu, \sigma^2\)</span>)</li>
</ul></li>
<li>Establecer las hipótesis nula y alterna:
<ul>
<li>En función de la prueba escogida en el punto anterior (<span class="math inline">\(z,t,\chi^2,F\)</span>)</li>
</ul></li>
<li>Determinar parámetros de la distribución a comparar (<span class="math inline">\(H_0\)</span>):
<ul>
<li>En función del parámetro de interés y datos disponibles</li>
</ul></li>
<li>Determinar valores críticos
<ul>
<li>En función de la distribución y el nivel de significancia (<span class="math inline">\(\alpha\)</span>)</li>
</ul></li>
<li>Calcular el estadístico de prueba
<ul>
<li>En función de la prueba escogida y datos disponibles</li>
<li>Aquí se puede agregar calcular los intervalos de confianza respectivos</li>
</ul></li>
<li>Tomar una decisión
<ul>
<li>En función de valores críticos y estadístico de prueba, valor-<em>p</em>, o intervalos de confianza</li>
</ul></li>
</ol>
<p>Si se rechaza <span class="math inline">\(H_0\)</span> se dice que hay un resultado <strong><em>estadísticamente significativo</em></strong>. Esta aseveración se refiere a que hay poca probabilidad de que los datos observados provengan de una población representada por <span class="math inline">\(H_0\)</span>. El hecho de que se rechace <span class="math inline">\(H_0\)</span> y se obtenga un resultado <strong><em>estadísticamente significativo</em></strong> no quiere decir que éste sea importante desde el punto de vista práctico <span class="citation">(Nolan &amp; Heinzen, <a href="#ref-nolan2014">2014</a>)</span>. Esto último es lo que va a indicar el tamaño del efecto.</p>
</div>
</div>
<div id="ES-p" class="section level2">
<h2><span class="header-section-number">15.3</span> Tamaño del Efecto</h2>
<p>Cuando una prueba da un resultado estadísticamente significativo, quiere decir que se determinó que hay una diferencia o relación. Como se mencionó en el capítulo anterior, este resultado se va a ver afectado directamente por el tamaño de la muestra, por lo que en el caso de muestras grandes casi siempre se va a encontrar un resultado estadísticamente significativo, aun cuando la diferencia o relación real sea pequeña. El tamaño del efecto (ES) es lo que indica la magnitud real de esa diferencia o relación, no se ve afectada por el tamaño de la muestra, e indica la importancia práctica de un efecto, y debe ser el objetivo a la hora de realizar análisis estadísticos <span class="citation">(Cohen, <a href="#ref-cohen1988">1988</a>; Cumming, <a href="#ref-cumming2012">2012</a>; Cumming &amp; Calin-Jageman, <a href="#ref-cumming2017">2017</a>; Nolan &amp; Heinzen, <a href="#ref-nolan2014">2014</a>)</span>.</p>
<p>A parte de presentar los resultados de pruebas estadísticas, sea que se rechace o no la hipótesis nula, es necesario incluir el tamaño del efecto para brindar una mejor idea del resultado encontrado, así como para posibles usos en futuros estudios (meta-análisis, cálculos de tamaños de muestra, potencia, etc.), y generar una base de resultados reportados en un área específica del saber para determinar qué se puede considerar como un efecto pequeño, mediano o grande <span class="citation">(American Psycological Association [APA] <a href="#ref-americanpsychologicalassociation2010">2010</a>; Cumming, <a href="#ref-cumming2012">2012</a>; Cumming &amp; Calin-Jageman, <a href="#ref-cumming2017">2017</a>; Nakagawa &amp; Cuthill, <a href="#ref-nakagawa2007br">2007</a>; Thompson, <a href="#ref-thompson2007ps">2007</a>; Tomczak &amp; Tomczak, <a href="#ref-tomczak2014tss">2014</a>)</span>.</p>
<div id="familias-de-tamaño-del-efecto" class="section level3">
<h3><span class="header-section-number">15.3.1</span> Familias de tamaño del efecto</h3>
<p>El tamaño del efecto puede presentarse en las unidades originales o de forma estandarizada (más usadas) y se reconocen dos familias: diferencia entre medias (familia <span class="math inline">\(d\)</span> y sus variantes), asociación/relación entre variables (familia <span class="math inline">\(r\)</span> y similares como <span class="math inline">\(R^2, \eta^2, \omega^2, V\)</span>), y dentro de lo posible es recomendable incluir intervalos de confianza <span class="citation">(Cohen, <a href="#ref-cohen1988">1988</a>; Cumming, <a href="#ref-cumming2012">2012</a>; Cumming &amp; Calin-Jageman, <a href="#ref-cumming2017">2017</a>; Lakens, <a href="#ref-lakens2013fp">2013</a>; Nakagawa &amp; Cuthill, <a href="#ref-nakagawa2007br">2007</a>)</span>. Para los tamaños de efecto es complicado calcular de forma manual los intervalos de confianza, en la mayoría de los casos se usa la distribución <span class="math inline">\(t\)</span> no-central, por lo que se recomienda utilizar métodos computacionales <span class="citation">(Cumming, <a href="#ref-cumming2012">2012</a>; Cumming &amp; Calin-Jageman, <a href="#ref-cumming2017">2017</a>)</span>.</p>
<div id="familia-d" class="section level4">
<h4><span class="header-section-number">15.3.1.1</span> Familia <span class="math inline">\(d\)</span></h4>
<p>La diferencia entre medias estandarizada se conoce como Cohen <span class="math inline">\(d\)</span> <span class="citation">(Cohen, <a href="#ref-cohen1988">1988</a>)</span>, de manera general se presenta en la Ecuación <a href="pruebas-estadísticas.html#eq:cohen-d-pop">(15.1)</a>, y se puede visualizar en la Figura <a href="pruebas-estadísticas.html#fig:cohen-d">15.2</a>. Se interpreta de manera similar a <span class="math inline">\(Z\)</span>, donde la diferencia entre medias está dada en función de una desviación estándar. La desviación estándar (denominador) es la que va a cambiar dependiendo de la prueba y condiciones de la misma (Tabla <a href="pruebas-estadísticas.html#tab:ES-p">15.1</a>).</p>
<p><span class="math display" id="eq:cohen-d-pop">\[\begin{equation}
  d = \frac{\bar{x}_1-\bar{x}_2}{\sigma}
  \tag{15.1}
\end{equation}\]</span></p>
<div class="figure" style="text-align: center"><span id="fig:cohen-d"></span>
<img src="geolonum_files/figure-html/cohen-d-1.png" alt="Representación del Cohen $d$." width="70%" />
<p class="caption">
Figura 15.2: Representación del Cohen <span class="math inline">\(d\)</span>.
</p>
</div>
<p>Hay dos factores que controlan el tamaño de <span class="math inline">\(d\)</span>, primero al incrementar la diferencia entre medias (manteniendo la dispersión constante) mayor será <span class="math inline">\(d\)</span>, segundo al disminuir la dispersión (manteniendo la diferencia de medias constante) mayor será <span class="math inline">\(d\)</span>. Estos dos factores van a influenciar el traslape entre las curvas, donde a mayor <span class="math inline">\(d\)</span> menor el traslape y mayor la diferencia entre las curvas y las muestras. Al igual que <span class="math inline">\(Z\)</span> puede tomar valores de <span class="math inline">\(-∞\)</span> a <span class="math inline">\(∞\)</span>.</p>
<p>Dada la naturaleza estadística del Cohen <span class="math inline">\(d\)</span> y la dificultad de su interpretación para personas con poco conocimiento estadístico, se han generado otras métricas comparables que pueden ser más fáciles de entender en términos generales. <span class="citation">Grissom &amp; Kim (<a href="#ref-grissom2005">2005</a>)</span>, <span class="citation">McGraw &amp; Wong (<a href="#ref-mcgraw1992pb">1992</a>)</span>, y <span class="citation">Ruscio (<a href="#ref-ruscio2008pm">2008</a>)</span> desarrollaron el concepto de probabilidad de superioridad (PS) o lenguaje común del tamaño del efecto (CL) el cuál se puede calcular de acuerdo a la Ecuación <a href="pruebas-estadísticas.html#eq:PS">(15.2)</a>. Este concepto se interpreta como la probabilidad de que un elemento del grupo con media superior (elegido al azar) tenga un valor superior al de un elemento del grupo con media inferior, y al ser una probabilidad se encuentra entre 0 y 100%, conforme mayor sea <span class="math inline">\(d\)</span> mayor será PS. <span class="citation">Reiser &amp; Faraggi (<a href="#ref-reiser1999jrss">1999</a>)</span> modificaron de <span class="citation">Cohen (<a href="#ref-cohen1988">1988</a>)</span> el traslape (OVL) entre las curvas (grupos), dado por la Ecuación <a href="pruebas-estadísticas.html#eq:traslape">(15.3)</a>, donde a mayor <span class="math inline">\(d\)</span> menor el traslape y más diferenciados los grupos. <span class="citation">Cohen (<a href="#ref-cohen1988">1988</a>)</span> definió el concepto de <span class="math inline">\(U_3\)</span>, denominado la medida de no-traslape, presentado en Ecuación <a href="pruebas-estadísticas.html#eq:U3">(15.4)</a>, y se puede interpretar como el porcentaje del grupo con media superior que va a estar por encima de la media del grupo con media inferior. Para todos estos casos <span class="math inline">\(\Phi\)</span> corresponde con la función de densidad acumulada de la distribución normal estándar <span class="math inline">\(Z\)</span>. <em>Cabe resaltar que éstos conceptos y cálculos se basan en grupos de mismo tamaño y misma desviación estándar</em>.Un muy buen recurso para visualizar todos estos conceptos lo brinda <span class="citation">Magnusson (<a href="#ref-magnusson2020">2020</a>)</span> en <a href="https://rpsychologist.com/d3/cohend/">Interpreting Cohen’s d</a>.</p>
<p><span class="math display" id="eq:PS">\[\begin{equation}
  PS = CL = \Phi \left( \frac{|d|}{\sqrt{2}} \right)
  \tag{15.2}
\end{equation}\]</span></p>
<p><span class="math display" id="eq:traslape">\[\begin{equation}
  OVL = 2 \Phi \left( \frac{-|d|}{2} \right)
  \tag{15.3}
\end{equation}\]</span></p>
<p><span class="math display" id="eq:U3">\[\begin{equation}
  U_3 = \Phi \left( |d| \right)
  \tag{15.4}
\end{equation}\]</span></p>
<p>Aquí se presenta cómo calcular estos conceptos en <strong>R</strong>, donde el único dato necesario es el <span class="math inline">\(d\)</span>.</p>
<pre class="sourceCode r"><code class="sourceCode r">d =<span class="st"> </span><span class="dv">2</span>
<span class="kw">pnorm</span>(<span class="kw">abs</span>(d)<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">2</span>))<span class="op">*</span><span class="dv">100</span> <span class="co"># PS, CL</span></code></pre>
<pre><code>## [1] 92.13504</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="dv">2</span><span class="op">*</span><span class="kw">pnorm</span>(<span class="op">-</span><span class="kw">abs</span>(d)<span class="op">/</span><span class="dv">2</span>)<span class="op">*</span><span class="dv">100</span> <span class="co"># traslape</span></code></pre>
<pre><code>## [1] 31.73105</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pnorm</span>(<span class="kw">abs</span>(d))<span class="op">*</span><span class="dv">100</span> <span class="co"># U3</span></code></pre>
<pre><code>## [1] 97.72499</code></pre>
</div>
<div id="familia-r" class="section level4">
<h4><span class="header-section-number">15.3.1.2</span> Familia <span class="math inline">\(r\)</span></h4>
<p>Los tamaños de efecto <span class="math inline">\(r, \ r_{pb}\)</span> y <span class="math inline">\(R^2\)</span> se interpretan como se presentó en las secciones <a href="estadística-descriptiva-bivariable.html#bivar-cor">10.3</a> y <a href="estadística-descriptiva-bivariable.html#bivar-reg-r2">10.4.4.2</a>, respectivamente. <span class="math inline">\(\eta^2\)</span> y <span class="math inline">\(\omega^2\)</span> se interpretan igual a <span class="math inline">\(R^2\)</span>, como el porcentaje de variación en la variable respuesta explicado por la variable predictora <span class="citation">(Cohen, <a href="#ref-cohen1988">1988</a>; Lakens, <a href="#ref-lakens2013fp">2013</a>; Tomczak &amp; Tomczak, <a href="#ref-tomczak2014tss">2014</a>)</span>.</p>
</div>
</div>
<div id="ecuaciones-para-tamaños-de-efecto" class="section level3">
<h3><span class="header-section-number">15.3.2</span> Ecuaciones para tamaños de efecto</h3>
<p>Muchos autores han trabajado en este tema, proponiendo mejoras a los tamaños de efecto inicialmente planteados y resumiendo los diferentes tamaños de efecto para las diferentes pruebas y condiciones <span class="citation">(Cohen, <a href="#ref-cohen1988">1988</a>; Cumming, <a href="#ref-cumming2012">2012</a>; Cumming &amp; Calin-Jageman, <a href="#ref-cumming2017">2017</a>; Ellis, <a href="#ref-ellis2010">2010</a>; Fritz et al., <a href="#ref-fritz2012joepg">2012</a>; Grissom &amp; Kim, <a href="#ref-grissom2005">2005</a>; Hedges &amp; Olkin, <a href="#ref-hedges1985">1985</a>; Lakens, <a href="#ref-lakens2013fp">2013</a>; McGrath &amp; Meyer, <a href="#ref-mcgrath2006pm">2006</a>; McGraw &amp; Wong, <a href="#ref-mcgraw1992pb">1992</a>; Nakagawa &amp; Cuthill, <a href="#ref-nakagawa2007br">2007</a>; Sheskin, <a href="#ref-sheskin2011">2011</a>; Thompson, <a href="#ref-thompson2007ps">2007</a>; Tomczak &amp; Tomczak, <a href="#ref-tomczak2014tss">2014</a>; Zou, <a href="#ref-zou2007pm">2007</a>)</span>. Aquí se presenta un resumen de los diferentes tamaños de efecto (Tabla <a href="pruebas-estadísticas.html#tab:ES-p">15.1</a>) y se remite al lector a revisar las referencias aquí mencionadas y las que se incluyen en las mismas, en el caso de querer ahondar en alguno de los casos presentados.</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:ES-p">Tabla 15.1: </span>Tamaños de efecto estandarizados para pruebas paramétricas
</caption>
<thead>
<tr>
<th style="text-align:center;">
Prueba
</th>
<th style="text-align:center;">
Tamaño de efecto
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;width: 15em; ">
Z de 1 muestra
</td>
<td style="text-align:center;width: 25em; ">
<span class="math display" id="eq:d-pop">\[\begin{equation}
              d_{pop} = \frac{\bar{x}-\mu_0}{\sigma}
              \tag{15.5}
              \end{equation}\]</span>
</td>
</tr>
<tr>
<td style="text-align:center;width: 15em; ">
t de 1 muestra
</td>
<td style="text-align:center;width: 25em; ">
<span class="math display" id="eq:d-t1">\[\begin{equation}
              d_s = \frac{\bar{x}-\mu_0}{s}
              \tag{15.6}
              \end{equation}\]</span>
</td>
</tr>
<tr>
<td style="text-align:center;width: 15em; ">
t de 2 muestras independientes
</td>
<td style="text-align:center;width: 25em; ">
<span class="math display" id="eq:d-t2-d">\[\begin{equation}
              d_s = \frac{\bar{x}_1-\bar{x}_2}{\sqrt{\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 - 2}}}
              \tag{15.7}
              \end{equation}\]</span>
</td>
</tr>
<tr>
<td style="text-align:center;width: 15em; ">
t de 2 muestras dependientes usando la desviación de las diferencias
</td>
<td style="text-align:center;width: 25em; ">
<span class="math display" id="eq:d-t2-dep1">\[\begin{equation}
              d_z = \frac{\bar{d}}{s_d}
              \tag{15.8}
              \end{equation}\]</span>
</td>
</tr>
<tr>
<td style="text-align:center;width: 15em; ">
t de 2 muestras dependientes tomando en cuenta la correlación
</td>
<td style="text-align:center;width: 25em; ">
<span class="math display" id="eq:d-t2-dep2">\[\begin{equation}
              d_{rm} = \frac{\bar{d}}{\sqrt{s_1^2 + s_2^2 - 2 \cdot r \cdot s_1 \cdot s_2}}\sqrt{2(1-r)}
              \tag{15.9}
              \end{equation}\]</span>
</td>
</tr>
<tr>
<td style="text-align:center;width: 15em; ">
t de 2 muestras dependientes usando el promedio de las desviaciones
</td>
<td style="text-align:center;width: 25em; ">
<span class="math display" id="eq:d-t2-dep3">\[\begin{equation}
              d_{av} = \frac{\bar{d}}{\sqrt{\frac{s_1^2 + s_2^2}{2}}}
              \tag{15.10}
              \end{equation}\]</span>
</td>
</tr>
<tr>
<td style="text-align:center;width: 15em; ">
t con corrección de Hedges
</td>
<td style="text-align:center;width: 25em; ">
<span class="math display" id="eq:d-g">\[\begin{equation}
              g = d \cdot \left( 1 - \frac{3}{4v-1} \right) = d \cdot \left( \frac{N-3}{N-2.25} \right)
              \tag{15.11}
              \end{equation}\]</span>
</td>
</tr>
<tr>
<td style="text-align:center;width: 15em; ">
Correlación punto biserial
</td>
<td style="text-align:center;width: 25em; ">
<span class="math display" id="eq:r-pb">\[\begin{equation}
              r_{pb} = \frac{\bar{y}_1-\bar{y}_0}{s_y}\sqrt{\frac{n_1 n_0}{N(N-1)}}
              \tag{15.12}
              \end{equation}\]</span>
</td>
</tr>
<tr>
<td style="text-align:center;width: 15em; ">
Correlación
</td>
<td style="text-align:center;width: 25em; ">
<span class="math display" id="eq:r">\[\begin{equation}
              r = \frac{\sum Z_xZ_y}{N-1}
              \tag{15.13}
              \end{equation}\]</span>
</td>
</tr>
<tr>
<td style="text-align:center;width: 15em; ">
Regresión
</td>
<td style="text-align:center;width: 25em; ">
<span class="math display" id="eq:r2">\[\begin{equation}
              R^2
              \tag{15.14}
              \end{equation}\]</span>
</td>
</tr>
<tr>
<td style="text-align:center;width: 15em; vertical-align: top !important;" rowspan="4">
ANOVA
</td>
<td style="text-align:center;width: 25em; ">
<span class="math display" id="eq:eta2-1">\[\begin{equation}
              \eta^2 = \frac{SC_{efecto}}{SC_{total}}
              \tag{15.15}
              \end{equation}\]</span>
</td>
</tr>
<tr>
<td style="text-align:center;width: 25em; ">
<span class="math display" id="eq:eta2-2">\[\begin{equation}
              \eta_p^2 = \frac{SC_{efecto}}{SC_{efecto}+SC_{error}}
              \tag{15.16}
              \end{equation}\]</span>
</td>
</tr>
<tr>
<td style="text-align:center;width: 25em; ">
<span class="math display" id="eq:omega2-1">\[\begin{equation}
              \omega^2 = \frac{v_{efecto}(CM_{efecto}-CM_{error})}{SC_{total}+CM_{error}}
              \tag{15.17}
              \end{equation}\]</span>
</td>
</tr>
<tr>
<td style="text-align:center;width: 25em; ">
<span class="math display" id="eq:omega2-2">\[\begin{equation}
              \omega_p^2 = \frac{v_{efecto}(CM_{efecto}-CM_{error})}{v_{efecto}CM_{efecto} + (N - v_{efecto})CM_{error}}
              \tag{15.18}
              \end{equation}\]</span>
</td>
</tr>
</tbody>
<tfoot>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<span style="font-style: italic;">Notas:</span>
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(\mu_0\)</span> = media poblacional
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(\sigma\)</span> = desviación estándar poblacional
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(\bar{x}_1\)</span> = media de muestra 1
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(\bar{x}_2\)</span> = media de muestra 2
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(s_1\)</span> = desviación estándar de muestra 1
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(s_2\)</span> = desviación estándar de muestra 2
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(s_1^2\)</span> = varianza de muestra 1
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(s_2^2\)</span> = varianza de muestra 2
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(n_1\)</span> = tamaño de muestra 1
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(n_2\)</span> = tamaño de muestra 2
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(N\)</span> = total de observaciones
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(v\)</span> = grados de libertad
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(\bar{d}\)</span> = media de la diferencia entre muestras
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(s_d\)</span> = desviación estándar de la diferencia entre muestras
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(r\)</span> = coeficiente de correlación de Pearson
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(r_{pb}\)</span> = coeficiente de correlación punto biserial
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(Z_x\)</span> = variable x estandarizada
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(Z_y\)</span> = variable y estandarizada
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(\bar{y}_1\)</span> = desviación estándar de la variable respuesta de grupo 1
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(\bar{y}_2\)</span> = desviación estándar de la variable respuesta de grupo 2
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(s_y\)</span> = desviación estándar de la variable respuesta
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(SC\)</span> = suma de cuadrados en ANOVA
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(CM\)</span> = cuadrados medios en ANOVA
</td>
</tr>
</tfoot>
</table>
<p>La corrección de Hedges (<span class="math inline">\(g\)</span>) se usa ya que <span class="math inline">\(d\)</span> se considera un estimador sesgado (biased) especialmente para muestras pequeñas, conforme mayor sea el tamaño de muestra más similares <span class="math inline">\(d\)</span> y <span class="math inline">\(g\)</span> <span class="citation">(Cumming, <a href="#ref-cumming2012">2012</a>; Cumming &amp; Calin-Jageman, <a href="#ref-cumming2017">2017</a>; Fritz et al., <a href="#ref-fritz2012joepg">2012</a>; McGrath &amp; Meyer, <a href="#ref-mcgrath2006pm">2006</a>)</span>. De manera similar <span class="math inline">\(\omega^2\)</span> corresponde con un estimador insesgado o menos sesgado de <span class="math inline">\(\eta^2\)</span> <span class="citation">(Fritz et al., <a href="#ref-fritz2012joepg">2012</a>; Lakens, <a href="#ref-lakens2013fp">2013</a>; Olejnik &amp; Algina, <a href="#ref-olejnik2000cep">2000</a>; Tomczak &amp; Tomczak, <a href="#ref-tomczak2014tss">2014</a>)</span>.</p>
<p>Así como se puede calcular el tamaño del efecto a partir de los datos, en algunos casos se puede calcular el tamaño del efecto a partir de los resultados de pruebas estadísticas u otros tamaños de efecto. Esta relación se muestra en la Tabla <a href="pruebas-estadísticas.html#tab:ES-conv">15.2</a>. En su mayoría estas relaciones son de utilidad cuando se revisan o quieren comparar estudios que reportan únicamente resultados de pruebas estadísticas pero no así el tamaño del efecto.</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:ES-conv">Tabla 15.2: </span>Tamaños de efecto a partir de pruebas estadísticas u otros tamaños de efecto
</caption>
<thead>
<tr>
<th style="text-align:center;">
Prueba
</th>
<th style="text-align:center;">
Tamaño de efecto
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;width: 15em; ">
t de 1 muestra
</td>
<td style="text-align:center;width: 25em; ">
<span class="math display" id="eq:d-t1-t">\[\begin{equation}
              d_s = \frac{t}{\sqrt{N}}
              \tag{15.19}
              \end{equation}\]</span>
</td>
</tr>
<tr>
<td style="text-align:center;width: 15em; ">
t de 2 muestras independientes
</td>
<td style="text-align:center;width: 25em; ">
<span class="math display" id="eq:d-t2-t">\[\begin{equation}
              d_s = t\sqrt{\frac{1}{n_1} + \frac{1}{n_2}} \sim \frac{2t}{\sqrt{N}}
              \tag{15.20}
              \end{equation}\]</span>
</td>
</tr>
<tr>
<td style="text-align:center;width: 15em; ">
t de 2 muestras dependientes usando la desviación de las diferencias
</td>
<td style="text-align:center;width: 25em; ">
<span class="math display" id="eq:d-t2-dep-t-dz">\[\begin{equation}
              d_z = \frac{t}{\sqrt{N}}
              \tag{15.21}
              \end{equation}\]</span>
</td>
</tr>
<tr>
<td style="text-align:center;width: 15em; ">
t de 2 muestras dependientes tomando en cuenta la correlación
</td>
<td style="text-align:center;width: 25em; ">
<span class="math display" id="eq:d-t2-dep-t-drm">\[\begin{equation}
              d_{rm} = t\sqrt{\frac{2(1-r)}{N}}
              \tag{15.22}
              \end{equation}\]</span>
</td>
</tr>
<tr>
<td style="text-align:center;width: 15em; ">
Correlación punto biserial
</td>
<td style="text-align:center;width: 25em; ">
<span class="math display" id="eq:r-pb-d">\[\begin{equation}
              r_{pb} = \frac{d_s}{\sqrt{d_s^2 + \frac{N^2-2N}{n_1  n_2}}}
              \tag{15.23}
              \end{equation}\]</span>
</td>
</tr>
<tr>
<td style="text-align:center;width: 15em; ">
ANOVA 1-factor con 2 grupos
</td>
<td style="text-align:center;width: 25em; ">
<span class="math display" id="eq:r-pb-eta2">\[\begin{equation}
              \eta_p^2 = r_{pb}^2 = \frac{t^2}{t^2+v}
              \tag{15.24}
              \end{equation}\]</span>
</td>
</tr>
</tbody>
<tfoot>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<span style="font-style: italic;">Notas:</span>
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(t\)</span> = estadístico de la prueba respectiva
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(n_1\)</span> = tamaño de muestra 1
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(n_2\)</span> = tamaño de muestra 2
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(N\)</span> = total de observaciones
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(r\)</span> = coeficiente de correlación de Pearson
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(r_{pb}\)</span> = coeficiente de correlación punto biserial
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(d_s\)</span> = Cohen d para 2 muestras independientes
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(v\)</span> = grados de libertad
</td>
</tr>
</tfoot>
</table>
</div>
<div id="clasificación-de-tamaños-de-efecto" class="section level3">
<h3><span class="header-section-number">15.3.3</span> Clasificación de tamaños de efecto</h3>
<p>Una pregunta que puede surgir es qué magnitud de los diferentes tamaños de efecto se puede considerar pequeña, mediana, o grande. <span class="citation">Cohen (<a href="#ref-cohen1988">1988</a>)</span> sugirió unos valores que se pueden usar como guías (Tabla <a href="pruebas-estadísticas.html#tab:ES-p-clas">15.3</a>), los cuales han surgido y fueron determinados como tales en las ciencias sociales. El mismo autor advierte sobre utilizar estos valores como definitivos y estrictos, y menciona que se debe aplicar criterio de experto en el área específica para determinar qué califica como pequeño, mediano, o grande.</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:ES-p-clas">Tabla 15.3: </span>Clases comúnmente usadas para diferentes tamaños de efecto
</caption>
<thead>
<tr>
<th style="border-bottom:hidden" colspan="2">
</th>
<th style="border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="3">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Clases del tamaño del efecto
</div>
</th>
</tr>
<tr>
<th style="text-align:center;">
Prueba
</th>
<th style="text-align:center;">
Tamaño de efecto
</th>
<th style="text-align:center;">
Pequeño
</th>
<th style="text-align:center;">
Mediano
</th>
<th style="text-align:center;">
Grande
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
Comparación de medias
</td>
<td style="text-align:center;">
<span class="math inline">\(d\)</span>, <span class="math inline">\(g\)</span>
</td>
<td style="text-align:center;">
0.20
</td>
<td style="text-align:center;">
0.50
</td>
<td style="text-align:center;">
0.80
</td>
</tr>
<tr>
<td style="text-align:center;vertical-align: top !important;" rowspan="3">
Correlación
</td>
<td style="text-align:center;">
<span class="math inline">\(r\)</span>
</td>
<td style="text-align:center;">
.10
</td>
<td style="text-align:center;">
.30
</td>
<td style="text-align:center;">
.50
</td>
</tr>
<tr>
<td style="text-align:center;">
<span class="math inline">\(R^2\)</span>
</td>
<td style="text-align:center;">
.01
</td>
<td style="text-align:center;">
.09
</td>
<td style="text-align:center;">
.25
</td>
</tr>
<tr>
<td style="text-align:center;">
<span class="math inline">\(r_{pb}\)</span>
</td>
<td style="text-align:center;">
.10
</td>
<td style="text-align:center;">
.24
</td>
<td style="text-align:center;">
.37
</td>
</tr>
<tr>
<td style="text-align:center;">
Regresión
</td>
<td style="text-align:center;">
<span class="math inline">\(R^2\)</span>
</td>
<td style="text-align:center;">
.02
</td>
<td style="text-align:center;">
.13
</td>
<td style="text-align:center;">
.26
</td>
</tr>
<tr>
<td style="text-align:center;">
ANOVA
</td>
<td style="text-align:center;">
<span class="math inline">\(\eta^2\)</span>, <span class="math inline">\(\omega^2\)</span>
</td>
<td style="text-align:center;">
.01
</td>
<td style="text-align:center;">
.06
</td>
<td style="text-align:center;">
.14
</td>
</tr>
</tbody>
<tfoot>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<span style="font-style: italic;">Nota:</span> <sup></sup> Conforme <span class="citation">Cohen (<a href="#ref-cohen1988">1988</a>)</span>
</td>
</tr>
</tfoot>
</table>
</div>
<div id="importancia-del-tamaño-del-efecto" class="section level3">
<h3><span class="header-section-number">15.3.4</span> Importancia del tamaño del efecto</h3>
<p>La importancia de reporat y utilizar tamaños de efecto para comparar resultados en diferentes estudios se presenta con un ejemplo sencillo pero ilustrativo.</p>
<p>Se tienen dos estudios (A y B) que analizaron el mismo fenómeno, por medio de una prueba <span class="math inline">\(t\)</span> de 2 muestras independientes. El estudio A reportó lo siguiente: <span class="math inline">\(t(79)=2.21, p&lt;.05\)</span>, mientras que el estudio B reportó lo siguiente: <span class="math inline">\(t(18)=1.06, p&gt;.3\)</span>.</p>
<p>A primera vista se podría concluir que los resultados de ambos estudios no coinciden y encontraron efectos diferentes. ¿Qué pasa con el tamaño del efecto? Si calculamos <span class="math inline">\(d\)</span> a aprtir de la Ecuación <a href="pruebas-estadísticas.html#eq:d-t2-t">(15.20)</a> para ambos estudios tenemos lo siguiente:</p>
<p><span class="math display">\[\begin{equation}
  d_s = \frac{2t}{\sqrt{N}}\\
  d_{sA} = \frac{2t_A}{\sqrt{N_A}} = \frac{2 \cdot 2.21}{\sqrt{80}} = 0.49\\
  d_{sB} = \frac{2t_B}{\sqrt{N_B}} = \frac{2 \cdot 1.06}{\sqrt{20}} = 0.47\\
\end{equation}\]</span></p>
<p>Al ver estos resultados se puede concluir que ambos estudios encontraron el mismo efecto (significancia práctica), la diferencia está simplemente en que el estudio B no tenía la sufuciente potencia (tamaño de muestra) para encontrar una significancia estadística.</p>
<p>Lo anterior deja claro que no se puede fiar únicamente en resultados de pruebas estadísticas (especialmente el valor-<em>p</em>) para comparar estudios, se necesita toda la información disponible y el tamaño del efecto.</p>
</div>
</div>
<div id="prueba-z1" class="section level2">
<h2><span class="header-section-number">15.4</span> <span class="math inline">\(z\)</span> de 1 muestra</h2>
<p>El uso de la prueba <span class="math inline">\(z\)</span> de 1 muestra se realiza con el ejemplo de la sección <a href="estimación-e-hipótesis.html#estim-ic-z">14.2.1.1</a> <span class="citation">(Walpole et al., <a href="#ref-walpole2012">2012</a>)</span>, donde se tenía una media muestral de <span class="math inline">\(2.6 \ g/ml\)</span> para una muestra de tamaño 36 y se asumía una desviación poblacional de <span class="math inline">\(0.3 \ g/ml\)</span>. Es posible que esta muestra provenga de una población con media 2.8 (<span class="math inline">\(\mu_0=2.8\)</span>)? Asuma <span class="math inline">\(\alpha = .05\)</span>.</p>
<p>Usando los pasos mencionados anteriormente (<a href="pruebas-estadísticas.html#supuestos-pasos">15.2.1</a>) se tiene:</p>
<ol style="list-style-type: decimal">
<li>Identificar la población, distribución, y la prueba apropiada:
<ul>
<li>Población: concentración de zinc en un río</li>
<li>Distribución: de medias</li>
<li>Prueba: <span class="math inline">\(Z\)</span> de 1 muestra porque se tiene 1 muestra, se quiere comparar con un valor hipotético, y se tiene <span class="math inline">\(\sigma\)</span></li>
</ul></li>
<li>Establecer las hipótesis nula y alterna:
<ul>
<li><span class="math inline">\(H_0: \mu = \mu_0 \to\)</span> La concentración de zinc en el río es <em>igual</em> a un valor hipotético o conocido (2.8)</li>
<li><span class="math inline">\(H_1: \mu \neq \mu_0 \to\)</span> La concentración de zinc en el río es <em>diferente</em> a un valor hipotético o conocido (2.8)</li>
</ul></li>
<li>Determinar parámetros de la distribución a comparar (<span class="math inline">\(H_0\)</span>):
<ul>
<li><span class="math inline">\(\mu_0 = 2.8\)</span></li>
<li><span class="math inline">\(\sigma_\bar{x} = \frac{\sigma}{\sqrt{n}} = \frac{0.3}{\sqrt{36}} = 0.05\)</span></li>
</ul></li>
<li>Determinar valores críticos
<ul>
<li><span class="math inline">\(\alpha = .05\)</span></li>
<li><span class="math inline">\(z_{\alpha/2} = z_{.05/2} = |1.96|\)</span></li>
</ul></li>
<li>Calcular el estadístico de prueba
<ul>
<li><span class="math inline">\(Z = \frac{\bar{x} - \mu}{\sigma_\bar{x}} = \frac{2.6 - 2.8}{0.05} = -4\)</span></li>
<li><span class="math inline">\(2.6 \pm 0.1 \to 95\% \ IC \ [2.50,2.70]\)</span></li>
</ul></li>
<li>Tomar una decisión
<ul>
<li>El estadístico de prueba es mayor al crítico, <span class="math inline">\(z &gt; z_{\alpha/2}\)</span></li>
<li>El valor-<em>p</em> es menor a <span class="math inline">\(\alpha = .05\)</span>, <span class="math inline">\(p &lt; .001\)</span></li>
<li>El valor hipotético del parámetro cae fuera del intervalo de confianza, <span class="math inline">\(IC \ [2.50,2.70]\)</span></li>
<li><em>Decisión</em>: Se rechaza <span class="math inline">\(H_0\)</span></li>
</ul></li>
</ol>
<p>En <strong>R</strong> el paquete <em>DescTools</em> tiene la función <code>ZTest</code> para realizar esta prueba, pero necesita un vector de datos, por lo que se genera un vector aleatorio, y se demuestra a continuación.</p>
<pre class="sourceCode r"><code class="sourceCode r">x =<span class="st"> </span><span class="fl">2.6</span>
n =<span class="st"> </span><span class="dv">36</span>
sig =<span class="st"> </span><span class="fl">0.3</span>
mu0 =<span class="st"> </span><span class="fl">2.8</span>
a =<span class="st"> </span><span class="fl">0.05</span>

<span class="kw">set.seed</span>(<span class="dv">123</span>)
vec =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n =</span> n, <span class="dt">mean =</span> x, <span class="dt">sd =</span> sig)

z1.res =<span class="st"> </span><span class="kw">ZTest</span>(vec, 
               <span class="dt">mu =</span> mu0, <span class="co"># valor del parámetro a comparar</span>
               <span class="dt">sd_pop =</span> sig, <span class="co"># deviación poblacional</span>
               <span class="dt">conf.level =</span> <span class="dv">1</span><span class="op">-</span>a) <span class="co"># nivel de confianza</span>
z1.res</code></pre>
<pre><code>## 
##  One Sample z-test
## 
## data:  vec
## z = -3.6664, Std. Dev. Population = 0.3, p-value = 0.000246
## alternative hypothesis: true mean is not equal to 2.8
## 95 percent confidence interval:
##  2.518683 2.714680
## sample estimates:
## mean of x 
##  2.616681</code></pre>
<p>El tamaño del efecto se puede calcular de acuerdo a la Ecuación <a href="pruebas-estadísticas.html#eq:d-pop">(15.5)</a> de la siguiente manera:</p>
<p><span class="math display">\[\begin{equation}
  d_{pop} = \frac{\bar{x}-\mu_0}{\sigma}\\
  d_{pop} = \frac{2.6-2.8}{0.3} = -0.67
\end{equation}\]</span></p>
<p>En <strong>R</strong> se puede calcular de forma básica y el intervalo de confianza con la función <code>d.ci</code> del paquete <em>psych</em> <span class="citation">(Revelle, <a href="#ref-R-psych">2020</a>)</span>, donde es necesario indicar <span class="math inline">\(d\)</span> y <span class="math inline">\(n\)</span>.</p>
<pre class="sourceCode r"><code class="sourceCode r">dpop =<span class="st"> </span>(x <span class="op">-</span><span class="st"> </span>mu0) <span class="op">/</span><span class="st"> </span>sig

dpop.ci =<span class="st"> </span><span class="kw">d.ci</span>(dpop,<span class="dt">n1=</span>n) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(<span class="dv">2</span>)
dpop.ci</code></pre>
<pre><code>##      lower effect upper
## [1,] -1.02  -0.67  -0.3</code></pre>
<p>Usando las medidas PS, OVL, y <span class="math inline">\(U_3\)</span> (Figura <a href="pruebas-estadísticas.html#fig:z1-u3">15.3</a>).</p>
<pre><code>## # A tibble: 1 x 3
##      PS   OVL    U3
##   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1  68.1  73.9  74.8</code></pre>
<div class="figure" style="text-align: center"><span id="fig:z1-u3"></span>
<img src="geolonum_files/figure-html/z1-u3-1.png" alt="$U_3$ para el ejemplo de la prueba $z$ de 1 muestra. **A** Corresponde con los datos en escala original. **B** Corresponde con el tamaño del efecto $d$." width="70%" />
<p class="caption">
Figura 15.3: <span class="math inline">\(U_3\)</span> para el ejemplo de la prueba <span class="math inline">\(z\)</span> de 1 muestra. <strong>A</strong> Corresponde con los datos en escala original. <strong>B</strong> Corresponde con el tamaño del efecto <span class="math inline">\(d\)</span>.
</p>
</div>
<blockquote>
<p>Conclusión: La concentración de zinc (<span class="math inline">\(M = 2.62\)</span>, 95% IC <span class="math inline">\([2.52\)</span>, <span class="math inline">\(2.71]\)</span>) es significativamente diferente a la media de 2.8 g/ml, <span class="math inline">\(z(36) = -3.67\)</span>, <span class="math inline">\(p &lt; .001\)</span>, <span class="math inline">\(d = -0.67 \ [-1.02, -0.3]\)</span>. El efecto se puede considerar mediano, pero con un rango de pequeño hasta muy grande. Hay una probabilidad de 68.1% (PS) que un elemento de la población hipotética tenga una concentración mayor a un elemento de la muestra; las dos curvas se traslapan en un 73.9% (OVL); el 74.8% (<span class="math inline">\(U_3\)</span>) de la población hipotética se encuentra por encima de la media de la muestra.</p>
</blockquote>
</div>
<div id="prueba-t1" class="section level2">
<h2><span class="header-section-number">15.5</span> <span class="math inline">\(t\)</span> de 1 muestra</h2>
<p>El uso de la prueba <span class="math inline">\(t\)</span> de 1 muestra se realiza con el ejemplo de la sección <a href="estimación-e-hipótesis.html#estim-ic-t">14.2.1.2</a> <span class="citation">(Swan &amp; Sandilands, <a href="#ref-swan1995">1995</a>)</span>, donde se tenía el contenido de cuarzo en secciones delgadas de una roca ígnea. Es posible que esta muestra provenga de una población con media 20% (<span class="math inline">\(\mu_0=20\)</span>)? Asuma <span class="math inline">\(\alpha = .05\)</span>.</p>
<ol style="list-style-type: decimal">
<li>Identificar la población, distribución, y la prueba apropiada:
<ul>
<li>Población: contenido de cuarzo en la roca ígnea</li>
<li>Distribución: de medias</li>
<li>Prueba: <span class="math inline">\(t\)</span> de 1 muestra porque se tiene 1 muestra, se quiere comparar con un valor hipotético, y no se tiene <span class="math inline">\(\sigma\)</span></li>
</ul></li>
<li>Establecer las hipótesis nula y alterna:
<ul>
<li><span class="math inline">\(H_0: \mu = \mu_0 \to\)</span> El contenido de cuarzo en la roca ígnea es <em>igual</em> a un valor hipotético o conocido (20)</li>
<li><span class="math inline">\(H_1: \mu \neq \mu_0 \to\)</span> El contenido de cuarzo en la roca ígnea es <em>diferente</em> a un valor hipotético o conocido (20)</li>
</ul></li>
<li>Determinar parámetros de la distribución a comparar (<span class="math inline">\(H_0\)</span>):
<ul>
<li><span class="math inline">\(\mu_0 = 20\)</span></li>
<li><span class="math inline">\(s_\bar{x} = \frac{s}{\sqrt{n}} = \frac{3.083}{\sqrt{8}} = 1.09\)</span></li>
</ul></li>
<li>Determinar valores críticos
<ul>
<li><span class="math inline">\(\alpha = .05\)</span></li>
<li><span class="math inline">\(t_{\alpha/2,v} = t_{.05/2,7} = |2.365|\)</span></li>
</ul></li>
<li>Calcular el estadístico de prueba
<ul>
<li><span class="math inline">\(t = \frac{\bar{x} - \mu}{s_\bar{x}} = \frac{21.5 - 20}{1.09} = 1.37\)</span></li>
<li><span class="math inline">\(21.512 \pm 2.578 \to 95\% \ IC \ [18.93, 24.09]\)</span></li>
</ul></li>
<li>Tomar una decisión
<ul>
<li>El estadístico de prueba es menor al crítico, <span class="math inline">\(t &lt; t_{\alpha/2,v}\)</span></li>
<li>El valor-<em>p</em> es mayor a <span class="math inline">\(\alpha = .05\)</span>, <span class="math inline">\(p = .2079\)</span></li>
<li>El valor hipotético del parámetro cae dentro del intervalo de confianza, <span class="math inline">\(IC \ [18.93, 24.09]\)</span></li>
<li><em>Decisión</em>: No se rechaza <span class="math inline">\(H_0\)</span></li>
</ul></li>
</ol>
<p><strong>R</strong> trae la función <code>t.test</code> que puede realizar las diferentes pruebas <span class="math inline">\(t\)</span>. Para el caso de 1 muestra se brinda el vector de datos, la media poblacional con la cual comparar (<code>mu</code>), y el nivel de confianza.</p>
<pre class="sourceCode r"><code class="sourceCode r">mu0 =<span class="st"> </span><span class="dv">20</span>
a =<span class="st"> </span><span class="fl">0.05</span>

cuarzo =<span class="st"> </span><span class="kw">c</span>(<span class="fl">23.5</span>, <span class="fl">16.6</span>, <span class="fl">25.4</span>, <span class="fl">19.1</span>, <span class="fl">19.3</span>, <span class="fl">22.4</span>, <span class="fl">20.9</span>, <span class="fl">24.9</span>)

t1.res =<span class="st"> </span><span class="kw">t.test</span>(cuarzo, 
                <span class="dt">mu =</span> mu0, 
                <span class="dt">conf.level =</span> <span class="dv">1</span><span class="op">-</span>a)
t1.res</code></pre>
<pre><code>## 
##  One Sample t-test
## 
## data:  cuarzo
## t = 1.3875, df = 7, p-value = 0.2079
## alternative hypothesis: true mean is not equal to 20
## 95 percent confidence interval:
##  18.93477 24.09023
## sample estimates:
## mean of x 
##   21.5125</code></pre>
<p>El tamaño del efecto se puede calcular de acuerdo a la Ecuación <a href="pruebas-estadísticas.html#eq:d-t1">(15.6)</a> de la siguiente manera:</p>
<p><span class="math display">\[\begin{equation}
  d_s = \frac{\bar{x}-\mu_0}{s}\\
  d_s = \frac{21.5-20}{3.083} = 0.49
\end{equation}\]</span></p>
<p>En <strong>R</strong> se puede calcular con la función <code>d.single.t</code> del paquete <em>MOTE</em> <span class="citation">(Buchanan et al., <a href="#ref-R-MOTE">2019</a>)</span>, donde es necesario indicar la media muestral, media poblacional a comparar, desviación estándar muestral, tamaño de la muestra, y nivel de significancia.</p>
<pre class="sourceCode r"><code class="sourceCode r">d.t1.res =<span class="st"> </span><span class="kw">d.single.t</span>(<span class="dt">m =</span> <span class="kw">mean</span>(cuarzo), 
                      <span class="dt">u =</span> mu0, 
                      <span class="dt">sd =</span> <span class="kw">sd</span>(cuarzo), 
                      <span class="dt">n =</span> <span class="kw">length</span>(cuarzo), 
                      <span class="dt">a =</span> a)
d.t1.res[<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">unlist</span>()</code></pre>
<pre><code>##          d       dlow      dhigh 
##  0.4905400 -0.2619016  1.2128190</code></pre>
<p>Usando las medidas PS, OVL, y <span class="math inline">\(U_3\)</span> (Figura <a href="pruebas-estadísticas.html#fig:t1-u3">15.4</a>).</p>
<pre><code>## # A tibble: 1 x 3
##      PS   OVL    U3
##   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1  63.6  80.6  68.8</code></pre>
<div class="figure" style="text-align: center"><span id="fig:t1-u3"></span>
<img src="geolonum_files/figure-html/t1-u3-1.png" alt="$U_3$ para el ejemplo de la prueba $t$ de 1 muestra. **A** Corresponde con los datos en escala original. **B** Corresponde con el tamaño del efecto $d$." width="70%" />
<p class="caption">
Figura 15.4: <span class="math inline">\(U_3\)</span> para el ejemplo de la prueba <span class="math inline">\(t\)</span> de 1 muestra. <strong>A</strong> Corresponde con los datos en escala original. <strong>B</strong> Corresponde con el tamaño del efecto <span class="math inline">\(d\)</span>.
</p>
</div>
<blockquote>
<p>Conclusión: El contenido de cuarzo de la roca ígnea (<span class="math inline">\(M = 21.51\)</span>, 95% IC <span class="math inline">\([18.93\)</span>, <span class="math inline">\(24.09]\)</span>) no es significativamente diferente a la media de 20% , <span class="math inline">\(t(7) = 1.39\)</span>, <span class="math inline">\(p = .208\)</span>, <span class="math inline">\(d\)</span> = 0.49 <span class="math inline">\([-0.26, 1.21]\)</span>. El efecto se puede considerar mediano, pero con un rango de pequeño, en dirección opuesta, hasta muy grande. Hay una probabilidad de 63.6% (PS) que un elemento de la muestra tenga un contenido de cuarzo mayor a un elemento de la población hipotética; las dos curvas se traslapan en un 80.6% (OVL); el 68.8% (<span class="math inline">\(U_3\)</span>) de la muestra se encuentra por encima de la media de la población hipotética.</p>
</blockquote>
<div class="figure" style="text-align: center"><span id="fig:t1-stats"></span>
<img src="geolonum_files/figure-html/t1-stats-1.png" alt="Histograma del contenido de cuarzo, mostrando la media muestral (azul) y el valor a comparar (rojo), así como el resumen estadístico respectivo." width="90%" />
<p class="caption">
Figura 15.5: Histograma del contenido de cuarzo, mostrando la media muestral (azul) y el valor a comparar (rojo), así como el resumen estadístico respectivo.
</p>
</div>
</div>
<div id="prueba-t2-ind" class="section level2">
<h2><span class="header-section-number">15.6</span> <span class="math inline">\(t\)</span> de 2 muestras independientes</h2>
<p>Para este caso es cuando, en teoría, se debiera cumplir no solo la normalidad de las muestras, sino también la igualdad de varianzas. Si se quiere relajar el supuesto de igualdad de varianzas se usa el estadístico Welch o Welch-Satterthwaite (<a href="estimación-e-hipótesis.html#estim-ic-t2-ind">14.2.2.2.1</a> - varianzas diferentes). En general la diferencia entre asumir igualdad de varianzas o no va a ser pequeña, siempre y cuando éstas no sean muy diferentes y los tamaños de muestra no sean muy disparejos, y es recomendado indicar qué método se usó <span class="citation">(Cumming &amp; Calin-Jageman, <a href="#ref-cumming2017">2017</a>)</span>.</p>
<p>El uso de la prueba <span class="math inline">\(t\)</span> de 2 muestras independientes se realiza con el ejemplo de la sección <a href="estimación-e-hipótesis.html#estim-ic-t2-ind">14.2.2.2.1</a> <span class="citation">(Swan &amp; Sandilands, <a href="#ref-swan1995">1995</a>)</span>, el de varianzas iguales, donde se tenían braquiópodos en dos capas (A, B) y se les midió la longitud (cm). Es posible que estas muestras provenga de una misma población (<span class="math inline">\(\mu_1=\mu_2\)</span>)? Asuma <span class="math inline">\(\alpha = .05\)</span>.</p>
<ol style="list-style-type: decimal">
<li>Identificar la población, distribución, y la prueba apropiada:
<ul>
<li>Población: braquiópodos en capas A y B</li>
<li>Distribución: diferencia de medias</li>
<li>Prueba: <span class="math inline">\(t\)</span> de 2 muestras independientes porque se tienen 2 muestras, y las dos provienen de sitios diferentes (independientes uno del otro)</li>
</ul></li>
<li>Establecer las hipótesis nula y alterna:
<ul>
<li><span class="math inline">\(H_0: \mu_1 = \mu_2 \to\)</span> La longitud e los braquiópodos en la capa A es <em>igual</em> a la longitud e los braquiópodos en la capa B</li>
<li><span class="math inline">\(H_1: \mu \neq \mu_0 \to\)</span> La longitud e los braquiópodos en la capa A es <em>diferente</em> la longitud e los braquiópodos en la capa B</li>
</ul></li>
<li>Determinar parámetros de la distribución a comparar (<span class="math inline">\(H_0\)</span>):
<ul>
<li><span class="math inline">\(\mu_1 - \mu_2 = 0\)</span></li>
<li><span class="math inline">\(s_p = \sqrt{\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 - 2}} = \sqrt{\frac{(8-1)0.042 + (10-1)0.029}{8 + 10 - 2}} = 0.1865\)</span></li>
<li><span class="math inline">\(s_{\bar{x}_1-\bar{x}_2} = s_p \sqrt{\frac{1}{n_1} + \frac{1}{n_2}} = 0.1865 \sqrt{\frac{1}{8} + \frac{1}{10}} = 0.0885\)</span></li>
</ul></li>
<li>Determinar valores críticos
<ul>
<li><span class="math inline">\(\alpha = .05\)</span></li>
<li><span class="math inline">\(t_{\alpha/2,v} = t_{.05/2,16} = |2.12|\)</span></li>
</ul></li>
<li>Calcular el estadístico de prueba
<ul>
<li><span class="math inline">\(t = \frac{(\bar{x}_1-\bar{x}_2) - (\mu_1-\mu_2)}{s_{\bar{x}_1-\bar{x}_2}} = \frac{(3.125-2.96) - 0}{0.0885} = 1.86\)</span></li>
<li><span class="math inline">\(0.165 \pm 0.1876 \to 95\% \ IC \ [-0.023,0.353]\)</span></li>
</ul></li>
<li>Tomar una decisión
<ul>
<li>El estadístico de prueba es menor al crítico, <span class="math inline">\(t &lt; t_{\alpha/2,v}\)</span></li>
<li>El valor-<em>p</em> es mayor a <span class="math inline">\(\alpha = .05\)</span>, <span class="math inline">\(p = .081\)</span></li>
<li>El valor de <span class="math inline">\(0\)</span> cae dentro del intervalo de confianza, <span class="math inline">\(IC \ [-0.023,0.353]\)</span></li>
<li><em>Decisión</em>: No se rechaza <span class="math inline">\(H_0\)</span></li>
</ul></li>
</ol>
<p><strong>R</strong> trae la función <code>t.test</code> que puede realizar las diferentes pruebas <span class="math inline">\(t\)</span>. Para el caso de 2 muestras independientes se brindan los vectores de datos, el indicador lógico de si las varianzas se deben considerar iguales, y el nivel de confianza.</p>
<pre class="sourceCode r"><code class="sourceCode r">a =<span class="st"> </span><span class="fl">0.05</span>

A =<span class="st"> </span><span class="kw">c</span>(<span class="fl">3.2</span>, <span class="fl">3.1</span>, <span class="fl">3.1</span>, <span class="fl">3.3</span>, <span class="fl">2.9</span>, <span class="fl">2.9</span>, <span class="fl">3.5</span>, <span class="fl">3.0</span>)
B =<span class="st"> </span><span class="kw">c</span>(<span class="fl">3.1</span>, <span class="fl">3.1</span>, <span class="fl">2.8</span>, <span class="fl">3.1</span>, <span class="fl">3.0</span>, <span class="fl">2.6</span>, <span class="fl">3.0</span>, <span class="fl">3.0</span>, <span class="fl">3.1</span>, <span class="fl">2.8</span>)

braq =<span class="st"> </span><span class="kw">stack</span>(<span class="kw">list</span>(<span class="dt">A=</span>A,
                  <span class="dt">B=</span>B))

t2.ind.res =<span class="st"> </span><span class="kw">t.test</span>(<span class="dt">x =</span> A,
                    <span class="dt">y =</span> B,
                    <span class="dt">var.equal =</span> T, 
                    <span class="dt">conf.level =</span> <span class="dv">1</span><span class="op">-</span>a)
t2.ind.res</code></pre>
<pre><code>## 
##  Two Sample t-test
## 
## data:  A and B
## t = 1.861, df = 16, p-value = 0.08122
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.02295489  0.35295489
## sample estimates:
## mean of x mean of y 
##     3.125     2.960</code></pre>
<p>Como se mencionó en la sección <a href="estimación-e-hipótesis.html#estim-ic-t2-ind">14.2.2.2.1</a>, las pruebas de hipótesis se pueden aproximar por medio de la estimación, más específicamente, los intervalos de confianza (Figura <a href="pruebas-estadísticas.html#fig:t2-ind-ci">15.6</a>), siguiendo las guías de <span class="citation">Cumming &amp; Finch (<a href="#ref-cumming2005ap">2005</a>)</span>, <span class="citation">Cumming (<a href="#ref-cumming2012">2012</a>)</span>, y <span class="citation">Cumming &amp; Calin-Jageman (<a href="#ref-cumming2017">2017</a>)</span>. El intervalo de confianza para el parámetro de interés se puede comparar con <span class="math inline">\(H_0\)</span>, y se puede obtener la misma conclusión a realizar la prueba estadística.</p>
<div class="figure" style="text-align: center"><span id="fig:t2-ind-ci"></span>
<img src="geolonum_files/figure-html/t2-ind-ci-1.png" alt="Intervalos de confianza para la prueba t de 2 muestras independientes. El valor de 0 cae dentro del intervalo de confianza para la diferencia, por lo que se pueden considerar iguales o que no hay diferencia entre las capas." width="70%" />
<p class="caption">
Figura 15.6: Intervalos de confianza para la prueba t de 2 muestras independientes. El valor de 0 cae dentro del intervalo de confianza para la diferencia, por lo que se pueden considerar iguales o que no hay diferencia entre las capas.
</p>
</div>
<p>El tamaño del efecto se puede calcular de acuerdo a las Ecuaciones <a href="pruebas-estadísticas.html#eq:d-t2-d">(15.7)</a> y <a href="pruebas-estadísticas.html#eq:d-g">(15.11)</a>, donde de manera general se usa la desviación agrupada (pooled standard deviation ,<span class="math inline">\(s_p\)</span>) como el estandarizador, sin importar si se asumen varianzas iguales o no para la prueba, pero es buena práctica reportar qué se uso como estandarizador <span class="citation">(Cumming &amp; Calin-Jageman, <a href="#ref-cumming2017">2017</a>)</span>.</p>
<p><span class="math display">\[\begin{equation}
  d_s = \frac{\bar{x}_1-\bar{x}_2}{\sqrt{\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 - 2}}}\\
  d_s = \frac{3.125-2.96}{\sqrt{\frac{(8-1)0.042 + (10-1)0.029}{8 + 10 - 2}}} = 0.88
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
  g_s = d_s \cdot \left( 1 - \frac{3}{4v-1} \right)\\
  g_s = 0.88 \cdot \left( 1 - \frac{3}{4(16)-1} \right) = 0.84
\end{equation}\]</span></p>
<p>En <strong>R</strong> se puede calcular <span class="math inline">\(d_s\)</span> con la función <code>d.ind.t</code> y <span class="math inline">\(g_s\)</span> con la función <code>g.ind.t</code> del paquete <em>MOTE</em>, donde es necesario indicar la media muestral de ambas muestras, desviación estándar muestral de ambas muestras, tamaño ambas muestras, y nivel de significancia. Adicionalmente existen las funciones <code>cohens_d</code> y <code>hedges_g</code> de <em>effectsize</em> <span class="citation">(Ben-Shachar et al., <a href="#ref-R-effectsize">2020</a>)</span>, y <code>cohen.d</code> de <em>effsize</em> <span class="citation">(Torchiano, <a href="#ref-R-effsize">2018</a>)</span>.</p>
<p>Usando <em>MOTE</em></p>
<pre class="sourceCode r"><code class="sourceCode r">d.t2.ind.res =<span class="st"> </span><span class="kw">d.ind.t</span>(<span class="dt">m1 =</span> <span class="kw">mean</span>(A), <span class="dt">m2 =</span> <span class="kw">mean</span>(B), 
                       <span class="dt">sd1 =</span> <span class="kw">sd</span>(A), <span class="dt">sd2 =</span> <span class="kw">sd</span>(B), 
                       <span class="dt">n1 =</span> <span class="kw">length</span>(A), <span class="dt">n2 =</span> <span class="kw">length</span>(B),
                       <span class="dt">a =</span> a)
d.t2.ind.res[<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">unlist</span>()</code></pre>
<pre><code>##          d       dlow      dhigh 
##  0.8827506 -0.1075693  1.8483100</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">g.t2.ind.res =<span class="st"> </span><span class="kw">g.ind.t</span>(<span class="dt">m1 =</span> <span class="kw">mean</span>(A), <span class="dt">m2 =</span> <span class="kw">mean</span>(B), 
                       <span class="dt">sd1 =</span> <span class="kw">sd</span>(A), <span class="dt">sd2 =</span> <span class="kw">sd</span>(B), 
                       <span class="dt">n1 =</span> <span class="kw">length</span>(A), <span class="dt">n2 =</span> <span class="kw">length</span>(B),
                       <span class="dt">a =</span> a)
g.t2.ind.res[<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">unlist</span>()</code></pre>
<pre><code>##          d       dlow      dhigh 
##  0.8407149 -0.1024469  1.7602953</code></pre>
<p>Usando <em>effectsize</em></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cohens_d</span>(A,B,
         <span class="dt">ci =</span> <span class="dv">1</span><span class="op">-</span>a)</code></pre>
<pre><code>## # A tibble: 1 x 4
##   Cohens_d    CI CI_low CI_high
##      &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;
## 1    0.883  0.95 -0.108    1.85</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">hedges_g</span>(A,B,
         <span class="dt">ci =</span> <span class="dv">1</span><span class="op">-</span>a)</code></pre>
<pre><code>## # A tibble: 1 x 4
##   Hedges_g    CI CI_low CI_high
##      &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;
## 1    0.841  0.95 -0.102    1.76</code></pre>
<p>Usando <em>effsize</em></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cohen.d</span>(A,B,
        <span class="dt">conf.level =</span> <span class="dv">1</span><span class="op">-</span>a,
        <span class="dt">noncentral=</span>T)</code></pre>
<pre><code>## 
## Cohen&#39;s d
## 
## d estimate: 0.8827506 (large)
## 95 percent confidence interval:
##      lower      upper 
## -0.1075693  1.8483100</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cohen.d</span>(A,B,
        <span class="dt">conf.level =</span> <span class="dv">1</span><span class="op">-</span>a,
        <span class="dt">hedges.correction =</span> T,
        <span class="dt">noncentral=</span>T)</code></pre>
<pre><code>## 
## Hedges&#39;s g
## 
## g estimate: 0.8407149 (large)
## 95 percent confidence interval:
##      lower      upper 
## -0.1075693  1.8483100</code></pre>
<p>Usando las medidas PS, OVL, y <span class="math inline">\(U_3\)</span> (Figura <a href="pruebas-estadísticas.html#fig:t2-ind-u3">15.7</a>).</p>
<pre><code>## # A tibble: 1 x 3
##      PS   OVL    U3
##   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1  73.4  65.9  81.1</code></pre>
<div class="figure" style="text-align: center"><span id="fig:t2-ind-u3"></span>
<img src="geolonum_files/figure-html/t2-ind-u3-1.png" alt="$U_3$ para el ejemplo de la prueba $t$ de 2 muestras independientes. **A** Corresponde con los datos en escala original. **B** Corresponde con el tamaño del efecto $d$." width="70%" />
<p class="caption">
Figura 15.7: <span class="math inline">\(U_3\)</span> para el ejemplo de la prueba <span class="math inline">\(t\)</span> de 2 muestras independientes. <strong>A</strong> Corresponde con los datos en escala original. <strong>B</strong> Corresponde con el tamaño del efecto <span class="math inline">\(d\)</span>.
</p>
</div>
<blockquote>
<p>Conclusión: La longitud de los braquiópodos en la capa A no es significativamente diferente de la longitud de los braquiópodos en la capa B (<span class="math inline">\(\Delta M = 0.165\)</span>, 95% IC <span class="math inline">\([-0.023\)</span>, <span class="math inline">\(0.353]\)</span>), <span class="math inline">\(t(16) = 1.86\)</span>, <span class="math inline">\(p = .081\)</span>, <span class="math inline">\(d_s\)</span> = 0.88 <span class="math inline">\([-0.11, 1.85]\)</span>. El efecto se puede considerar grande, pero con un rango de muy pequeño, en dirección opuesta, hasta muy grande. Hay una probabilidad de 73.4% (PS) que un elemento de la muestra A tenga una longitud mayor que un elemento de la muestra B; las dos curvas se traslapan en un 65.9% (OVL); el 81.8% (<span class="math inline">\(U_3\)</span>) de la muestra A se encuentra por encima de la media de la muestra B.</p>
</blockquote>
<div class="figure" style="text-align: center"><span id="fig:t2-ind-stats"></span>
<img src="geolonum_files/figure-html/t2-ind-stats-1.png" alt="Gráfico de caja mostrando el efecto de la capa sobre la longitud de los braquiópodos, así como el resumen estadístico respectivo." width="90%" />
<p class="caption">
Figura 15.8: Gráfico de caja mostrando el efecto de la capa sobre la longitud de los braquiópodos, así como el resumen estadístico respectivo.
</p>
</div>
</div>
<div id="prueba-t2-dep" class="section level2">
<h2><span class="header-section-number">15.7</span> <span class="math inline">\(t\)</span> de 2 muestras dependientes</h2>
<p>Estas muestras que miden la misma observación (objeto, sujeto) más de una vez también se conocen como <em>muestras pareadas</em> o <em>mediciones repetidas</em> (repeated measures - en inglés).</p>
<p>El uso de la prueba <span class="math inline">\(t\)</span> de 2 muestras dependientes se realiza con el ejemplo de la sección <a href="estimación-e-hipótesis.html#estim-ic-t2-dep">14.2.2.2.2</a> <span class="citation">(McKillup &amp; Darby Dyar, <a href="#ref-mckillup2010">2010</a>)</span>, donde se tenía el contenido de <span class="math inline">\(FeO\)</span> en porcentaje de peso para 10 granitos que fueron preparados a diferentes tamaños de grano: <span class="math inline">\(&lt; 25 \ \mu m\)</span> y <span class="math inline">\(&lt; 125 \ \mu m\)</span>. Hay un efecto en el tratamiento, en este caso, cambio del tamaño de grano (<span class="math inline">\(\mu_D=0\)</span>)? Asuma <span class="math inline">\(\alpha = .05\)</span>.</p>
<ol style="list-style-type: decimal">
<li>Identificar la población, distribución, y la prueba apropiada:
<ul>
<li>Población: contenido de <span class="math inline">\(FeO\)</span> a diferentes tamaños de grano: <span class="math inline">\(&lt; 25 \ \mu m\)</span> y <span class="math inline">\(&lt; 125 \ \mu m\)</span></li>
<li>Distribución: media de las diferencia</li>
<li>Prueba: <span class="math inline">\(t\)</span> de 2 muestras dependientes porque se tienen los mismos elementos antes y después de un tratamiento (cambio de tamaño de grano)</li>
</ul></li>
<li>Establecer las hipótesis nula y alterna:
<ul>
<li><span class="math inline">\(H_0: \mu_D = 0 \to\)</span> El contenido de <span class="math inline">\(FeO\)</span> es <em>igual</em> a los diferentes tamaños de grano</li>
<li><span class="math inline">\(H_1: \mu_D \neq 0 \to\)</span> El contenido de <span class="math inline">\(FeO\)</span> es <em>diferente</em> a los diferentes tamaños de grano</li>
</ul></li>
<li>Determinar parámetros de la distribución a comparar (<span class="math inline">\(H_0\)</span>):
<ul>
<li><span class="math inline">\(\mu_D = 0\)</span></li>
<li><span class="math inline">\(s_{\bar{d}} = \frac{s_d}{\sqrt{n}} = \frac{0.1247}{\sqrt{10}} = 0.0394\)</span></li>
</ul></li>
<li>Determinar valores críticos
<ul>
<li><span class="math inline">\(\alpha = .05\)</span></li>
<li><span class="math inline">\(t_{\alpha/2,v} = t_{.05/2,9} = |2.262|\)</span></li>
</ul></li>
<li>Calcular el estadístico de prueba
<ul>
<li><span class="math inline">\(t = \frac{\bar{d}}{s_{\bar{d}}} = \frac{0.1}{0.0394} = 2.538\)</span></li>
<li><span class="math inline">\(0.1 \pm 0.0981 \to 95\% \ IC \ [0.0108,0.189]\)</span></li>
</ul></li>
<li>Tomar una decisión
<ul>
<li>El estadístico de prueba es mayor al crítico, <span class="math inline">\(t &gt; t_{\alpha/2,v}\)</span></li>
<li>El valor-<em>p</em> es menor a <span class="math inline">\(\alpha = .05\)</span>, <span class="math inline">\(p = .032\)</span></li>
<li>El valor de <span class="math inline">\(0\)</span> no cae dentro del intervalo de confianza, <span class="math inline">\(IC \ [0.0108,0.189]\)</span></li>
<li><em>Decisión</em>: Se rechaza <span class="math inline">\(H_0\)</span></li>
</ul></li>
</ol>
<p><strong>R</strong> trae la función <code>t.test</code> que puede realizar las diferentes pruebas <span class="math inline">\(t\)</span>. Para el caso de 2 muestras dependientes se brindan los vectores de datos, el indicador lógico de si es una prueba dependiente (<code>paired</code>), y el nivel de confianza.</p>
<pre class="sourceCode r"><code class="sourceCode r">a =<span class="st"> </span><span class="fl">0.05</span>

m1 =<span class="st"> </span><span class="kw">c</span>(<span class="fl">13.5</span>,<span class="fl">14.6</span>,<span class="fl">12.7</span>,<span class="fl">15.5</span>,<span class="fl">11.1</span>,<span class="fl">16.4</span>,<span class="fl">13.2</span>,<span class="fl">19.3</span>,<span class="fl">16.7</span>,<span class="fl">18.4</span>)
m2 =<span class="st"> </span><span class="kw">c</span>(<span class="fl">13.6</span>,<span class="fl">14.6</span>,<span class="fl">12.6</span>,<span class="fl">15.7</span>,<span class="fl">11.1</span>,<span class="fl">16.6</span>,<span class="fl">13.2</span>,<span class="fl">19.5</span>,<span class="fl">16.8</span>,<span class="fl">18.7</span>)
n =<span class="st"> </span><span class="kw">length</span>(m2)
r =<span class="st"> </span><span class="kw">cor</span>(m1,m2)

t2.dep.res =<span class="st"> </span><span class="kw">t.test</span>(<span class="dt">x =</span> m2,
                    <span class="dt">y =</span> m1,
                    <span class="dt">paired =</span> T,
                    <span class="dt">conf.level =</span> <span class="dv">1</span><span class="op">-</span>a)
t2.dep.res</code></pre>
<pre><code>## 
##  Paired t-test
## 
## data:  m2 and m1
## t = 2.5355, df = 9, p-value = 0.03195
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  0.01077932 0.18922068
## sample estimates:
## mean of the differences 
##                     0.1</code></pre>
<p>Como se mencionó en la sección <a href="estimación-e-hipótesis.html#estim-ic-t2-dep">14.2.2.2.2</a>, y a diferencia de muestras independientes, las pruebas de hipótesis para muestras dependientes no se pueden aproximar por medio de los intervalos de confianza (Figura <a href="pruebas-estadísticas.html#fig:t2-dep-ci">15.9</a>), siguiendo las guías de <span class="citation">Cumming &amp; Finch (<a href="#ref-cumming2005ap">2005</a>)</span>, <span class="citation">Cumming (<a href="#ref-cumming2012">2012</a>)</span>, y <span class="citation">Cumming &amp; Calin-Jageman (<a href="#ref-cumming2017">2017</a>)</span>. En este caso solo se puede utilizar el intervalo de confianza para la diferencia, que va a estar en función de los márgenes de error de las muestras y la correlación entre las mismas (<span class="math inline">\(MoE_d^2 = MoE_1^2 + MoE_2^2 - 2rMoE_1MoE_2\)</span>), donde a mayor correlación menor el margen de error para la diferencia y mayor precisión <span class="citation">(Cumming &amp; Finch, <a href="#ref-cumming2005ap">2005</a>)</span>.</p>
<div class="figure" style="text-align: center"><span id="fig:t2-dep-ci"></span>
<img src="geolonum_files/figure-html/t2-dep-ci-1.png" alt="Intervalos de confianza para la prueba t de 2 muestras independientes. El valor de 0 cae fuera del intervalo de confianza para la diferencia, por lo que no se pueden considerar iguales o que hay diferencia entre la concentración de $FeO$ para los tamaños." width="70%" />
<p class="caption">
Figura 15.9: Intervalos de confianza para la prueba t de 2 muestras independientes. El valor de 0 cae fuera del intervalo de confianza para la diferencia, por lo que no se pueden considerar iguales o que hay diferencia entre la concentración de <span class="math inline">\(FeO\)</span> para los tamaños.
</p>
</div>
<p>El tamaño del efecto se puede calcular de acuerdo a las Ecuaciones <a href="pruebas-estadísticas.html#eq:d-t2-dep1">(15.8)</a>, <a href="pruebas-estadísticas.html#eq:d-t2-dep2">(15.9)</a> y <a href="pruebas-estadísticas.html#eq:d-t2-dep3">(15.10)</a>, donde la diferencia es qué se usa como estandarizador. De nuevo es buena práctica reportar qué se usó como estandarizador para claridad en lo que se reporta <span class="citation">(Cumming &amp; Calin-Jageman, <a href="#ref-cumming2017">2017</a>)</span>. Si la correlación entre las muestras es <span class="math inline">\(r \sim |.5|\)</span> no hay mucha diferencia entre los tamaños de efecto, pero conforme la correlación se acerque a <span class="math inline">\(0\)</span> o <span class="math inline">\(1\)</span> mayor será la diferencia entre <span class="math inline">\(d_z\)</span> con respecto a <span class="math inline">\(d_{rm}\)</span> y <span class="math inline">\(d_{av}\)</span> <span class="citation">(Lakens, <a href="#ref-lakens2013fp">2013</a>)</span>. Debido al punto anterior, y la típica relación entre muestras, <span class="citation">Cumming (<a href="#ref-cumming2012">2012</a>)</span>, <span class="citation">Cumming &amp; Calin-Jageman (<a href="#ref-cumming2017">2017</a>)</span>, y <span class="citation">Lakens (<a href="#ref-lakens2013fp">2013</a>)</span> sugieren utilizar <span class="math inline">\(d_{av}\)</span> como el tamaño del efecto.</p>
<p><span class="math display">\[\begin{equation}
  d_z = \frac{\bar{d}}{s_d}\\
  d_z = \frac{0.1}{0.1247} = 0.80
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
  d_{rm} = \frac{\bar{d}}{\sqrt{s_1^2 + s_2^2 - 2 \cdot r \cdot s_1 \cdot s_2}}\sqrt{2(1-r)}\\
  d_{rm} = \frac{0.1}{\sqrt{7.33 + 6.79 - 2 \cdot .9996 \cdot 2.7 \cdot 2.6}}\sqrt{2(1-.9996)} = 0.001\\
  \text{usando todos los decimales da } d_{rm} = 0.022)
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
  d_{av} = \frac{\bar{d}}{\sqrt{\frac{s_1^2 + s_2^2}{2}}}\\
  d_{av} = \frac{0.1}{\sqrt{\frac{7.33 + 6.79}{2}}} = 0.038
\end{equation}\]</span></p>
<p>En <strong>R</strong> se puede calcular <span class="math inline">\(d_z\)</span> con la función <code>d.dep.t.diff</code>, <span class="math inline">\(d_{rm}\)</span> con la función <code>d.dep.t.rm</code>, y <span class="math inline">\(d_{av}\)</span> con la función <code>d.dep.t.avg</code>, todas del paquete <em>MOTE</em>. Adicionalmente existen las funciones <code>cohens_d</code> de <em>effectsize</em>, y <code>cohen.d</code> de <em>effsize</em>, donde de nuevo se tiene que definir el argumento <code>paired</code>, pero en los dos casos el efecto que calculan es <span class="math inline">\(d_z\)</span>, el cual es el menos recomendado. Además, la función <code>cohensd_rm</code> del paquete <em>itns</em> <span class="citation">(Erceg-Hurn et al., <a href="#ref-R-itns">2017</a>)</span> calcula <span class="math inline">\(d_{av}\)</span>.</p>
<p>Usando <em>MOTE</em></p>
<pre class="sourceCode r"><code class="sourceCode r">a =<span class="st"> </span><span class="fl">0.05</span>
d.t2.dep.res1 =<span class="st"> </span><span class="kw">d.dep.t.diff</span>(<span class="dt">mdiff =</span> <span class="kw">mean</span>(m2<span class="op">-</span>m1),
                             <span class="dt">sddiff =</span> <span class="kw">sd</span>(m2<span class="op">-</span>m1),
                             <span class="dt">n =</span> n,
                             <span class="dt">a =</span> a)
d.t2.dep.res1[<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">unlist</span>()</code></pre>
<pre><code>##          d       dlow      dhigh 
## 0.80178373 0.06638463 1.50482386</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">d.t2.dep.res2 =<span class="st"> </span><span class="kw">d.dep.t.rm</span>(<span class="dt">m1 =</span> <span class="kw">mean</span>(m2),
                           <span class="dt">m2 =</span> <span class="kw">mean</span>(m1),
                           <span class="dt">sd1 =</span> <span class="kw">sd</span>(m2),
                           <span class="dt">sd2 =</span> <span class="kw">sd</span>(m1),
                           <span class="dt">r =</span> r,
                           <span class="dt">n =</span> n,
                           <span class="dt">a =</span> a)
d.t2.dep.res2[<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">unlist</span>()</code></pre>
<pre><code>##           d        dlow       dhigh 
##  0.02164429 -0.59882065  0.64092600</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">d.t2.dep.res3 =<span class="st"> </span><span class="kw">d.dep.t.avg</span>(<span class="dt">m1 =</span> <span class="kw">mean</span>(m2),
                            <span class="dt">m2 =</span> <span class="kw">mean</span>(m1),
                            <span class="dt">sd1 =</span> <span class="kw">sd</span>(m2),
                            <span class="dt">sd2 =</span> <span class="kw">sd</span>(m1),
                            <span class="dt">n =</span> n,
                            <span class="dt">a =</span> a)
d.t2.dep.res3[<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">unlist</span>()</code></pre>
<pre><code>##           d        dlow       dhigh 
##  0.03764125 -0.58341889  0.65664471</code></pre>
<p>La Tabla <a href="pruebas-estadísticas.html#tab:d-dep-comparacion">15.4</a> muestra la comparación entre los diferentes tamaños de efecto para el ejemplo de muestras dependientes. Los resultados muestran como <span class="math inline">\(d_z\)</span> sobrestima (y por mucho) a <span class="math inline">\(d_{rm}\)</span> y <span class="math inline">\(d_{av}\)</span>, donde <span class="math inline">\(d_{rm}\)</span> es el más conservador de todos. <span class="citation">(Lakens, <a href="#ref-lakens2013fp">2013</a>)</span>. El hecho de que <span class="math inline">\(d_z\)</span> sobrestima el tamaño del efecto es debido a la alta correlación entre las muestras <span class="math inline">\(r = .9996\)</span>.</p>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:d-dep-comparacion">Tabla 15.4: </span>Comparación de tamaños de efecto para muestras dependientes
</caption>
<thead>
<tr>
<th style="text-align:center;">
ES
</th>
<th style="text-align:center;">
<span class="math inline">\(d\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(IC_{inf}\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(IC_{sup}\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
<span class="math inline">\(d_z\)</span>
</td>
<td style="text-align:center;">
0.802
</td>
<td style="text-align:center;">
0.066
</td>
<td style="text-align:center;">
1.505
</td>
</tr>
<tr>
<td style="text-align:center;">
<span class="math inline">\(d_{rm}\)</span>
</td>
<td style="text-align:center;">
0.022
</td>
<td style="text-align:center;">
-0.599
</td>
<td style="text-align:center;">
0.641
</td>
</tr>
<tr>
<td style="text-align:center;">
<span class="math inline">\(d_{av}\)</span>
</td>
<td style="text-align:center;">
0.038
</td>
<td style="text-align:center;">
-0.583
</td>
<td style="text-align:center;">
0.657
</td>
</tr>
</tbody>
</table>
<p>Un panorama general del efecto de <span class="math inline">\(r\)</span> en el tamaño del efecto para muestras dependientes se muestra en la Tabla <a href="pruebas-estadísticas.html#tab:d-dep-comparacion2">15.5</a>, donde se generaron tres juegos de datos, provenientes de poblaciones con <span class="math inline">\(r=.1\)</span>, <span class="math inline">\(r=.5\)</span>, y <span class="math inline">\(r=.9\)</span>, respectivamente. Se observa como a bajos valores de <span class="math inline">\(r\)</span> <span class="math inline">\(d_z\)</span> subestima el tamaño del efecto (con respecto a <span class="math inline">\(d_{rm}\)</span> y <span class="math inline">\(d_{av}\)</span>), a valores intermedios todos son muy similares, y a altos valores de <span class="math inline">\(r\)</span> <span class="math inline">\(d_z\)</span> sobrestima el tamaño del efecto (con respecto a <span class="math inline">\(d_{rm}\)</span> y <span class="math inline">\(d_{av}\)</span>), lo que muestra la sensibilidad y el efecto de <span class="math inline">\(r\)</span> en el uso de <span class="math inline">\(d_z\)</span>, y por lo que se recomienda usar <span class="math inline">\(d_{rm}\)</span> o <span class="math inline">\(d_{av}\)</span>.</p>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:d-dep-comparacion2">Tabla 15.5: </span>Comparación de los diferentes <span class="math inline">\(d\)</span> para muestras dependientes
</caption>
<thead>
<tr>
<th style="text-align:center;">
<span class="math inline">\(\rho\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(r\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(d_z\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(d_{rm}\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(d_{av}\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
.1
</td>
<td style="text-align:center;">
.254
</td>
<td style="text-align:center;">
0.511
</td>
<td style="text-align:center;">
0.624
</td>
<td style="text-align:center;">
0.625
</td>
</tr>
<tr>
<td style="text-align:center;">
.5
</td>
<td style="text-align:center;">
.492
</td>
<td style="text-align:center;">
0.637
</td>
<td style="text-align:center;">
0.642
</td>
<td style="text-align:center;">
0.646
</td>
</tr>
<tr>
<td style="text-align:center;">
.9
</td>
<td style="text-align:center;">
.932
</td>
<td style="text-align:center;">
2.107
</td>
<td style="text-align:center;">
0.778
</td>
<td style="text-align:center;">
0.804
</td>
</tr>
</tbody>
</table>
<p>Usando <em>itns</em></p>
<pre class="sourceCode r"><code class="sourceCode r">d.t2.dep.res4 =<span class="st"> </span><span class="kw">cohensd_rm</span>(m2,m1,
                           <span class="dt">ci =</span> <span class="dv">1</span><span class="op">-</span>a)
d.t2.dep.res4</code></pre>
<pre><code>##        est         ll         ul 
## 0.03763431 0.03630516 0.03671538</code></pre>
<p>Usando <em>effectsize</em></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cohens_d</span>(m2,m1,
         <span class="dt">paired =</span> T,
         <span class="dt">ci =</span> <span class="dv">1</span><span class="op">-</span>a)</code></pre>
<pre><code>## # A tibble: 1 x 4
##   Cohens_d    CI CI_low CI_high
##      &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;
## 1    0.802  0.95 0.0700    1.59</code></pre>
<p>Usando <em>effsize</em></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cohen.d</span>(m2,m1,
        <span class="dt">conf.level =</span> <span class="dv">1</span><span class="op">-</span>a,
        <span class="dt">paired =</span> T,
        <span class="dt">noncentral=</span>T)</code></pre>
<pre><code>## 
## Cohen&#39;s d
## 
## d estimate: 0.8017837 (large)
## 95 percent confidence interval:
##      lower      upper 
## 0.06996669 1.58622949</code></pre>
<p>Usando las medidas PS, OVL, y <span class="math inline">\(U_3\)</span> (Figura <a href="pruebas-estadísticas.html#fig:t2-dep-u3">15.10</a>).</p>
<pre><code>## # A tibble: 1 x 3
##      PS   OVL    U3
##   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1  51.1  98.5  51.5</code></pre>
<div class="figure" style="text-align: center"><span id="fig:t2-dep-u3"></span>
<img src="geolonum_files/figure-html/t2-dep-u3-1.png" alt="$U_3$ para el ejemplo de la prueba $t$ de 2 muestras dependientes. **A** Corresponde con los datos en escala original. **B** Corresponde con el tamaño del efecto $d$." width="70%" />
<p class="caption">
Figura 15.10: <span class="math inline">\(U_3\)</span> para el ejemplo de la prueba <span class="math inline">\(t\)</span> de 2 muestras dependientes. <strong>A</strong> Corresponde con los datos en escala original. <strong>B</strong> Corresponde con el tamaño del efecto <span class="math inline">\(d\)</span>.
</p>
</div>
<blockquote>
<p>Conclusión: La concentración de <span class="math inline">\(FeO\)</span> es significativamente diferente para los diferentes tamaños (<span class="math inline">\(M_d = 0.100\)</span>, 95% IC <span class="math inline">\([0.011\)</span>, <span class="math inline">\(0.189]\)</span>), <span class="math inline">\(t(9) = 2.54\)</span>, <span class="math inline">\(p = .032\)</span>, <span class="math inline">\(N = 10\)</span>, <span class="math inline">\(r = .9996\)</span>, <span class="math inline">\(d_{av}\)</span> = 0.04 <span class="math inline">\([-0.58, 0.66]\)</span>. El efecto se puede considerar muy pequeño, con un rango de mediano, en dirección opuesta, hasta mediano en la dirección del efecto. Hay una probabilidad de 51.1% (PS) que un elemento de la muestra de <span class="math inline">\(&lt; 125 \ \mu m\)</span> tenga una concentración mayor que un elemento de la muestra de <span class="math inline">\(&lt; 25 \ \mu m\)</span>; las dos curvas se traslapan en un 98.5% (OVL); el 51.5% (<span class="math inline">\(U_3\)</span>) de la muestra de <span class="math inline">\(&lt; 125 \ \mu m\)</span> se encuentra por encima de la media de la muestra de <span class="math inline">\(&lt; 25 \ \mu m\)</span>.</p>
</blockquote>
<div class="figure" style="text-align: center"><span id="fig:t2-dep-stats"></span>
<img src="geolonum_files/figure-html/t2-dep-stats-1.png" alt="Gráfico de caja mostrando el efecto del tamaño de partícula sobre el contenido de FeO, así como el resumen estadístico respectivo." width="90%" />
<p class="caption">
Figura 15.11: Gráfico de caja mostrando el efecto del tamaño de partícula sobre el contenido de FeO, así como el resumen estadístico respectivo.
</p>
</div>
</div>
<div id="prueba-aov" class="section level2">
<h2><span class="header-section-number">15.8</span> ANOVA de 1-factor entre-sujetos</h2>
<p>Hasta el momento solo se han analizado casos donde se tenían 1 o 2 muestras y se desean hacer inferencias sobre la media, pero en muchos casos se pueden llegar a tener 3 o más muestras.</p>
<p>Se podría pensar en realizar diferentes pruebas <span class="math inline">\(t\)</span> de dos muestras, pero esto genera dos problemas: primero, dependiendo de la cantidad de grupos el número de comparaciones sería muy grande, y segundo y más importante al realizar diferentes pruebas <span class="math inline">\(t\)</span> se va a inflar el error tipo-I (<span class="math inline">\(\alpha\)</span>), pudiendo incurrir en conclusiones equivocadas <span class="citation">(Nolan &amp; Heinzen, <a href="#ref-nolan2014">2014</a>)</span>.</p>
<p>La prueba del análisis de varianza (ANOVA - Analysis of Variance, en inglés), es una prueba que permite dilucidar la similitud entre muestras sin incurrir en los problemas antes mencionados, y la cual hace uso de la distribución y prueba <span class="math inline">\(F\)</span> para el análisis. La base teórica y procedimental que se va a exponer aquí se puede encontrar en <span class="citation">(Borradaile, <a href="#ref-borradaile2003">2003</a>; Davis, <a href="#ref-davis2002">2002</a>; McKillup &amp; Darby Dyar, <a href="#ref-mckillup2010">2010</a>; Nolan &amp; Heinzen, <a href="#ref-nolan2014">2014</a>; Swan &amp; Sandilands, <a href="#ref-swan1995">1995</a>; Walpole et al., <a href="#ref-walpole2012">2012</a>)</span></p>
<p>Una suposición de ANOVA es que las varianzas son iguales; esta prueba es relativamente robusta a esta suposición siempre y cuando la razón entre las desviaciones estándar mayor y menor no sea superior a 2. De querer realizar pruebas para determinar esta similitud, se pueden usar las pruebas de Levene (<span class="math inline">\(F\)</span>, media), Brown-Forsythe (<span class="math inline">\(F\)</span>, mediana), o Bartlett (<span class="math inline">\(\chi^2\)</span>, media). ANOVA es una técnica que permite diferentes diseños, pero en esta sección se presenta el caso más sencillo, el cual se conoce como ANOVA de 1 factor entre-sujetos (between-subjects ANOVA). Este diseño quiere decir que la variable de interés (numérica continua) está en función de una variable categórica (factor o tratamiento) con <span class="math inline">\(2+\)</span> grupos o clases. De hecho, la prueba <span class="math inline">\(t\)</span> de 2 muestras independientes es un caso especial de ANOVA con 2 grupos, y se puede comprobar que <span class="math inline">\(F=t^2\)</span>.</p>
<p>De manera general las hipótesis nula y alterna serían:</p>
<ul>
<li><span class="math inline">\(H_0: \mu_1 = \mu_2 = \mu_3 = \cdots = \mu_k\)</span></li>
<li><span class="math inline">\(H_1: \text{Al menos 1 de las media es diferente}\)</span></li>
</ul>
<p>Para poder determinar el efecto de los diferentes grupos (muestras) en la variación de la media de la variable de interés, se puede pensar en que hay dos fuentes de variación: <strong>entre</strong> las muestras (Figura <a href="pruebas-estadísticas.html#fig:anova-entre">15.12</a>) y <strong>dentro</strong> de las muestras (Figura <a href="pruebas-estadísticas.html#fig:anova-dentro">15.13</a>).</p>
<div class="figure" style="text-align: center"><span id="fig:anova-entre"></span>
<img src="images/anova-entre.png" alt="Representación de la variación entre grupos. Conforme más separados estén y más distancia con respecto a la media general, mayor la variación." width="70%" />
<p class="caption">
Figura 15.12: Representación de la variación entre grupos. Conforme más separados estén y más distancia con respecto a la media general, mayor la variación.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:anova-dentro"></span>
<img src="images/anova-dentro.png" alt="Representación de la variación dentro de grupos. Conforme más dispersión haya en las muestras mayor la vriación dentro de lo grupos." width="70%" />
<p class="caption">
Figura 15.13: Representación de la variación dentro de grupos. Conforme más dispersión haya en las muestras mayor la vriación dentro de lo grupos.
</p>
</div>
<p>La variación entre grupos va a cuantificar la diferencia real entre las medias más el error (variación dentro de los grupos), por lo que de manera general se puede estimar este efecto por medio del estadístico <span class="math inline">\(F\)</span> a como se muestra en la Ecuación <a href="pruebas-estadísticas.html#eq:anova-F-gen">(15.25)</a>. Conforme mayor sea la diferencia entre los grupos mayor será el valor de <span class="math inline">\(F\)</span>, mientras que conforme más similares sean los grupos <span class="math inline">\(F \sim 1\)</span>. Para este caso la prueba <span class="math inline">\(F\)</span> va a ser siempre de una cola, donde hay un único valor crítico y la región de rechazo se encuentra a la derecha.</p>
<p><span class="math display" id="eq:anova-F-gen">\[\begin{equation}
  F = \frac{\text{variación entre grupos (diferencia + error)}}{\text{variación dentro de grupos (error)}}
  \tag{15.25}
\end{equation}\]</span></p>
<div class="figure" style="text-align: center"><span id="fig:anova-F"></span>
<img src="geolonum_files/figure-html/anova-F-1.png" alt="Representación de la distribución $F$, donde se muestra la región crítica o de rechazo en color rojo." width="70%" />
<p class="caption">
Figura 15.14: Representación de la distribución <span class="math inline">\(F\)</span>, donde se muestra la región crítica o de rechazo en color rojo.
</p>
</div>
<p>El resultado de ANOVA por lo general se presenta como una tabla, donde manera general lleva la estructura presentada en la Tabla <a href="pruebas-estadísticas.html#tab:anova-tabla">15.6</a>. El tamaño del efecto para ANOVA se puede obtener de los valores de la tabla: <span class="math inline">\(\eta^2=SCG/SCT\)</span>, donde <span class="math inline">\(SCT\)</span> es la suma de cuadrados total (<span class="math inline">\(SCT=SCG+SCE\)</span>) y corresponde con el porcentaje de variación en la variable respuesta explicado por el efecto de los grupos.</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:anova-tabla">Tabla 15.6: </span>Tabla de ANOVA
</caption>
<thead>
<tr>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
Suma de cuadrados
</th>
<th style="text-align:center;">
Grados de liberta
</th>
<th style="text-align:center;">
Cuadrados medios
</th>
<th style="text-align:center;">
F
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
Entre grupos
</td>
<td style="text-align:center;">
<span class="math inline">\(SCG = \sum(\bar{x}_g-\bar{x}_T)^2 \cdot n_g\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(k-1\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(s_1^2 = \frac{\sum(\bar{x}_g-\bar{x}_T)^2 \cdot n_g}{k-1}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\frac{s_1^2}{s^2}\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
Dentro de grupos (error)
</td>
<td style="text-align:center;">
<span class="math inline">\(SCE = \sum\sum(x_{ig}-\bar{x}_g)^2\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(N-k\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(s^2 = \frac{\sum\sum(x_{ig}-\bar{x}_g)^2}{N-k}\)</span>
</td>
<td style="text-align:center;">
</td>
</tr>
</tbody>
<tfoot>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<span style="font-style: italic;">Notas:</span>
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(\bar{x}_g\)</span> = media del grupo
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(\bar{x}_T\)</span> = media total (global)
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(x_{ig}\)</span> = valor <span class="math inline">\(i\)</span> del grupo <span class="math inline">\(g\)</span>
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(n_g\)</span> = tamaño del grupo <span class="math inline">\(g\)</span>
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(k\)</span> = número de grupos
</td>
</tr>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> <span class="math inline">\(N\)</span> = total de observaciones
</td>
</tr>
</tfoot>
</table>
<p>Cuando el resultado de la prueba de ANOVA es significativo esto indica que al menos uno de los grupos es diferente, pero no se sabe cuál. Para poder responder hay dos opciones:</p>
<ul>
<li>Si no se tiene idea o no se ha decidido con anterioridad de cuáles grupos se quieren comparar se pueden realizar análisis posteriores (post-hoc) comparando todos los grupos, donde se ajusta para el error tipo-I. El post-hoc más utilizado es TukeyHSD (Honestly Significant Difference), pero existen otros como Bonferroni, Holm, Scheffe, etc. La ventaja de Tukey es que brinda más información que los otros (diferencia entre grupos e intervalo de confianza para la diferencia).</li>
<li>Si se han decidido comparaciones (contrastes) <em>a priori</em> éstas son las que se analizan, pero debieron haberse especificado durante la planificación del estudio y antes de recolectar los datos. Estas tienen la ventaja de que se reducen el número de comparaciones, y por lo general se obtienen las mismas conclusiones.</li>
</ul>
<p>Para demostrar el ANOVA se usa un ejemplo de <span class="citation">McKillup &amp; Darby Dyar (<a href="#ref-mckillup2010">2010</a>)</span>, donde se tiene el contenido de <span class="math inline">\(MgO\)</span> presente en cuatro turmalinas en tres sitios diferentes: Mount Mica, Sebago Batholith, Black Mountain. Asuma <span class="math inline">\(\alpha=.05\)</span>.</p>
<ol style="list-style-type: decimal">
<li>Identificar la población, distribución, y la prueba apropiada:
<ul>
<li>Población: contenido de <span class="math inline">\(MgO\)</span> presente en turmalinas en Mount Mica, Sebago Batholith, Black Mountain</li>
<li>Distribución: F</li>
<li>Prueba: <span class="math inline">\(F\)</span></li>
</ul></li>
<li>Establecer las hipótesis nula y alterna:
<ul>
<li><span class="math inline">\(H_0: \mu_1 = \mu_2 = \mu_3 \to\)</span> El contenido de <span class="math inline">\(MgO\)</span> presente en las turmalinas de los tres sitios es el mismo</li>
<li><span class="math inline">\(H_1:\)</span> El contenido de <span class="math inline">\(MgO\)</span> presente en las turmalinas difiere por lo menos en uno de los tres sitios</li>
</ul></li>
<li>Determinar parámetros de la distribución a comparar (<span class="math inline">\(H_0\)</span>):
<ul>
<li><span class="math inline">\(v_1 = k-1 = 3-1=2\)</span></li>
<li><span class="math inline">\(v_2 = N-k = 12-3 = 9\)</span></li>
</ul></li>
<li>Determinar valores críticos
<ul>
<li><span class="math inline">\(\alpha = .05\)</span></li>
<li><span class="math inline">\(F_{\alpha,v_1,v_2} = F_{.05,2,9} = 4.256\)</span></li>
</ul></li>
<li>Calcular el estadístico de prueba
<ul>
<li><span class="math inline">\(F = \frac{36}{3.3} = 10.8\)</span></li>
<li>El procedimiento manual no se detalla aquí por ser más extenso y elaborado de lo normal, pero se recomienda al lector revisar las referencias mencionadas para detallarlo y entenderlo</li>
</ul></li>
<li>Tomar una decisión
<ul>
<li>El estadístico de prueba es mayor al crítico, <span class="math inline">\(F &gt; F_{\alpha,v_1,v_2}\)</span></li>
<li>El valor-<em>p</em> es menor a <span class="math inline">\(\alpha = .05\)</span>, <span class="math inline">\(p = .004\)</span></li>
<li><em>Decisión</em>: Se rechaza <span class="math inline">\(H_0\)</span> y por lo menos uno de los contenidos de <span class="math inline">\(MgO\)</span> es diferente</li>
</ul></li>
</ol>
<p>En <strong>R</strong> los datos tienen que estar en formato largo, lo que quiere decir una columna con los valores de la variable de interés, y otra columna con el grupo al que pertenece la medición. Otro punto importante es que la variable agrupadora es mejor que sea del tipo <em>factor</em>.</p>
<p>Los datos del ejemplo se encuentran en el archivo <em>anova MgO.csv</em></p>
<pre class="sourceCode r"><code class="sourceCode r">a =<span class="st"> </span><span class="fl">0.05</span>
dat.aov =<span class="st"> </span><span class="kw">import</span>(<span class="st">&#39;data/anova MgO.csv&#39;</span>, <span class="dt">setclass =</span> <span class="st">&#39;tibble&#39;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Location =</span> <span class="kw">as.factor</span>(Location) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">           </span><span class="kw">fct_reorder</span>(MgO))
dat.aov</code></pre>
<pre><code>## # A tibble: 12 x 2
##    Location           MgO
##    &lt;fct&gt;            &lt;int&gt;
##  1 Mount Mica           7
##  2 Mount Mica           8
##  3 Mount Mica          10
##  4 Mount Mica          11
##  5 Sebago Batholith     4
##  6 Sebago Batholith     5
##  7 Sebago Batholith     7
##  8 Sebago Batholith     8
##  9 Black Mountain       1
## 10 Black Mountain       2
## 11 Black Mountain       4
## 12 Black Mountain       5</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">N =<span class="st"> </span><span class="kw">nrow</span>(dat.aov)</code></pre>
<p>Es recomendable hacer una inspección de los grupos, tanto numérica (Tabla <a href="pruebas-estadísticas.html#tab:mgo-resumen">15.7</a>) como gráfica, para darnos una idea de la media y desviaciones estándar. Aquí se observa que todos los grupos tienen la misma desviación estándar (algo poco común), por lo que el supuesto de la homogeneidad de varianzas se mantiene.</p>
<pre class="sourceCode r"><code class="sourceCode r">dat.aov <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(Location) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarise_all</span>(<span class="kw">list</span>(<span class="dt">N =</span> <span class="op">~</span><span class="kw">n</span>(),
                     <span class="dt">Avg =</span> <span class="op">~</span><span class="kw">mean</span>(.),
                     <span class="dt">SD =</span> <span class="op">~</span><span class="kw">sd</span>(.)))</code></pre>
<table>
<caption>
<span id="tab:mgo-resumen">Tabla 15.7: </span>Resumen por grupo
</caption>
<thead>
<tr>
<th style="text-align:left;">
Location
</th>
<th style="text-align:right;">
N
</th>
<th style="text-align:right;">
Avg
</th>
<th style="text-align:right;">
SD
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Black Mountain
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
1.826
</td>
</tr>
<tr>
<td style="text-align:left;">
Sebago Batholith
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
6
</td>
<td style="text-align:right;">
1.826
</td>
</tr>
<tr>
<td style="text-align:left;">
Mount Mica
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
1.826
</td>
</tr>
</tbody>
</table>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(dat.aov, <span class="kw">aes</span>(Location, MgO)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">stat_summary</span>(<span class="dt">fun.data =</span> mean_cl_normal, 
               <span class="dt">fun.args =</span> <span class="kw">list</span>(<span class="dt">conf.int =</span> <span class="dv">1</span><span class="op">-</span>a), 
               <span class="dt">geom =</span> <span class="st">&#39;pointrange&#39;</span>, <span class="dt">size =</span> <span class="fl">.75</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x=</span><span class="st">&#39;&#39;</span>)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:mgo-ci"></span>
<img src="geolonum_files/figure-html/mgo-ci-1.png" alt="Medias e intervalos de confianza (95%) para cada grupo." width="70%" />
<p class="caption">
Figura 15.15: Medias e intervalos de confianza (95%) para cada grupo.
</p>
</div>
<p>Para realizar el ANOVA se puede hacer de diferentes maneras, pero de manera general se expresa como un modelo lineal <code>y ~ x</code>, donde <code>y</code> es la variable de interés y <code>x</code> es la variable agrupadora. Se pueden usar diferentes funciones, dentro de ellas <code>aov</code>, <code>lm</code>, donde siempre es necesario especificar la tabla de datos. La tabla resumen se muestra en la Tabla <a href="pruebas-estadísticas.html#tab:mgo-anova">15.8</a>, donde se puede confeccionar a partir de la función <code>anova</code> o <code>summary</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">mgo.aov =<span class="st"> </span><span class="kw">aov</span>(MgO <span class="op">~</span><span class="st"> </span>Location, dat.aov)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(mgo.aov)</code></pre>
<table>
<caption>
<span id="tab:mgo-anova">Tabla 15.8: </span>Tabla de ANOVA para el ejemplo
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Grados libertad
</th>
<th style="text-align:right;">
Suma Cuadrados
</th>
<th style="text-align:right;">
Cuadrados Medios
</th>
<th style="text-align:right;">
F
</th>
<th style="text-align:right;">
Valor-<em>p</em>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Location
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
72
</td>
<td style="text-align:right;">
36.0000
</td>
<td style="text-align:right;">
10.8
</td>
<td style="text-align:right;">
0.0041
</td>
</tr>
<tr>
<td style="text-align:left;">
Residuals
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
30
</td>
<td style="text-align:right;">
3.3333
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
NA
</td>
</tr>
</tbody>
</table>
<p>El resultado es significativo, indicando que por lo menos uno de los contenidos de <span class="math inline">\(MgO\)</span> difiere del resto.</p>
<p>El tamaño del efecto <span class="math inline">\(\eta^2\)</span> se puede calcular usando las Ecuaciones <a href="pruebas-estadísticas.html#eq:eta2-1">(15.15)</a>, <a href="pruebas-estadísticas.html#eq:eta2-2">(15.16)</a>, y el tamaño del efecto <span class="math inline">\(\omega^2\)</span> se puede calcular usando las Ecuaciones <a href="pruebas-estadísticas.html#eq:omega2-1">(15.17)</a>, <a href="pruebas-estadísticas.html#eq:omega2-2">(15.18)</a>, donde <span class="math inline">\(SC_{total}\)</span> es la suma de la columna <em>Suma de cuadrados (Sum Sq)</em>. Para este tipo de ANOVA (1-factor entre grupos) se cumple que <span class="math inline">\(\eta^2 = \eta_p^2\)</span> y <span class="math inline">\(\omega^2 = \omega_p^2\)</span>, ya que hay solo 1 factor, pero para el resto de ocasiones donde haya más de un factor esta igualdad no se cumple y se recomienda incluir ambos tamaños de efecto (global y parcial).</p>
<p><span class="math display">\[\begin{equation}
  \eta^2 = \frac{SC_{efecto}}{SC_{total}} = \frac{72}{72+30} = .706
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
  \omega^2 = \frac{v_{efecto}(CM_{efecto}-CM_{error})}{SC_{total}+CM_{error}} = \frac{2 (36-3.33)}{102+3.33} = .62
\end{equation}\]</span></p>
<p>En <strong>R</strong> el tamaño del efecto, así como el intervalo de confianza, se puede obtener por medio de las funciones <code>eta.F</code> (<span class="math inline">\(\eta^2\)</span>), <code>eta.partial.SS</code> (<span class="math inline">\(\eta^2_p\)</span>), <code>omega.F</code> (<span class="math inline">\(\omega^2\)</span>), <code>omega.partial.SS.bn</code> (<span class="math inline">\(\omega^2_p\)</span>) de <em>MOTE</em>, y <code>eta_squared</code>, <code>omega_squared</code> de <em>effectsize</em>. Para <code>eta.F</code> y <code>omega.F</code> es necesario indicar los grados de libertad, el valor de <span class="math inline">\(F\)</span>, y el nivel de significancia <span class="math inline">\(\alpha\)</span>, mientras que para <code>eta.partial.SS</code> hay que indicar además las sumas de cuadrados y para <code>omega.partial.SS.bn</code> los cuadrados medios. Para <code>eta_squared</code> y <code>omega_squared</code> lo que se necesita es el objeto de ANOVA y el nivel se confianza, por defecto calcula el <span class="math inline">\(\eta^2_p\)</span> o <span class="math inline">\(\omega^2_p\)</span>.</p>
<p>Para <span class="math inline">\(\eta^2\)</span></p>
<pre class="sourceCode r"><code class="sourceCode r">aov.eta =<span class="st"> </span><span class="kw">eta.F</span>(<span class="dt">dfm =</span> <span class="dv">2</span>, <span class="dt">dfe =</span> <span class="dv">9</span>, <span class="dt">Fvalue =</span> <span class="fl">10.8</span>, <span class="dt">a =</span> a)
aov.eta[<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">unlist</span>()</code></pre>
<pre><code>##       eta    etalow   etahigh 
## 0.7058824 0.1574104 0.8872368</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">aov.eta.p =<span class="st"> </span><span class="kw">eta.partial.SS</span>(<span class="dt">dfm =</span> <span class="dv">2</span>, <span class="dt">dfe =</span> <span class="dv">9</span>, 
                           <span class="dt">ssm =</span> <span class="dv">72</span>, <span class="dt">sse =</span> <span class="dv">30</span>,
                           <span class="dt">Fvalue =</span> <span class="fl">10.8</span>, <span class="dt">a =</span> a)
aov.eta.p[<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">unlist</span>()</code></pre>
<pre><code>##       eta    etalow   etahigh 
## 0.7058824 0.1574104 0.8872368</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">eta_squared</span>(mgo.aov,<span class="dt">partial =</span> T,<span class="dt">ci =</span> <span class="dv">1</span><span class="op">-</span>a)</code></pre>
<pre><code>## # A tibble: 1 x 5
##   Parameter Eta_Sq_partial    CI CI_low CI_high
##   &lt;chr&gt;              &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;
## 1 Location           0.706  0.95  0.193   0.859</code></pre>
<p>Para <span class="math inline">\(\omega^2\)</span></p>
<pre class="sourceCode r"><code class="sourceCode r">aov.omega =<span class="st"> </span><span class="kw">omega.F</span>(<span class="dt">dfm =</span> <span class="dv">2</span>, <span class="dt">dfe =</span> <span class="dv">9</span>, <span class="dt">Fvalue =</span> <span class="fl">10.8</span>, <span class="dt">n =</span> N, <span class="dt">a =</span> a)
aov.omega[<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">unlist</span>()</code></pre>
<pre><code>##      omega   omegalow  omegahigh 
## 0.62025316 0.05224699 0.84844901</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">aov.omega.p =<span class="st"> </span><span class="kw">omega.partial.SS.bn</span>(<span class="dt">dfm =</span> <span class="dv">2</span>, <span class="dt">dfe =</span> <span class="dv">9</span>, 
                                  <span class="dt">msm =</span> <span class="dv">36</span>,<span class="dt">mse =</span> <span class="fl">3.33</span>,
                                  <span class="dt">ssm =</span> <span class="dv">72</span>, <span class="dt">n =</span> N, <span class="dt">a =</span> a)
aov.omega.p[<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">unlist</span>()</code></pre>
<pre><code>##      omega   omegalow  omegahigh 
## 0.62051282 0.05249113 0.84857108</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">omega_squared</span>(mgo.aov,<span class="dt">partial =</span> T,<span class="dt">ci =</span> <span class="dv">1</span><span class="op">-</span>a)</code></pre>
<pre><code>## # A tibble: 1 x 5
##   Parameter Omega_Sq_partial    CI CI_low CI_high
##   &lt;chr&gt;                &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;
## 1 Location             0.620  0.95 0.0120   0.815</code></pre>
<p>Como se encontró un resultado significativo, es necesario indicar dónde se encuentran esas diferencias. Aquí no se definieron contrastes <em>a priori</em>, por lo que se usa Tukey para ajustar el error tipo-I para todas las comparaciones. Se usa la función <code>TukeyHSD</code> donde los argumentos necesarios son el objeto de ANOVA y el nivel de confianza. Aquí se puede interpretar el valor-<em>p</em> con respecto al nivel de significancia escogido, ya que es un valor-<em>p</em> ajustado, de igual manera se puede interpretar el intervalo de confianza. El resumen de la prueba de Tukey se presenta en la Tabla <a href="pruebas-estadísticas.html#tab:mgo-tukey-resumen">15.9</a> y la Figura <a href="pruebas-estadísticas.html#fig:mgo-tukey-ci">15.16</a>. En los resultados se observa que la única diferencia significativa es la de <em>Mount Mica-Black Mountain</em>, ya que el valor-<em>p</em> está por debajo del <span class="math inline">\(\alpha\)</span> y el intervalo de confianza no incluye 0.</p>
<pre class="sourceCode r"><code class="sourceCode r">tukey =<span class="st"> </span><span class="kw">TukeyHSD</span>(mgo.aov, 
                 <span class="dt">conf.level =</span> <span class="dv">1</span><span class="op">-</span>a) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">tidy</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>term)</code></pre>
<table>
<caption>
<span id="tab:mgo-tukey-resumen">Tabla 15.9: </span>Resumen de la prueba de Tukey
</caption>
<thead>
<tr>
<th style="text-align:left;">
Comparación
</th>
<th style="text-align:right;">
Diferencia
</th>
<th style="text-align:right;">
<span class="math inline">\(IC_{inf}\)</span>
</th>
<th style="text-align:right;">
<span class="math inline">\(IC_{sup}\)</span>
</th>
<th style="text-align:right;">
Valor-<em>p</em> ajustado
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Sebago Batholith-Black Mountain
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
-0.604
</td>
<td style="text-align:right;">
6.604
</td>
<td style="text-align:right;">
0.103
</td>
</tr>
<tr>
<td style="text-align:left;">
Mount Mica-Black Mountain
</td>
<td style="text-align:right;">
6
</td>
<td style="text-align:right;">
2.396
</td>
<td style="text-align:right;">
9.604
</td>
<td style="text-align:right;">
0.003
</td>
</tr>
<tr>
<td style="text-align:left;">
Mount Mica-Sebago Batholith
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
-0.604
</td>
<td style="text-align:right;">
6.604
</td>
<td style="text-align:right;">
0.103
</td>
</tr>
</tbody>
</table>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(tukey, <span class="kw">aes</span>(comparison, estimate, 
                  <span class="dt">ymin =</span> conf.low, <span class="dt">ymax =</span> conf.high)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_pointrange</span>(<span class="dt">size =</span> <span class="dv">1</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="dv">0</span>, <span class="dt">col =</span> <span class="st">&#39;red&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_flip</span>() <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">theme_bw</span>() <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">y =</span> <span class="st">&#39;Diferencia en medias&#39;</span>, <span class="dt">x =</span> <span class="st">&#39;Comparación&#39;)</span></code></pre>
<div class="figure" style="text-align: center"><span id="fig:mgo-tukey-ci"></span>
<img src="geolonum_files/figure-html/mgo-tukey-ci-1.png" alt="Intervalos de confianza (95%) para las comparaciones usando la prueba de Tukey." width="70%" />
<p class="caption">
Figura 15.16: Intervalos de confianza (95%) para las comparaciones usando la prueba de Tukey.
</p>
</div>
<p>Además de realizar los análisis posteriores (contrastes <em>a priori</em> o comparaciones múltiples posteriores) y determinar en dónde hay diferencias significativas, es recomendable calcular el tamaño del efecto (<span class="math inline">\(d\)</span> o <span class="math inline">\(g\)</span>) para estos contrastes/comparaciones. Ésto se demuestra en el siguiente bloque de código donde a los resultados de Tukey se le agregan el tamaño de efecto y el intervalo de confianza para éste.</p>
<pre class="sourceCode r"><code class="sourceCode r">dat.aov.wide =<span class="st"> </span>dat.aov <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">id =</span> <span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(.)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">pivot_wider</span>(<span class="dt">names_from =</span> <span class="st">&#39;Location&#39;</span>,<span class="dt">values_from =</span> <span class="st">&#39;MgO&#39;</span>)

tukey <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">separate</span>(comparison,<span class="kw">c</span>(<span class="st">&#39;G1&#39;</span>,<span class="st">&#39;G2&#39;</span>),<span class="st">&#39;-&#39;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">d =</span> <span class="kw">map2</span>(G1,G2,<span class="op">~</span><span class="kw">hedges_g</span>(dat.aov.wide[[.x]] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">na.omit</span>(),
                                  dat.aov.wide[[.y]] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">na.omit</span>(),
                                  <span class="dt">ci =</span> <span class="dv">1</span><span class="op">-</span>a,<span class="dt">correction =</span> F) <span class="op">%&gt;%</span>
<span class="st">                    </span>as.data.frame)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">unnest</span>(d) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">as.data.frame</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>CI) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate_if</span>(is.numeric,<span class="op">~</span><span class="kw">round</span>(.,<span class="dv">3</span>))</code></pre>
<pre><code>## # A tibble: 3 x 9
##   G1      G2     estimate conf.low conf.high adj.p.value Hedges_g CI_low CI_high
##   &lt;chr&gt;   &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;
## 1 Sebago… Black…        3   -0.604      6.60       0.103     1.43 -0.052    2.83
## 2 Mount … Black…        6    2.40       9.60       0.003     2.86  0.836    4.80
## 3 Mount … Sebag…        3   -0.604      6.60       0.103     1.43 -0.052    2.83</code></pre>
<blockquote>
<p>Conclusión: El contenido de <span class="math inline">\(MgO\)</span> varía significativamente entre las localidades, <span class="math inline">\(F\)</span>(2, 9) = 10.80, <span class="math inline">\(p\)</span> = .004. El tamaño del efecto es grande, <span class="math inline">\(\eta^2\)</span> = .71, 95% IC [.16, .89], pero con un rango muy amplio. Análisis posteriores con Tukey HSD indican que hay una diferencia entre Mount Mica - Black Mountain (<span class="math inline">\(\Delta M = 6.00\)</span>, 95% IC <span class="math inline">\([2.39\)</span>, <span class="math inline">\(9.61]\)</span>, <span class="math inline">\(t(9) = 4.65\)</span>, <span class="math inline">\(p = .003\)</span>), pero no así entre Mount Mica - Sebago Batholith (<span class="math inline">\(\Delta M = 3.00\)</span>, 95% IC <span class="math inline">\([-0.61\)</span>, <span class="math inline">\(6.61]\)</span>, <span class="math inline">\(t(9) = 2.32\)</span>, <span class="math inline">\(p = .103\)</span>), ni Sebago Batholith - Black Mountain (<span class="math inline">\(\Delta M = 3.00\)</span>, 95% IC <span class="math inline">\([-0.61\)</span>, <span class="math inline">\(6.61]\)</span>, <span class="math inline">\(t(9) = 2.32\)</span>, <span class="math inline">\(p = .103\)</span>).</p>
</blockquote>
<div class="figure" style="text-align: center"><span id="fig:aov-stats"></span>
<img src="geolonum_files/figure-html/aov-stats-1.png" alt="Gráfico de caja mostrando el efecto de localidad sobre el contenido de MgO, la comparación significativa, así como el resumen estadístico respectivo." width="90%" />
<p class="caption">
Figura 15.17: Gráfico de caja mostrando el efecto de localidad sobre el contenido de MgO, la comparación significativa, así como el resumen estadístico respectivo.
</p>
</div>
<div id="relación-entre-la-prueba-t-de-2-muestras-independientes-y-anova-de-1-factor-entre-sujetos" class="section level3">
<h3><span class="header-section-number">15.8.1</span> Relación entre la prueba <span class="math inline">\(t\)</span> de 2 muestras independientes y ANOVA de 1-factor entre-sujetos</h3>
<p>Como se mencionó en la introducción de ANOVA, la prueba <span class="math inline">\(t\)</span> de 2 muestras independientes es un caso especial de ANOVA con 2 grupos, y se mencionó que <span class="math inline">\(F=t^2\)</span>. En esta pequeña sección se muestra la relación entre estas pruebas, tratando los datos usados en la prueba <span class="math inline">\(t\)</span> de 2 muestras independientes como un ANOVA.</p>
<pre class="sourceCode r"><code class="sourceCode r">braq.aov =<span class="st"> </span><span class="kw">aov</span>(values<span class="op">~</span>ind,<span class="dt">data =</span> braq)
<span class="kw">anova</span>(braq.aov)</code></pre>
<pre><code>## # A tibble: 2 x 5
##      Df `Sum Sq` `Mean Sq` `F value` `Pr(&gt;F)`
##   &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1     1    0.121    0.121       3.46   0.0812
## 2    16    0.559    0.0349     NA     NA</code></pre>
<p>El resultado de la prueba <span class="math inline">\(t\)</span> de 2 muestras independientes tenía <span class="math inline">\(t = 1.86\)</span>, y <span class="math inline">\(p = .081\)</span>. Si comparamos estos valores con el resultado de ANOVA se tiene que el valor-<em>p</em> es el mismo, y <span class="math inline">\(t^2=F \to 1.86^2=3.46\)</span>, que efectivamente es el valor de <span class="math inline">\(F\)</span>.</p>
<p>Lo otro que se puede comparar son los tamaños de efecto. Para la prueba <span class="math inline">\(t\)</span> de 2 muestras independientes se tenía <span class="math inline">\(d_s = 0.883\)</span>, y para el ANOVA de los mismos datos se tiene <span class="math inline">\(\eta_p^2 = .178\)</span> (el lector puede hacer el cálculo para corroborar).</p>
<p>Para pasar de <span class="math inline">\(d_s\)</span> a <span class="math inline">\(\eta_p^2\)</span> se pueden usar las Ecuaciones <a href="pruebas-estadísticas.html#eq:r-pb-d">(15.23)</a> para obtener <span class="math inline">\(r_{pb}\)</span> y <span class="math inline">\(\eta_p^2 = r_{pb}^2\)</span>, o <a href="pruebas-estadísticas.html#eq:r-pb-eta2">(15.24)</a> para obtener <span class="math inline">\(\eta_p^2\)</span> directamente, como se demuestra a continuación.</p>
<p><span class="math display">\[\begin{equation}
  r_{pb} = \frac{d_s}{\sqrt{d_s^2 + \frac{N^2-2N}{n_1  n_2}}}\\
  r_{pb} = \frac{0.883}{\sqrt{0.883^2 + \frac{18^2-2 \cdot 18}{8 \cdot 10}}} = .422\\
  \eta_p^2 = r_{pb}^2 = .422^2 = .178\\
  \eta_p^2 = \frac{t^2}{t^2+v} = \frac{1.86^2}{1.86^2+16} = .178
\end{equation}\]</span></p>
<p>Como se puede observar se obtiene el mismo valor de <span class="math inline">\(\eta^2\)</span> para ambas pruebas, demostrando de nuevo la relación entre las mismas.</p>
<p>Este pequeño ejemplo demuestra la relación que hay entre las pruebas mencionadas, donde lo importante es que se obtiene la misma conclusión.</p>
</div>
</div>
<div id="prueba-pearson" class="section level2">
<h2><span class="header-section-number">15.9</span> Correlación de Pearson</h2>
<p>En la sección de <a href="estadística-descriptiva-bivariable.html#bivar-cor">Correlación</a> (<a href="estadística-descriptiva-bivariable.html#bivar-cor">10.3</a>) se introdujo el concepto de correlación, más específicamente la correlación de Pearson. Esta es una medida de asociación entre dos variables (en este caso numéricas) que indica la magnitud y dirección de dicha asociación. La idea de la prueba para la correlación es determinar si la correlación encontrada es significativa o no, o sea, si difiere de cero <span class="citation">(Borradaile, <a href="#ref-borradaile2003">2003</a>; Davis, <a href="#ref-davis2002">2002</a>; Field et al., <a href="#ref-field2012">2012</a>; Nolan &amp; Heinzen, <a href="#ref-nolan2014">2014</a>; Swan &amp; Sandilands, <a href="#ref-swan1995">1995</a>; Trauth, <a href="#ref-trauth2015">2015</a>)</span>.</p>
<p>Para determinar la significancia de la correlación de Pearson se usa una prueba <span class="math inline">\(t\)</span>. Esta prueba se realiza con un ejemplo de <span class="citation">Davis (<a href="#ref-davis2002">2002</a>)</span>, donde se tiene la longitud de los ejes de cantos en una playa (Tabla <a href="pruebas-estadísticas.html#tab:cantos-playa">15.10</a>). Se quiere determinar si la correlación entre los ejes <span class="math inline">\(a\)</span> y <span class="math inline">\(b\)</span> es significativa, asumiendo <span class="math inline">\(\alpha = .1\)</span>.</p>
<table>
<caption>
<span id="tab:cantos-playa">Tabla 15.10: </span>Longitudes de los ejes de cantos en una playa
</caption>
<thead>
<tr>
<th style="text-align:center;">
Canto
</th>
<th style="text-align:center;">
Eje-a
</th>
<th style="text-align:center;">
Eje-b
</th>
<th style="text-align:center;">
Eje-c
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
8
</td>
<td style="text-align:center;">
7
</td>
<td style="text-align:center;">
3
</td>
</tr>
<tr>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
16
</td>
<td style="text-align:center;">
8
</td>
<td style="text-align:center;">
5
</td>
</tr>
<tr>
<td style="text-align:center;">
3
</td>
<td style="text-align:center;">
12
</td>
<td style="text-align:center;">
10
</td>
<td style="text-align:center;">
9
</td>
</tr>
<tr>
<td style="text-align:center;">
4
</td>
<td style="text-align:center;">
13
</td>
<td style="text-align:center;">
12
</td>
<td style="text-align:center;">
5
</td>
</tr>
<tr>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
16
</td>
<td style="text-align:center;">
14
</td>
<td style="text-align:center;">
5
</td>
</tr>
<tr>
<td style="text-align:center;">
6
</td>
<td style="text-align:center;">
14
</td>
<td style="text-align:center;">
9
</td>
<td style="text-align:center;">
8
</td>
</tr>
<tr>
<td style="text-align:center;">
7
</td>
<td style="text-align:center;">
16
</td>
<td style="text-align:center;">
13
</td>
<td style="text-align:center;">
13
</td>
</tr>
<tr>
<td style="text-align:center;">
8
</td>
<td style="text-align:center;">
11
</td>
<td style="text-align:center;">
6
</td>
<td style="text-align:center;">
3
</td>
</tr>
<tr>
<td style="text-align:center;">
9
</td>
<td style="text-align:center;">
15
</td>
<td style="text-align:center;">
9
</td>
<td style="text-align:center;">
9
</td>
</tr>
<tr>
<td style="text-align:center;">
10
</td>
<td style="text-align:center;">
13
</td>
<td style="text-align:center;">
10
</td>
<td style="text-align:center;">
9
</td>
</tr>
</tbody>
<tfoot>
<tr>
<td style="padding: 0; border: 0;" colspan="100%">
<sup></sup> Fuente: <span class="citation">Davis (<a href="#ref-davis2002">2002</a>)</span>
</td>
</tr>
</tfoot>
</table>
<ol style="list-style-type: decimal">
<li>Identificar la población, distribución, y la prueba apropiada:
<ul>
<li>Población: relación entre ejes <span class="math inline">\(a\)</span> y <span class="math inline">\(b\)</span></li>
<li>Distribución: de correlaciones</li>
<li>Prueba: <span class="math inline">\(t\)</span> de correlación</li>
</ul></li>
<li>Establecer las hipótesis nula y alterna:
<ul>
<li><span class="math inline">\(H_0: \rho = 0 \to\)</span> No hay relación entre los ejes</li>
<li><span class="math inline">\(H_1: \rho \neq 0 \to\)</span> Hay una relación entre los ejes</li>
<li><em>Nota</em>: <span class="math inline">\(\rho\)</span> es el parámetro poblacional para la correlación</li>
</ul></li>
<li>Determinar parámetros de la distribución a comparar (<span class="math inline">\(H_0\)</span>):
<ul>
<li><span class="math inline">\(r_{a,b} = .597\)</span></li>
<li><span class="math inline">\(v = N-2 = 10-2 = 8\)</span></li>
<li>Aquí el único parámetro del que depende la prueba son los grados de libertad <span class="math inline">\(v\)</span>, pero se muestra el valor de <span class="math inline">\(r\)</span> encontrado</li>
</ul></li>
<li>Determinar valores críticos
<ul>
<li><span class="math inline">\(\alpha = .1\)</span></li>
<li><span class="math inline">\(t_{\alpha/2,v} = t_{.1/2,8} = |1.860|\)</span></li>
</ul></li>
<li>Calcular el estadístico de prueba
<ul>
<li><span class="math inline">\(t = \frac{r \sqrt{v}}{\sqrt{1-r^2}} = \frac{.597 \cdot \sqrt{8}}{\sqrt{1-.597^2}} = 2.10\)</span></li>
<li><span class="math inline">\(90\% \ IC \ [.066,.864]\)</span></li>
</ul></li>
<li>Tomar una decisión
<ul>
<li>El estadístico de prueba es mayor al crítico, <span class="math inline">\(t &gt; t_{\alpha/2,v}\)</span></li>
<li>El valor-<em>p</em> es menor a <span class="math inline">\(\alpha = .1\)</span>, <span class="math inline">\(p = .068\)</span></li>
<li>El valor de <span class="math inline">\(0\)</span> no cae dentro del intervalo de confianza, <span class="math inline">\(IC \ [.066,.864]\)</span></li>
<li><em>Decisión</em>: Se rechaza <span class="math inline">\(H_0\)</span></li>
<li><em>Nota</em>: Tomar en cuenta que si se escogiera <span class="math inline">\(\alpha=.05\)</span>, no se rechazaría <span class="math inline">\(H_0\)</span></li>
</ul></li>
</ol>
<p>En <strong>R</strong> así como está la función <code>cor</code> para calcular el coeficiente de correlación, se tiene la función <code>cor.test</code> para la prueba específica. Se pueden especificar el tipo de correlación (<code>method</code>) y el nivel de significancia. El coeficiente de correlación es ya un tamaño de efecto, por lo que no es necesario realizar ningún cálculo adicional.</p>
<pre class="sourceCode r"><code class="sourceCode r">cantos =<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">Canto =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">10</span>,
                <span class="dt">a =</span> <span class="kw">c</span>(<span class="dv">8</span>,<span class="dv">16</span>,<span class="dv">12</span>,<span class="dv">13</span>,<span class="dv">16</span>,<span class="dv">14</span>,<span class="dv">16</span>,<span class="dv">11</span>,<span class="dv">15</span>,<span class="dv">13</span>),
                <span class="dt">b =</span> <span class="kw">c</span>(<span class="dv">7</span>,<span class="dv">8</span>,<span class="dv">10</span>,<span class="dv">12</span>,<span class="dv">14</span>,<span class="dv">9</span>,<span class="dv">13</span>,<span class="dv">6</span>,<span class="dv">9</span>,<span class="dv">10</span>),
                <span class="dt">c =</span> <span class="kw">c</span>(<span class="dv">3</span>,<span class="dv">5</span>,<span class="dv">9</span>,<span class="dv">5</span>,<span class="dv">5</span>,<span class="dv">8</span>,<span class="dv">13</span>,<span class="dv">3</span>,<span class="dv">9</span>,<span class="dv">9</span>))
a =<span class="st"> </span><span class="fl">0.1</span>

r.res =<span class="st"> </span><span class="kw">cor.test</span>(<span class="op">~</span>a<span class="op">+</span>b,<span class="dt">data =</span> cantos,
                 <span class="dt">method =</span> <span class="st">&#39;pearson&#39;</span>,
                 <span class="dt">conf.level =</span> <span class="dv">1</span><span class="op">-</span>a)
r.res</code></pre>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  a and b
## t = 2.1031, df = 8, p-value = 0.06861
## alternative hypothesis: true correlation is not equal to 0
## 90 percent confidence interval:
##  0.0661825 0.8641924
## sample estimates:
##       cor 
## 0.5966799</code></pre>
<blockquote>
<p>Conclusión: Los ejes <span class="math inline">\(a\)</span> y <span class="math inline">\(b\)</span> están correlacionados, <span class="math inline">\(r = .60\)</span>, 90% IC <span class="math inline">\([.07\)</span>, <span class="math inline">\(.86]\)</span>, <span class="math inline">\(t(8) = 2.10\)</span>, <span class="math inline">\(p = .069\)</span>. El efecto se puede considerar grande, con un rango de pequeño, hasta muy grande.</p>
</blockquote>
<div class="figure" style="text-align: center"><span id="fig:pearson-stats"></span>
<img src="geolonum_files/figure-html/pearson-stats-1.png" alt="Gráfico de dispersión mostrando la relación entre longitud de 2 ejes de cantos de playa, así como el resumen estadístico respectivo." width="90%" />
<p class="caption">
Figura 15.18: Gráfico de dispersión mostrando la relación entre longitud de 2 ejes de cantos de playa, así como el resumen estadístico respectivo.
</p>
</div>
</div>
<div id="prueba-rpb" class="section level2">
<h2><span class="header-section-number">15.10</span> Correlación Punto Biserial</h2>
<p>La correlación punto biserial es una medida de asociación entre dos variables, donde una variable es cuantitativa continua y la otra es cualitativa con dos categorías (dicotómica). La idea de la correlación es determinar la asociación entre los niveles de la variable cualitativa con respecto a la variable continua. La prueba determina si hay una diferencia o relación significativa entre estas variables, o si hay un efecto de la variable cualitativa sobre la variable continua. Lo anterior es la misma idea tras la prueba <span class="math inline">\(t\)</span> de dos muestras independientes, por lo que la conclusión es la misma pero con un tamaño de efecto diferente, <span class="math inline">\(r\)</span> en vez de <span class="math inline">\(d\)</span> <span class="citation">(Field et al., <a href="#ref-field2012">2012</a>; Sheskin, <a href="#ref-sheskin2011">2011</a>)</span>.</p>
<p>El procedimento para calcular esta correlación sería:</p>
<ol style="list-style-type: decimal">
<li>Asignar una de las categorías como 1 y la otra como 0,</li>
<li>Calcular la media de la variable continua para cada categoría (<span class="math inline">\(\bar{y}_1, \ \bar{y}_0\)</span>),</li>
<li>Calcular la desviación estándar de la variable continua (<span class="math inline">\(s_y\)</span>),</li>
<li>Calcular <span class="math inline">\(r_{pb}\)</span> usando la Ecuación <a href="pruebas-estadísticas.html#eq:r-pb">(15.12)</a>.</li>
</ol>
<p>Lo anterior se demuestra a continuación con los datos del ejemplo usado en la prueba <span class="math inline">\(t\)</span> de 2 muestras independientes (<a href="pruebas-estadísticas.html#prueba-t2-ind">15.6</a>), para demostrar que son homólogas y se obtienen las mismas conclusiones. Para determinar la significancia de la correlación punto biserial se usa la misma prueba <span class="math inline">\(t\)</span> que se usó con la correlación de Pearson.</p>
<pre class="sourceCode r"><code class="sourceCode r">braq =<span class="st"> </span>braq <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">ind.bin =</span> <span class="kw">ifelse</span>(ind <span class="op">==</span><span class="st"> &#39;A&#39;</span>,<span class="dv">1</span>,<span class="dv">0</span>))
braq</code></pre>
<pre><code>## # A tibble: 18 x 3
##    values ind   ind.bin
##     &lt;dbl&gt; &lt;fct&gt;   &lt;dbl&gt;
##  1    3.2 A           1
##  2    3.1 A           1
##  3    3.1 A           1
##  4    3.3 A           1
##  5    2.9 A           1
##  6    2.9 A           1
##  7    3.5 A           1
##  8    3   A           1
##  9    3.1 B           0
## 10    3.1 B           0
## 11    2.8 B           0
## 12    3.1 B           0
## 13    3   B           0
## 14    2.6 B           0
## 15    3   B           0
## 16    3   B           0
## 17    3.1 B           0
## 18    2.8 B           0</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">N =<span class="st"> </span><span class="kw">nrow</span>(braq)

braq <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(ind.bin) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">media =</span> <span class="kw">mean</span>(values), 
            <span class="dt">n =</span> <span class="kw">n</span>())</code></pre>
<pre><code>## # A tibble: 2 x 3
##   ind.bin media     n
##     &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;
## 1       0  2.96    10
## 2       1  3.12     8</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">braq <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">s_y =</span> <span class="kw">sd</span>(values))</code></pre>
<pre><code>## # A tibble: 1 x 1
##     s_y
##   &lt;dbl&gt;
## 1   0.2</code></pre>
<p><span class="math display">\[\begin{equation}
  r_{pb} = \frac{\bar{y}_1-\bar{y}_0}{s_y}\sqrt{\frac{n_1 n_0}{N(N-1)}}\\
  r_{pb} = \frac{3.125-2.96}{0.2}\sqrt{\frac{8 \cdot 10}{18(18-1)}} = .422
\end{equation}\]</span></p>
<p>La dirección del efecto está únicamente en función de cuál categoría se escoge como 1. Lo que indica el valor de <span class="math inline">\(r_{pb} = .422\)</span> es que hay una relación positiva hacia la capa A (los braquiópodos son más largos en la capa A), ya que ésta fue la que se codificó como 1.</p>
<ol style="list-style-type: decimal">
<li>Identificar la población, distribución, y la prueba apropiada:
<ul>
<li>Población: relación entre la longitud de braquiópodos y la capa a la que pertenecen</li>
<li>Distribución: <span class="math inline">\(t\)</span></li>
<li>Prueba: <span class="math inline">\(t\)</span> de correlación</li>
</ul></li>
<li>Establecer las hipótesis nula y alterna:
<ul>
<li><span class="math inline">\(H_0: \rho_{pb} = 0 \to\)</span> No hay relación entre la longitud de braquiópodos y la capa a la que pertenecen</li>
<li><span class="math inline">\(H_1: \rho_{pb} \neq 0 \to\)</span> Hay una relación entre la longitud de braquiópodos y la capa a la que pertenecen</li>
</ul></li>
<li>Determinar parámetros de la distribución a comparar (<span class="math inline">\(H_0\)</span>):
<ul>
<li><span class="math inline">\(r_{pb} = .422\)</span></li>
<li><span class="math inline">\(v = N-2 = 18-2 = 16\)</span></li>
</ul></li>
<li>Determinar valores críticos
<ul>
<li><span class="math inline">\(\alpha = .05\)</span></li>
<li><span class="math inline">\(t_{\alpha/2,v} = t_{.05/2,16} = |2.12|\)</span></li>
</ul></li>
<li>Calcular el estadístico de prueba
<ul>
<li><span class="math inline">\(t = \frac{r_{pb} \sqrt{v}}{\sqrt{1-r_{pb}^2}} = \frac{.422 \cdot \sqrt{16}}{\sqrt{1-.422^2}} = 1.86\)</span></li>
<li><span class="math inline">\(95\% \ IC \ [-.056,.742]\)</span></li>
</ul></li>
<li>Tomar una decisión
<ul>
<li>El estadístico de prueba es menor al crítico, <span class="math inline">\(t &lt; t_{\alpha/2,v}\)</span></li>
<li>El valor-<em>p</em> es mayor a <span class="math inline">\(\alpha = .05\)</span>, <span class="math inline">\(p = .081\)</span></li>
<li>El valor de <span class="math inline">\(0\)</span> cae dentro del intervalo de confianza, <span class="math inline">\(IC \ [-.056,.742]\)</span></li>
<li><em>Decisión</em>: No se rechaza <span class="math inline">\(H_0\)</span></li>
<li><em>Nota</em>: Tomar en cuenta que si se escogiera <span class="math inline">\(\alpha=.1\)</span>, se rechazaría <span class="math inline">\(H_0\)</span></li>
</ul></li>
</ol>
<p>En <strong>R</strong> se usa la función <code>cor.test</code> con las columnas de la variable continua y la variable dicotómica (1 y 0), usando el tipo de correlación (<code>method</code>) de <code>pearson</code>, e indicando el nivel de significancia. El coeficiente de correlación es ya un tamaño de efecto, por lo que no es necesario realizar ningún cálculo adicional.</p>
<pre class="sourceCode r"><code class="sourceCode r">a =<span class="st"> </span><span class="fl">.05</span>
rpb.res =<span class="st"> </span><span class="kw">cor.test</span>(<span class="op">~</span>values<span class="op">+</span>ind.bin,<span class="dt">data =</span> braq,
                 <span class="dt">method =</span> <span class="st">&#39;pearson&#39;</span>,
                 <span class="dt">conf.level =</span> <span class="dv">1</span><span class="op">-</span>a)
rpb.res</code></pre>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  values and ind.bin
## t = 1.861, df = 16, p-value = 0.08122
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  -0.05608465  0.74247724
## sample estimates:
##       cor 
## 0.4218307</code></pre>
<p>Estos resultados muestran el mismo valor <span class="math inline">\(t\)</span> y mismo valor-<em>p</em> que la prueba <span class="math inline">\(t\)</span> de 2 muestras independientes, demostrando que ambas son homólogas.</p>
<blockquote>
<p>Conclusión: La longitud de los braquiópos no está correlacionada con la capa a la cual pertenecen, <span class="math inline">\(r_{pb} = .42\)</span>, 95% IC <span class="math inline">\([-.06\)</span>, <span class="math inline">\(.74]\)</span>, <span class="math inline">\(t(16) = 1.86\)</span>, <span class="math inline">\(p = .081\)</span>. El efecto se puede considerar mediano, con un rango amplio de muy pequeño, en la dirección opuesta, hasta muy grande.</p>
</blockquote>
<div class="figure" style="text-align: center"><span id="fig:rpb-stats"></span>
<img src="geolonum_files/figure-html/rpb-stats-1.png" alt="Gráfico de dispersión mostrando la relación entre longitud de los braquiópodos de acuerdo a la capa que pertencen, así como el resumen estadístico respectivo." width="90%" />
<p class="caption">
Figura 15.19: Gráfico de dispersión mostrando la relación entre longitud de los braquiópodos de acuerdo a la capa que pertencen, así como el resumen estadístico respectivo.
</p>
</div>
</div>
<div id="prueba-chi" class="section level2">
<h2><span class="header-section-number">15.11</span> <span class="math inline">\(\chi^2\)</span> para 1 varianza</h2>
<p>Así como se pueden realizar pruebas estadísticas sobre la media poblacional (<span class="math inline">\(\mu\)</span>), se pueden realizar pruebas estadísticas sobre la varianza poblacional (<span class="math inline">\(\sigma^2\)</span>), aunque son menos comunes. Por esto último es que para estas pruebas no hay tamaños de efecto estandarizados, sino más bien se usan los datos en escala original.</p>
<p>El uso de la prueba <span class="math inline">\(\chi^2\)</span> de 1 muestra se realiza con el ejemplo de la sección <a href="estimación-e-hipótesis.html#estim-ic-chi">14.2.3</a> <span class="citation">(Swan &amp; Sandilands, <a href="#ref-swan1995">1995</a>)</span>, donde se tenía el contenido de cuarzo en secciones delgadas de una roca ígnea. Es posible que esta muestra provenga de una población con varianza 12 (<span class="math inline">\(\sigma^2_0=12\)</span>)? Asuma <span class="math inline">\(\alpha = .05\)</span>.</p>
<ol style="list-style-type: decimal">
<li>Identificar la población, distribución, y la prueba apropiada:
<ul>
<li>Población: variabilidad del contenido de cuarzo en la roca ígnea</li>
<li>Distribución: de varianza</li>
<li>Prueba: <span class="math inline">\(\chi^2\)</span> de 1 muestra porque se tiene 1 muestra, se quiere hacer inferencia sobre la variabilidad, y se quiere comparar con un valor hipotético</li>
</ul></li>
<li>Establecer las hipótesis nula y alterna:
<ul>
<li><span class="math inline">\(H_0: \sigma^2 = \sigma^2_0 \to\)</span> La variabilidad en el contenido de cuarzo en la roca ígnea es <em>igual</em> a un valor hipotético o conocido (12)</li>
<li><span class="math inline">\(H_1: \sigma^2 \neq \sigma^2_0 \to\)</span> La variabilidad en el contenido de cuarzo en la roca ígnea es <em>diferente</em> a un valor hipotético o conocido (12)</li>
</ul></li>
<li>Determinar parámetros de la distribución a comparar (<span class="math inline">\(H_0\)</span>):
<ul>
<li><span class="math inline">\(\sigma^2_0 = 20\)</span></li>
<li><span class="math inline">\(v = N-1 = 8-1 = 7\)</span></li>
</ul></li>
<li>Determinar valores críticos
<ul>
<li><span class="math inline">\(\alpha = .05\)</span></li>
<li><span class="math inline">\(\chi^2_{\alpha/2,v} = \chi^2_{.05/2,7} = 12.83\)</span></li>
<li><span class="math inline">\(\chi^2_{1-\alpha/2,v} = \chi^2_{1-0.05/2,7} = 0.83\)</span></li>
</ul></li>
<li>Calcular el estadístico de prueba
<ul>
<li><span class="math inline">\(\chi^2 = \frac{(n-1)s^2}{\sigma_0^2} = \frac{(8-1)9.507}{12} = 5.546\)</span></li>
<li><span class="math inline">\(4.16 &lt; \sigma^2 &lt; 39.38 \to 95\% \ IC \ [4.16,39.38]\)</span></li>
</ul></li>
<li>Tomar una decisión
<ul>
<li>El estadístico de prueba cae entre los valores críticos</li>
<li>El valor-<em>p</em> es mayor a <span class="math inline">\(\alpha = .05\)</span>, <span class="math inline">\(p = .8127\)</span></li>
<li>El valor hipotético del parámetro cae dentro del intervalo de confianza, <span class="math inline">\(IC \ [4.16, 39.38]\)</span></li>
<li><em>Decisión</em>: No se rechaza <span class="math inline">\(H_0\)</span></li>
</ul></li>
</ol>
<p>En <strong>R</strong> el paquete <em>DescTools</em> trae la función <code>VarTest</code> para realizar esta prueba, donde ocupa brindar el vector de datos, la varianza poblacional (<code>sigma.squared</code>), y el nivel de confianza.</p>
<pre class="sourceCode r"><code class="sourceCode r">sigma0 =<span class="st"> </span><span class="dv">12</span>
a =<span class="st"> </span><span class="fl">0.05</span>

cuarzo =<span class="st"> </span><span class="kw">c</span>(<span class="fl">23.5</span>, <span class="fl">16.6</span>, <span class="fl">25.4</span>, <span class="fl">19.1</span>, <span class="fl">19.3</span>, <span class="fl">22.4</span>, <span class="fl">20.9</span>, <span class="fl">24.9</span>)
n =<span class="st"> </span><span class="kw">length</span>(cuarzo)

chi.res =<span class="st"> </span><span class="kw">VarTest</span>(<span class="dt">x =</span> cuarzo, 
                  <span class="dt">sigma.squared =</span> sigma0,
                  <span class="dt">conf.level =</span> <span class="dv">1</span><span class="op">-</span>a)
chi.res</code></pre>
<pre><code>## 
##  One Sample Chi-Square test on variance
## 
## data:  cuarzo
## X-squared = 5.5457, df = 7, p-value = 0.8127
## alternative hypothesis: true variance is not equal to 12
## 95 percent confidence interval:
##   4.155981 39.381007
## sample estimates:
## variance of x 
##      9.506964</code></pre>
<blockquote>
<p>Conclusión: La variabilidad del contenido de cuarzo no difiere significativamente del valor propuesto, <span class="math inline">\(s^2 = 9.51\)</span>, 95% IC <span class="math inline">\([4.16\)</span>, <span class="math inline">\(39.38]\)</span>, <span class="math inline">\(\chi^2(7, n = 8) = 5.55\)</span>, <span class="math inline">\(p = .813\)</span>.</p>
</blockquote>
</div>
<div id="prueba-f" class="section level2">
<h2><span class="header-section-number">15.12</span> <span class="math inline">\(F\)</span> para 2 varianzas</h2>
<p>En algunas de las pruebas se hace la suposición de igualdad de varianzas. Lo anterior se puede evaluar empíricamente comparando la menor y mayor desviación estándar, donde la relación entre ellas no debiera ser mayor a 2 <span class="citation">(Cumming &amp; Calin-Jageman, <a href="#ref-cumming2017">2017</a>)</span>. Si se quiere realizar de manera formal se puede realizar la prueba aquí descrita.</p>
<p>El uso de la prueba <span class="math inline">\(F\)</span> para 2 varianzas se realiza con el ejemplo de la sección <a href="pruebas-estadísticas.html#prueba-t2-ind">15.6</a> <span class="citation">(Swan &amp; Sandilands, <a href="#ref-swan1995">1995</a>)</span>, donde se tenían braquiópodos en dos capas (A, B) y se les midió la longitud (cm). Es factible la suposición de igualdad de varianzas (<span class="math inline">\(\sigma^2_1=\sigma^2_2\)</span>)? Asuma <span class="math inline">\(\alpha = .05\)</span>.</p>
<ol style="list-style-type: decimal">
<li>Identificar la población, distribución, y la prueba apropiada:
<ul>
<li>Población: variabilidad de la longitud de braquiópodos en las capas A y B</li>
<li>Distribución: de razón de varianzas (<span class="math inline">\(F\)</span>)</li>
<li>Prueba: <span class="math inline">\(F\)</span> para 2 muestras (varianzas), se quiere hacer inferencia sobre la variabilidad, y se quieren comparar las varianzas de 2 muestras</li>
</ul></li>
<li>Establecer las hipótesis nula y alterna:
<ul>
<li><span class="math inline">\(H_0: \sigma^2_1 = \sigma^2_2, \ \frac{\sigma^2_1}{\sigma^2_2} = 1 \to\)</span> La variabilidad la longitud de braquiópodos de la capa A es <em>igual</em> a la variabilidad la longitud de braquiópodos de la capa B</li>
<li><span class="math inline">\(H_1: \sigma^2_1 \neq \sigma^2_2, \ \frac{\sigma^2_1}{\sigma^2_2} \neq 1 \to\)</span> La variabilidad la longitud de braquiópodos de la capa A es <em>diferente</em> a la variabilidad la longitud de braquiópodos de la capa B</li>
</ul></li>
<li>Determinar parámetros de la distribución a comparar (<span class="math inline">\(H_0\)</span>):
<ul>
<li><span class="math inline">\(v_1 = n_1-1 = 8-1 = 7\)</span></li>
<li><span class="math inline">\(v_2 = n_2-1 = 10-1 = 9\)</span></li>
</ul></li>
<li>Determinar valores críticos
<ul>
<li><span class="math inline">\(\alpha = .05\)</span></li>
<li><span class="math inline">\(F_{\alpha/2,v_1,v_2} = F_{.05/2,8,10} = 3.85\)</span></li>
<li><span class="math inline">\(F_{1-\alpha/2,v_1,v_2} = F_{1-0.05/2,8,10} = 0.23\)</span></li>
</ul></li>
<li>Calcular el estadístico de prueba
<ul>
<li><span class="math inline">\(\frac{\sigma^2_1}{\sigma^2_2} = \frac{0.042}{0.029} = 1.45\)</span></li>
<li><span class="math inline">\(0.345 &lt; \frac{\sigma^2_1}{\sigma^2_2} &lt; 6.985 \to 95\% \ IC \ [0.345,6.985]\)</span></li>
</ul></li>
<li>Tomar una decisión
<ul>
<li>El estadístico de prueba cae entre los valores críticos</li>
<li>El valor-<em>p</em> es mayor a <span class="math inline">\(\alpha = .05\)</span>, <span class="math inline">\(p = .599\)</span></li>
<li>El valor hipotético del parámetro (1) cae dentro del intervalo de confianza, <span class="math inline">\(IC \ [0.345, 6.985]\)</span></li>
<li><em>Decisión</em>: No se rechaza <span class="math inline">\(H_0\)</span></li>
</ul></li>
</ol>
<p>En <strong>R</strong> la función <code>var.test</code> para realizar esta prueba, donde se ocupan brindar los vectores de datos, la razón de varianzas (<code>ratio</code>), y el nivel de confianza.</p>
<pre class="sourceCode r"><code class="sourceCode r">a =<span class="st"> </span><span class="fl">0.05</span>

f.res =<span class="st"> </span><span class="kw">var.test</span>(<span class="dt">x =</span> A,<span class="dt">y =</span> B,
                 <span class="dt">ratio =</span> <span class="dv">1</span>,
                 <span class="dt">conf.level =</span> <span class="dv">1</span><span class="op">-</span>a)
f.res</code></pre>
<pre><code>## 
##  F test to compare two variances
## 
## data:  A and B
## F = 1.4367, num df = 7, denom df = 9, p-value = 0.5994
## alternative hypothesis: true ratio of variances is not equal to 1
## 95 percent confidence interval:
##  0.3423094 6.9294596
## sample estimates:
## ratio of variances 
##           1.436688</code></pre>
<blockquote>
<p>Conclusión: La variabilidad de la longitud de los braquiópodos en las capas A y B no varia significativamente, <span class="math inline">\(\text{razón de varianzas} = 1.44\)</span>, 95% IC <span class="math inline">\([0.34\)</span>, <span class="math inline">\(6.93]\)</span>, <span class="math inline">\(F(7, 9) = 1.44\)</span>, <span class="math inline">\(p = .599\)</span>.</p>
</blockquote>

</div>
</div>
<h3>Referencias</h3>
<div id="refs" class="references">
<div id="ref-americanpsychologicalassociation2010">
<p>American Psychological Association. (2010). <em>Publication Manual of the American Psychological Association</em> (6.ª ed.).</p>
</div>
<div id="ref-R-effectsize">
<p>Ben-Shachar, M. S., Makowski, D., &amp; Lüdecke, D. (2020). <em>effectsize: Indices of Effect Size and Standardized Parameters</em>. <a href="https://CRAN.R-project.org/package=effectsize">https://CRAN.R-project.org/package=effectsize</a></p>
</div>
<div id="ref-borradaile2003">
<p>Borradaile, G. J. (2003). <em>Statistics of Earth Science Data: Their Distribution in Time, Space and Orientation</em>. Springer-Verlag Berlin Heidelberg.</p>
</div>
<div id="ref-R-MOTE">
<p>Buchanan, E. M., Gillenwaters, A. M., Scofield, J. E., &amp; Valentine, K. D. (2019). <em>MOTE: Effect Size and Confidence Interval Calculator</em>. <a href="https://CRAN.R-project.org/package=MOTE">https://CRAN.R-project.org/package=MOTE</a></p>
</div>
<div id="ref-cohen1988">
<p>Cohen, J. (1988). <em>Statistical Power Analysis for the Behavioral Sciences</em> (2.ª ed.). Erlbaum.</p>
</div>
<div id="ref-cumming2012">
<p>Cumming, G. (2012). <em>Understanding The New Statistics - Effect Sizes, Confidence Intervals, and Meta-Analysis</em>. Rutledge.</p>
</div>
<div id="ref-cumming2017">
<p>Cumming, G., &amp; Calin-Jageman, R. (2017). <em>Introduction to the New Statistics: Estimation, Open Science, and Beyond</em>. Rutledge.</p>
</div>
<div id="ref-cumming2005ap">
<p>Cumming, G., &amp; Finch, S. (2005). Inference by Eye: Confidence Intervals and How to Read Pictures of Data. <em>American Psychologist</em>, <em>60</em>(2), 170-180. <a href="https://doi.org/10.1037/0003-066X.60.2.170">https://doi.org/10.1037/0003-066X.60.2.170</a></p>
</div>
<div id="ref-davis2002">
<p>Davis, J. C. (2002). <em>Statistics and Data Analysis in Geology</em> (3.ª ed.). John Wiley &amp; Sons.</p>
</div>
<div id="ref-ellis2010">
<p>Ellis, P. D. (2010). <em>The Essential Guide to Effect Sizes : Statistical Power, Meta-Analysis, and the Interpretation of Research Results</em>. Cambridge University Press.</p>
</div>
<div id="ref-R-itns">
<p>Erceg-Hurn, D., Cumming, G., &amp; Calin-Jageman, R. (2017). <em>itns: Datasets from the book Introduction to the New Statistics</em>.</p>
</div>
<div id="ref-field2012">
<p>Field, A., Miles, J., &amp; Field, Z. (2012). <em>Discovering Statistics Using R</em>. SAGE Publications Ltd.</p>
</div>
<div id="ref-fritz2012joepg">
<p>Fritz, C. O., Morris, P. E., &amp; Richler, J. J. (2012). Effect size estimates: Current use, calculations, and interpretation. <em>Journal of Experimental Psychology: General</em>, <em>141</em>(1), 2-18. <a href="https://doi.org/10.1037/a0024338">https://doi.org/10.1037/a0024338</a></p>
</div>
<div id="ref-grissom2005">
<p>Grissom, R. J., &amp; Kim, J. J. (2005). <em>Effect Sizes for Research: A Broad Practical Approach</em>. Erlbaum.</p>
</div>
<div id="ref-hedges1985">
<p>Hedges, L. V., &amp; Olkin, I. (1985). <em>Statistical Methods for Meta-Analysis</em>. Academic Press.</p>
</div>
<div id="ref-lakens2013fp">
<p>Lakens, D. (2013). Calculating and reporting effect sizes to facilitate cumulative science: A practical primer for t-tests and ANOVAs. <em>Frontiers in Psychology</em>, <em>4</em>. <a href="https://doi.org/10.3389/fpsyg.2013.00863">https://doi.org/10.3389/fpsyg.2013.00863</a></p>
</div>
<div id="ref-magnusson2020">
<p>Magnusson, K. (2020). <em>Interpreting Cohen’s d Effect Size: An Interactive Visualization</em> (Versión 2.1.1) [Computer software]. <a href="https://rpsychologist.com/d3/cohend/">https://rpsychologist.com/d3/cohend/</a></p>
</div>
<div id="ref-mcgrath2006pm">
<p>McGrath, R. E., &amp; Meyer, G. J. (2006). When effect sizes disagree: The case of r and d. <em>Psychological Methods</em>, <em>11</em>(4), 386-401. <a href="https://doi.org/10.1037/1082-989X.11.4.386">https://doi.org/10.1037/1082-989X.11.4.386</a></p>
</div>
<div id="ref-mcgraw1992pb">
<p>McGraw, K. O., &amp; Wong, S. P. (1992). A Common Language Effect Size Statistic. <em>Psychonomic Bulletin</em>, <em>111</em>(2), 361-365.</p>
</div>
<div id="ref-mckillup2010">
<p>McKillup, S., &amp; Darby Dyar, M. (2010). <em>Geostatistics Explained: An Introductory Guide for Earth Scientists</em>. Cambridge University Press. <a href="www.cambridge.org/9780521763226">www.cambridge.org/9780521763226</a></p>
</div>
<div id="ref-nakagawa2007br">
<p>Nakagawa, S., &amp; Cuthill, I. C. (2007). Effect size, confidence interval and statistical significance: A practical guide for biologists. <em>Biological Reviews</em>, <em>82</em>(4), 591-605. <a href="https://doi.org/10.1111/j.1469-185X.2007.00027.x">https://doi.org/10.1111/j.1469-185X.2007.00027.x</a></p>
</div>
<div id="ref-nolan2014">
<p>Nolan, S. A., &amp; Heinzen, T. E. (2014). <em>Statistics for the Behavioral Sciences</em> (3.ª ed.). Worth Publishers.</p>
</div>
<div id="ref-olejnik2000cep">
<p>Olejnik, S., &amp; Algina, J. (2000). Measures of Effect Size for Comparative Studies: Applications, Interpretations, and Limitations. <em>Contemporary Educational Psychology</em>, <em>25</em>(3), 241-286. <a href="https://doi.org/10.1006/ceps.2000.1040">https://doi.org/10.1006/ceps.2000.1040</a></p>
</div>
<div id="ref-reiser1999jrss">
<p>Reiser, B., &amp; Faraggi, D. (1999). Confidence intervals for the overlapping coefficient: The normal equal variance case. <em>Journal of the Royal Statistical Society</em>, <em>48</em>(3), 413-418.</p>
</div>
<div id="ref-R-psych">
<p>Revelle, W. (2020). <em>psych: Procedures for Psychological, Psychometric, and Personality Research</em>. <a href="https://CRAN.R-project.org/package=psych">https://CRAN.R-project.org/package=psych</a></p>
</div>
<div id="ref-ruscio2008pm">
<p>Ruscio, J. (2008). A probability-based measure of effect size: Robustness to base rates and other factors. <em>Psychological Methods</em>, <em>13</em>(1), 19-30. <a href="https://doi.org/10.1037/1082-989X.13.1.19">https://doi.org/10.1037/1082-989X.13.1.19</a></p>
</div>
<div id="ref-sheskin2011">
<p>Sheskin, D. J. (2011). <em>Handbook of Parametric and Nonparametric Statistical Procedures</em> (5.ª ed.). CRC Press.</p>
</div>
<div id="ref-swan1995">
<p>Swan, A., &amp; Sandilands, M. (1995). <em>Introduction to Geological Data Analysis</em>. Blackwell Science.</p>
</div>
<div id="ref-thompson2007ps">
<p>Thompson, B. (2007). Effect sizes, confidence intervals, and confidence intervals for effect sizes. <em>Psychology in the Schools</em>, <em>44</em>(5), 423-432. <a href="https://doi.org/10.1002/pits.20234">https://doi.org/10.1002/pits.20234</a></p>
</div>
<div id="ref-tomczak2014tss">
<p>Tomczak, M., &amp; Tomczak, E. (2014). The need to report effect size estimates revisited. An overview of some recommended measures of effect size. <em>Trends in Sport Sciences</em>, <em>1</em>(21), 19-25.</p>
</div>
<div id="ref-R-effsize">
<p>Torchiano, M. (2018). <em>effsize: Efficient Effect Size Computation</em>. <a href="https://CRAN.R-project.org/package=effsize">https://CRAN.R-project.org/package=effsize</a></p>
</div>
<div id="ref-trauth2015">
<p>Trauth, M. (2015). <em>MATLAB® Recipes for Earth Sciences</em> (4.ª ed.). Springer-Verlag Berlin Heidelberg.</p>
</div>
<div id="ref-triola2004">
<p>Triola, M. F. (2004). <em>Probabilidad y Estadística</em> (9.ª ed.). Pearson Educación.</p>
</div>
<div id="ref-walpole2012">
<p>Walpole, R. E., Myers, R. H., &amp; Myers, S. L. (2012). <em>Probabilidad y Estadística Para Ingeniería y Ciencias</em>. Pearson.</p>
</div>
<div id="ref-zou2007pm">
<p>Zou, G. Y. (2007). Toward using confidence intervals to compare correlations. <em>Psychological Methods</em>, <em>12</em>(4), 399-413. <a href="https://doi.org/10.1037/1082-989X.12.4.399">https://doi.org/10.1037/1082-989X.12.4.399</a></p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="estimación-e-hipótesis.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="estadística-no-paramétrica.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
