
@article{algina2003eapm,
  title = {Approximate {{Confidence Intervals}} for {{Effect Sizes}}},
  author = {Algina, James and Keselman, H. J.},
  date = {2003-08},
  journaltitle = {Educational and Psychological Measurement},
  shortjournal = {Educational and Psychological Measurement},
  volume = {63},
  pages = {537--553},
  issn = {0013-1644, 1552-3888},
  doi = {10.1177/0013164403256358},
  url = {http://journals.sagepub.com/doi/10.1177/0013164403256358},
  urldate = {2020-06-30},
  file = {/Users/maximiliano/Documents/pCloud sync/zotero-lib/Algina_Keselman/Algina_Keselman_2003_Approximate Confidence Intervals for Effect Sizes.pdf},
  langid = {english},
  number = {4}
}

@book{altman2000,
  title = {Statistics with {{Confidence}}: {{Confidence}} Intervals and Statistical Guidelines},
  author = {Altman, Douglas G. and Machin, David and Bryant, Trevor N. and Gardner, Martin J.},
  date = {2000},
  edition = {2},
  publisher = {{BMJ Books}}
}

@book{americanpsychologicalassociation2010,
  title = {Publication Manual of the {{American Psychological Association}}},
  author = {{American Psychological Association}},
  date = {2010},
  edition = {6},
  location = {{Washington, D.C}}
}

@book{borradaile2003,
  title = {Statistics of {{Earth Science Data}}: {{Their Distribution}} in {{Time}}, {{Space}} and {{Orientation}}},
  author = {Borradaile, Graham J.},
  date = {2003},
  publisher = {{Springer-Verlag Berlin Heidelberg}},
  location = {{New York}},
  isbn = {978-3-642-07815-6}
}

@book{cohen1988,
  title = {Statistical Power Analysis for the Behavioral Sciences},
  author = {Cohen, Jacob},
  date = {1988},
  edition = {2},
  publisher = {{Erlbaum}},
  location = {{Hillsdale, NJ}}
}

@book{cohen2003,
  title = {Applied Multiple Regression/Correlation Analysis for the Behavioral Sciences},
  author = {Cohen, Jacob and Cohen, Patricia and West, Stephen G. and Aiken, Leona S.},
  date = {2003},
  edition = {3},
  publisher = {{Erlbaum}}
}

@article{cumming2005ap,
  title = {Inference by {{Eye}}: {{Confidence Intervals}} and {{How}} to {{Read Pictures}} of {{Data}}.},
  shorttitle = {Inference by {{Eye}}},
  author = {Cumming, Geoff and Finch, Sue},
  date = {2005},
  journaltitle = {American Psychologist},
  shortjournal = {American Psychologist},
  volume = {60},
  pages = {170--180},
  issn = {1935-990X, 0003-066X},
  doi = {10.1037/0003-066X.60.2.170},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0003-066X.60.2.170},
  urldate = {2020-05-28},
  file = {/Users/maximiliano/Documents/pCloud sync/zotero-lib/Cumming_Finch/Cumming_Finch_2005_Inference by Eye.pdf},
  langid = {english},
  number = {2}
}

@book{cumming2012,
  title = {Understanding {{The New Statistics}} - {{Effect Sizes}}, {{Confidence Intervals}}, and {{Meta}}-{{Analysis}}},
  author = {Cumming, Geoff},
  date = {2012},
  publisher = {{Rutledge}},
  location = {{New York}}
}

@article{cumming2014ps,
  title = {The {{New Statistics}}: {{Why}} and {{How}}},
  shorttitle = {The {{New Statistics}}},
  author = {Cumming, Geoff},
  date = {2014-01},
  journaltitle = {Psychological Science},
  shortjournal = {Psychol Sci},
  volume = {25},
  pages = {7--29},
  issn = {0956-7976, 1467-9280},
  doi = {10.1177/0956797613504966},
  url = {http://journals.sagepub.com/doi/10.1177/0956797613504966},
  urldate = {2020-05-28},
  abstract = {We need to make substantial changes to how we conduct research. First, in response to heightened concern that our published research literature is incomplete and untrustworthy, we need new requirements to ensure research integrity. These include prespecification of studies whenever possible, avoidance of selection and other inappropriate dataanalytic practices, complete reporting, and encouragement of replication. Second, in response to renewed recognition of the severe flaws of null-hypothesis significance testing (NHST), we need to shift from reliance on NHST to estimation and other preferred techniques. The new statistics refers to recommended practices, including estimation based on effect sizes, confidence intervals, and meta-analysis. The techniques are not new, but adopting them widely would be new for many researchers, as well as highly beneficial. This article explains why the new statistics are important and offers guidance for their use. It describes an eight-step new-statistics strategy for research with integrity, which starts with formulation of research questions in estimation terms, has no place for NHST, and is aimed at building a cumulative quantitative discipline.},
  file = {/Users/maximiliano/Documents/pCloud sync/zotero-lib/Cumming/Cumming_2014_The New Statistics.pdf},
  langid = {english},
  number = {1}
}

@book{cumming2017,
  title = {Introduction to the {{New Statistics}}: {{Estimation}}, {{Open Science}}, and {{Beyond}}},
  author = {Cumming, Geoff and Calin-Jageman, Robert},
  date = {2017},
  publisher = {{Rutledge}},
  isbn = {978-1-315-70860-7}
}

@book{davis2002,
  title = {Statistics and {{Data Analysis}} in {{Geology}}},
  author = {Davis, J. C.},
  date = {2002},
  edition = {3},
  publisher = {{John Woley \& Sons.}},
  location = {{New Delhi}},
  isbn = {978-81-265-3008-3}
}

@book{ellis2010,
  title = {The Essential Guide to Effect Sizes : Statistical Power, Meta-Analysis, and the Interpretation of Research Results},
  author = {Ellis, Paul D.},
  date = {2010},
  publisher = {{Cambridge University Press}}
}

@article{fritz2012joepg,
  title = {Effect Size Estimates: {{Current}} Use, Calculations, and Interpretation.},
  shorttitle = {Effect Size Estimates},
  author = {Fritz, Catherine O. and Morris, Peter E. and Richler, Jennifer J.},
  date = {2012},
  journaltitle = {Journal of Experimental Psychology: General},
  shortjournal = {Journal of Experimental Psychology: General},
  volume = {141},
  pages = {2--18},
  issn = {1939-2222, 0096-3445},
  doi = {10.1037/a0024338},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0024338},
  urldate = {2020-06-19},
  abstract = {The Publication Manual of the American Psychological Association (American Psychological Association, 2001, 2010) calls for the reporting of effect sizes and their confidence intervals. Estimates of effect size are useful for determining the practical or theoretical importance of an effect, the relative contributions of factors, and the power of an analysis. We surveyed articles published in 2009 and 2010 in the Journal of Experimental Psychology: General, noting the statistical analyses reported and the associated reporting of effect size estimates. Effect sizes were reported for fewer than half of the analyses; no article reported a confidence interval for an effect size. The most often reported analysis was analysis of variance, and almost half of these reports were not accompanied by effect sizes. Partial ␩2 was the most commonly reported effect size estimate for analysis of variance. For t tests, 2/3 of the articles did not report an associated effect size estimate; Cohen’s d was the most often reported. We provide a straightforward guide to understanding, selecting, calculating, and interpreting effect sizes for many types of data and to methods for calculating effect size confidence intervals and power analysis.},
  file = {/Users/maximiliano/Documents/pCloud sync/zotero-lib/Fritz et al/Fritz et al_2012_Effect size estimates.pdf},
  langid = {english},
  number = {1}
}

@book{grissom2005,
  title = {Effect Sizes for Research: {{A}} Broad Practical Approach},
  author = {Grissom, R. J. and Kim, J. J.},
  date = {2005},
  publisher = {{Erlbaum}},
  location = {{Mahwah, NJ}}
}

@book{grolemund2016,
  title = {R for {{Data Science}}},
  author = {Grolemund, Garrett and Wickham, Hadley},
  date = {2016},
  publisher = {{O'Reilly}},
  url = {https://bookdown.org/roy_schumacher/r4ds/}
}

@book{hedges1985,
  title = {Statistical Methods for Meta-Analysis},
  author = {Hedges, L. V. and Olkin, I.},
  date = {1985},
  publisher = {{Academic Press}},
  location = {{Orlando, FL}}
}

@article{lakens2013fp,
  title = {Calculating and Reporting Effect Sizes to Facilitate Cumulative Science: A Practical Primer for t-Tests and {{ANOVAs}}},
  shorttitle = {Calculating and Reporting Effect Sizes to Facilitate Cumulative Science},
  author = {Lakens, Daniël},
  date = {2013},
  journaltitle = {Frontiers in Psychology},
  shortjournal = {Front. Psychol.},
  volume = {4},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2013.00863},
  url = {http://journal.frontiersin.org/article/10.3389/fpsyg.2013.00863/abstract},
  urldate = {2020-06-17},
  abstract = {Effect sizes are the most important outcome of empirical studies. Most articles on effect sizes highlight their importance to communicate the practical significance of results. For scientists themselves, effect sizes are most useful because they facilitate cumulative science. Effect sizes can be used to determine the sample size for follow-up studies, or examining effects across studies. This article aims to provide a practical primer on how to calculate and report effect sizes for t-tests and ANOVA’s such that effect sizes can be used in a-priori power analyses and meta-analyses. Whereas many articles about effect sizes focus on between-subjects designs and address within-subjects designs only briefly, I provide a detailed overview of the similarities and differences between withinand between-subjects designs. I suggest that some research questions in experimental psychology examine inherently intra-individual effects, which makes effect sizes that incorporate the correlation between measures the best summary of the results. Finally, a supplementary spreadsheet is provided to make it as easy as possible for researchers to incorporate effect size calculations into their workflow.},
  file = {/Users/maximiliano/Documents/pCloud sync/zotero-lib/Lakens/Lakens_2013_Calculating and reporting effect sizes to facilitate cumulative science.pdf},
  langid = {english}
}

@software{magnusson2020,
  title = {Interpreting {{Cohen}}'s d {{Effect Size}}: {{An Interactive Visualization}}},
  author = {Magnusson, Kristoffer},
  date = {2020},
  url = {https://rpsychologist.com/d3/cohend/},
  version = {2.1.1}
}

@article{mcgrath2006pm,
  title = {When Effect Sizes Disagree: {{The}} Case of r and d.},
  shorttitle = {When Effect Sizes Disagree},
  author = {McGrath, Robert E. and Meyer, Gregory J.},
  date = {2006},
  journaltitle = {Psychological Methods},
  shortjournal = {Psychological Methods},
  volume = {11},
  pages = {386--401},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/1082-989X.11.4.386},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/1082-989X.11.4.386},
  urldate = {2020-06-20},
  file = {/Users/maximiliano/Documents/pCloud sync/zotero-lib/McGrath_Meyer/McGrath_Meyer_2006_When effect sizes disagree.pdf},
  langid = {english},
  number = {4}
}

@article{mcgraw1992pb,
  title = {A {{Common Language Effect Size Statistic}}},
  author = {McGraw, Kenneth O and Wong, S P},
  date = {1992},
  journaltitle = {Psychonomic Bulletin},
  volume = {111},
  pages = {361--365},
  file = {/Users/maximiliano/Documents/pCloud sync/zotero-lib/McGraw_Wong/McGraw_Wong_1992_A Common Language Effect Size Statistic.pdf},
  langid = {english},
  number = {2}
}

@book{mckillup2010,
  title = {Geostatistics {{Explained}}: {{An Introductory Guide}} for {{Earth Scientists}}},
  author = {McKillup, Steve and Darby Dyar, Melinda},
  date = {2010},
  publisher = {{Cambridge University Press}},
  url = {www.cambridge.org/9780521763226},
  isbn = {978-0-511-67730-4},
  pagetotal = {396}
}

@article{nakagawa2007br,
  title = {Effect Size, Confidence Interval and Statistical Significance: A Practical Guide for Biologists},
  shorttitle = {Effect Size, Confidence Interval and Statistical Significance},
  author = {Nakagawa, Shinichi and Cuthill, Innes C.},
  date = {2007-11},
  journaltitle = {Biological Reviews},
  shortjournal = {Biological Reviews},
  volume = {82},
  pages = {591--605},
  issn = {1464-7931, 1469-185X},
  doi = {10.1111/j.1469-185X.2007.00027.x},
  url = {http://doi.wiley.com/10.1111/j.1469-185X.2007.00027.x},
  urldate = {2020-06-12},
  abstract = {Null hypothesis significance testing (NHST) is the dominant statistical approach in biology, although it has many, frequently unappreciated, problems. Most importantly, NHST does not provide us with two crucial pieces of information: (1) the magnitude of an effect of interest, and (2) the precision of the estimate of the magnitude of that effect. All biologists should be ultimately interested in biological importance, which may be assessed using the magnitude of an effect, but not its statistical significance. Therefore, we advocate presentation of measures of the magnitude of effects (i.e. effect size statistics) and their confidence intervals (CIs) in all biological journals. Combined use of an effect size and its CIs enables one to assess the relationships within data more effectively than the use of p values, regardless of statistical significance. In addition, routine presentation of effect sizes will encourage researchers to view their results in the context of previous research and facilitate the incorporation of results into future meta-analysis, which has been increasingly used as the standard method of quantitative review in biology. In this article, we extensively discuss two dimensionless (and thus standardised) classes of effect size statistics: d statistics (standardised mean difference) and r statistics (correlation coefficient), because these can be calculated from almost all study designs and also because their calculations are essential for meta-analysis. However, our focus on these standardised effect size statistics does not mean unstandardised effect size statistics (e.g. mean difference and regression coefficient) are less important. We provide potential solutions for four main technical problems researchers may encounter when calculating effect size and CIs: (1) when covariates exist, (2) when bias in estimating effect size is possible, (3) when data have non-normal error structure and/or variances, and (4) when data are non-independent. Although interpretations of effect sizes are often difficult, we provide some pointers to help researchers. This paper serves both as a beginner’s instruction manual and a stimulus for changing statistical practice for the better in the biological sciences.},
  file = {/Users/maximiliano/Documents/pCloud sync/zotero-lib/Nakagawa_Cuthill/Nakagawa_Cuthill_2007_Effect size, confidence interval and statistical significance.pdf},
  langid = {english},
  number = {4}
}

@book{nolan2014,
  title = {Statistics for the {{Behavioral Sciences}}},
  author = {Nolan, Susan A. and Heinzen, Thomas E.},
  date = {2014},
  edition = {3},
  publisher = {{Worth Publishers}},
  location = {{New York}}
}

@article{reiser1999jrss,
  title = {Confidence Intervals for the Overlapping Coefficient: The Normal Equal Variance Case},
  author = {Reiser, Benjamin and Faraggi, David},
  date = {1999},
  journaltitle = {Journal of the Royal Statistical Society},
  volume = {48},
  pages = {413--418},
  abstract = {The overlapping coefficient, desined as the common area under two probability density curves, is used as a measure of agreement between two distributions. It has recently been proposed as a measure of bioequivalence under the name proportion of similar responses. Confi
dence intervals for this measure have been considered for the special case of two normal distributions with equal variances. We review and compare two procedures for this confidence interval based on the non-central t- and F -distributions. Our comparison is based on both theoretical considerations and a simulation study. Data on a marker from a study of recurrence of breast cancer are used to illustrate the methodology.},
  file = {/Users/maximiliano/Documents/pCloud sync/zotero-lib/Reiser_Faraggi/Reiser_Faraggi_1999_Confidence intervals for the overlapping coefficient.pdf},
  langid = {english},
  number = {3}
}

@article{ruscio2008pm,
  title = {A Probability-Based Measure of Effect Size: {{Robustness}} to Base Rates and Other Factors.},
  shorttitle = {A Probability-Based Measure of Effect Size},
  author = {Ruscio, John},
  date = {2008},
  journaltitle = {Psychological Methods},
  shortjournal = {Psychological Methods},
  volume = {13},
  pages = {19--30},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/1082-989X.13.1.19},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/1082-989X.13.1.19},
  urldate = {2020-06-20},
  abstract = {Calculating and reporting appropriate measures of effect size are becoming standard practice in psychological research. One of the most common scenarios encountered involves the comparison of 2 groups, which includes research designs that are experimental (e.g., random assignment to treatment vs. placebo conditions) and nonexperimental (e.g., testing for gender differences). Familiar measures such as the standardized mean difference (d) or the pointbiserial correlation (rpb) characterize the magnitude of the difference between groups, but these effect size measures are sensitive to a number of additional influences. For example, R. E. McGrath and G. J. Meyer (2006) showed that rpb is sensitive to sample base rates, and extending their analysis to situations of unequal variances reveals that d is, too. The probability-based measure A, the nonparametric generalization of what K. O. McGraw and S. P. Wong (1992) called the common language effect size statistic, is insensitive to base rates and more robust to several other factors (e.g., extreme scores, nonlinear transformations). In addition to its excellent generalizability across contexts, A is easy to understand and can be obtained from standard computer output or through simple hand calculations.},
  file = {/Users/maximiliano/Documents/pCloud sync/zotero-lib/Ruscio/Ruscio_2008_A probability-based measure of effect size.pdf},
  langid = {english},
  number = {1}
}

@article{ruscio2012mbr,
  title = {Confidence {{Intervals}} for the {{Probability}} of {{Superiority Effect Size Measure}} and the {{Area Under}} a {{Receiver Operating Characteristic Curve}}},
  author = {Ruscio, John and Mullen, Tara},
  date = {2012-03-30},
  journaltitle = {Multivariate Behavioral Research},
  shortjournal = {Multivariate Behavioral Research},
  volume = {47},
  pages = {201--223},
  issn = {0027-3171, 1532-7906},
  doi = {10.1080/00273171.2012.658329},
  url = {http://www.tandfonline.com/doi/abs/10.1080/00273171.2012.658329},
  urldate = {2020-06-20},
  file = {/Users/maximiliano/Documents/pCloud sync/zotero-lib/Ruscio_Mullen/Ruscio_Mullen_2012_Confidence Intervals for the Probability of Superiority Effect Size Measure and.pdf},
  langid = {english},
  number = {2}
}

@article{sullivan2012jogme,
  title = {Using {{Effect Size}}—or {{Why}} the {{P Value Is Not Enough}}},
  author = {Sullivan, Gail M. and Feinn, Richard},
  date = {2012-09},
  journaltitle = {Journal of Graduate Medical Education},
  shortjournal = {Journal of Graduate Medical Education},
  volume = {4},
  pages = {279--282},
  issn = {1949-8349, 1949-8357},
  doi = {10.4300/JGME-D-12-00156.1},
  url = {http://www.jgme.org/doi/abs/10.4300/JGME-D-12-00156.1},
  urldate = {2020-05-28},
  abstract = {Effect size helps readers understand the magnitude of differences found, whereas statistical significance examines whether the findings are likely to be due to chance. Both are essential for readers to understand the full impact of your work. Report both in the Abstract and Results sections.},
  file = {/Users/maximiliano/Documents/pCloud sync/zotero-lib/Sullivan_Feinn/Sullivan_Feinn_2012_Using Effect Size—or Why the P Value Is Not Enough.pdf},
  langid = {english},
  number = {3}
}

@book{swan1995,
  title = {Introduction to {{Geological Data Analysis}}},
  author = {Swan, A.R.H. and Sandilands, M.},
  date = {1995},
  publisher = {{Blackwell Science}}
}

@article{thompson2007ps,
  title = {Effect Sizes, Confidence Intervals, and Confidence Intervals for Effect Sizes},
  author = {Thompson, Bruce},
  date = {2007-05},
  journaltitle = {Psychology in the Schools},
  shortjournal = {Psychol. Schs.},
  volume = {44},
  pages = {423--432},
  issn = {00333085, 15206807},
  doi = {10.1002/pits.20234},
  url = {http://doi.wiley.com/10.1002/pits.20234},
  urldate = {2020-06-17},
  file = {/Users/maximiliano/Documents/pCloud sync/zotero-lib/Thompson/Thompson_2007_Effect sizes, confidence intervals, and confidence intervals for effect sizes.pdf},
  langid = {english},
  number = {5}
}

@article{tomczak2014tss,
  title = {The Need to Report Effect Size Estimates Revisited. {{An}} Overview of Some Recommended Measures of Effect Size},
  author = {Tomczak, Maciej and Tomczak, Ewa},
  date = {2014},
  journaltitle = {Trends in Sport Sciences},
  volume = {1},
  pages = {19--25},
  file = {/Users/maximiliano/Documents/pCloud sync/zotero-lib/Tomczak_Tomczak/Tomczak_Tomczak_2014_The need to report effect size estimates revisited.pdf},
  langid = {english},
  number = {21}
}

@book{trauth2015,
  title = {{{MATLAB}}® {{Recipes}} for {{Earth Sciences}}},
  author = {Trauth, M.H.},
  date = {2015},
  edition = {4},
  publisher = {{Springer-Verlag Berlin Heidelberg}},
  location = {{Berlin}},
  isbn = {978-3-662-46243-0}
}

@book{triola2004,
  title = {Probabilidad y Estadística},
  author = {Triola, Mario F.},
  date = {2004},
  edition = {9},
  publisher = {{Pearson Educación}},
  location = {{México}},
  isbn = {970-26-0575-X}
}

@book{walpole2012,
  title = {Probabilidad y Estadística Para Ingeniería y Ciencias},
  author = {Walpole, R. E. and Myers, R. H. and Myers, S. L.},
  date = {2012},
  publisher = {{Pearson}},
  isbn = {978-607-32-1417-9}
}

@article{zou2007pm,
  title = {Toward Using Confidence Intervals to Compare Correlations.},
  author = {Zou, Guang Yong},
  date = {2007-12},
  journaltitle = {Psychological Methods},
  shortjournal = {Psychological Methods},
  volume = {12},
  pages = {399--413},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/1082-989X.12.4.399},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/1082-989X.12.4.399},
  urldate = {2020-06-17},
  abstract = {Confidence intervals are widely accepted as a preferred way to present study results. They encompass significance tests and provide an estimate of the magnitude of the effect. However, comparisons of correlations still rely heavily on significance testing. The persistence of this practice is caused primarily by the lack of simple yet accurate procedures that can maintain coverage at the nominal level in a nonlopsided manner. The purpose of this article is to present a general approach to constructing approximate confidence intervals for differences between (a) 2 independent correlations, (b) 2 overlapping correlations, (c) 2 nonoverlapping correlations, and (d) 2 independent R2s. The distinctive feature of this approach is its acknowledgment of the asymmetry of sampling distributions for single correlations. This approach requires only the availability of confidence limits for the separate correlations and, for correlated correlations, a method for taking into account the dependency between correlations. These closed-form procedures are shown by simulation studies to provide very satisfactory results in small to moderate sample sizes. The proposed approach is illustrated with worked examples.},
  file = {/Users/maximiliano/Documents/pCloud sync/zotero-lib/Zou/Zou_2007_Toward using confidence intervals to compare correlations.pdf},
  langid = {english},
  number = {4}
}


